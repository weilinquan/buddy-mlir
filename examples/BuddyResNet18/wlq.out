{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg0_1', 'op': 'placeholder', 'target': 'arg0_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution: None}, 'type': None, '_prev': , '_next': arg1_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64, 3, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 3, 7, 7]), dtype=torch.float32, requires_grad=True, stride=(147, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg1_1', 'op': 'placeholder', 'target': 'arg1_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training: None}, 'type': None, '_prev': arg0_1, '_next': arg2_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg2_1', 'op': 'placeholder', 'target': 'arg2_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training: None}, 'type': None, '_prev': arg1_1, '_next': arg3_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg3_1', 'op': 'placeholder', 'target': 'arg3_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_1: None}, 'type': None, '_prev': arg2_1, '_next': arg4_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64, 64, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 64, 3, 3]), dtype=torch.float32, requires_grad=True, stride=(576, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg4_1', 'op': 'placeholder', 'target': 'arg4_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_1: None}, 'type': None, '_prev': arg3_1, '_next': arg5_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg5_1', 'op': 'placeholder', 'target': 'arg5_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_1: None}, 'type': None, '_prev': arg4_1, '_next': arg6_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg6_1', 'op': 'placeholder', 'target': 'arg6_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_2: None}, 'type': None, '_prev': arg5_1, '_next': arg7_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64, 64, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 64, 3, 3]), dtype=torch.float32, requires_grad=True, stride=(576, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg7_1', 'op': 'placeholder', 'target': 'arg7_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_2: None}, 'type': None, '_prev': arg6_1, '_next': arg8_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg8_1', 'op': 'placeholder', 'target': 'arg8_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_2: None}, 'type': None, '_prev': arg7_1, '_next': arg9_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg9_1', 'op': 'placeholder', 'target': 'arg9_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_3: None}, 'type': None, '_prev': arg8_1, '_next': arg10_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64, 64, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 64, 3, 3]), dtype=torch.float32, requires_grad=True, stride=(576, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg10_1', 'op': 'placeholder', 'target': 'arg10_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_3: None}, 'type': None, '_prev': arg9_1, '_next': arg11_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg11_1', 'op': 'placeholder', 'target': 'arg11_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_3: None}, 'type': None, '_prev': arg10_1, '_next': arg12_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg12_1', 'op': 'placeholder', 'target': 'arg12_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_4: None}, 'type': None, '_prev': arg11_1, '_next': arg13_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64, 64, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 64, 3, 3]), dtype=torch.float32, requires_grad=True, stride=(576, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg13_1', 'op': 'placeholder', 'target': 'arg13_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_4: None}, 'type': None, '_prev': arg12_1, '_next': arg14_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg14_1', 'op': 'placeholder', 'target': 'arg14_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_4: None}, 'type': None, '_prev': arg13_1, '_next': arg15_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg15_1', 'op': 'placeholder', 'target': 'arg15_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_5: None}, 'type': None, '_prev': arg14_1, '_next': arg16_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128, 64, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 64, 3, 3]), dtype=torch.float32, requires_grad=True, stride=(576, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg16_1', 'op': 'placeholder', 'target': 'arg16_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_5: None}, 'type': None, '_prev': arg15_1, '_next': arg17_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg17_1', 'op': 'placeholder', 'target': 'arg17_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_5: None}, 'type': None, '_prev': arg16_1, '_next': arg18_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg18_1', 'op': 'placeholder', 'target': 'arg18_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_6: None}, 'type': None, '_prev': arg17_1, '_next': arg19_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128, 128, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 128, 3, 3]), dtype=torch.float32, requires_grad=True, stride=(1152, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg19_1', 'op': 'placeholder', 'target': 'arg19_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_6: None}, 'type': None, '_prev': arg18_1, '_next': arg20_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg20_1', 'op': 'placeholder', 'target': 'arg20_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_6: None}, 'type': None, '_prev': arg19_1, '_next': arg21_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg21_1', 'op': 'placeholder', 'target': 'arg21_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_7: None}, 'type': None, '_prev': arg20_1, '_next': arg22_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128, 64, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 64, 1, 1]), dtype=torch.float32, requires_grad=True, stride=(64, 1, 1, 1), memory_format=torch.channels_last, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg22_1', 'op': 'placeholder', 'target': 'arg22_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_7: None}, 'type': None, '_prev': arg21_1, '_next': arg23_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg23_1', 'op': 'placeholder', 'target': 'arg23_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_7: None}, 'type': None, '_prev': arg22_1, '_next': arg24_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg24_1', 'op': 'placeholder', 'target': 'arg24_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_8: None}, 'type': None, '_prev': arg23_1, '_next': arg25_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128, 128, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 128, 3, 3]), dtype=torch.float32, requires_grad=True, stride=(1152, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg25_1', 'op': 'placeholder', 'target': 'arg25_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_8: None}, 'type': None, '_prev': arg24_1, '_next': arg26_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg26_1', 'op': 'placeholder', 'target': 'arg26_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_8: None}, 'type': None, '_prev': arg25_1, '_next': arg27_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg27_1', 'op': 'placeholder', 'target': 'arg27_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_9: None}, 'type': None, '_prev': arg26_1, '_next': arg28_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128, 128, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 128, 3, 3]), dtype=torch.float32, requires_grad=True, stride=(1152, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg28_1', 'op': 'placeholder', 'target': 'arg28_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_9: None}, 'type': None, '_prev': arg27_1, '_next': arg29_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg29_1', 'op': 'placeholder', 'target': 'arg29_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_9: None}, 'type': None, '_prev': arg28_1, '_next': arg30_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg30_1', 'op': 'placeholder', 'target': 'arg30_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_10: None}, 'type': None, '_prev': arg29_1, '_next': arg31_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256, 128, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 128, 3, 3]), dtype=torch.float32, requires_grad=True, stride=(1152, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg31_1', 'op': 'placeholder', 'target': 'arg31_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_10: None}, 'type': None, '_prev': arg30_1, '_next': arg32_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg32_1', 'op': 'placeholder', 'target': 'arg32_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_10: None}, 'type': None, '_prev': arg31_1, '_next': arg33_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg33_1', 'op': 'placeholder', 'target': 'arg33_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_11: None}, 'type': None, '_prev': arg32_1, '_next': arg34_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256, 256, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 256, 3, 3]), dtype=torch.float32, requires_grad=True, stride=(2304, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg34_1', 'op': 'placeholder', 'target': 'arg34_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_11: None}, 'type': None, '_prev': arg33_1, '_next': arg35_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg35_1', 'op': 'placeholder', 'target': 'arg35_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_11: None}, 'type': None, '_prev': arg34_1, '_next': arg36_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg36_1', 'op': 'placeholder', 'target': 'arg36_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_12: None}, 'type': None, '_prev': arg35_1, '_next': arg37_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256, 128, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 128, 1, 1]), dtype=torch.float32, requires_grad=True, stride=(128, 1, 1, 1), memory_format=torch.channels_last, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg37_1', 'op': 'placeholder', 'target': 'arg37_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_12: None}, 'type': None, '_prev': arg36_1, '_next': arg38_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg38_1', 'op': 'placeholder', 'target': 'arg38_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_12: None}, 'type': None, '_prev': arg37_1, '_next': arg39_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg39_1', 'op': 'placeholder', 'target': 'arg39_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_13: None}, 'type': None, '_prev': arg38_1, '_next': arg40_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256, 256, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 256, 3, 3]), dtype=torch.float32, requires_grad=True, stride=(2304, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg40_1', 'op': 'placeholder', 'target': 'arg40_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_13: None}, 'type': None, '_prev': arg39_1, '_next': arg41_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg41_1', 'op': 'placeholder', 'target': 'arg41_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_13: None}, 'type': None, '_prev': arg40_1, '_next': arg42_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg42_1', 'op': 'placeholder', 'target': 'arg42_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_14: None}, 'type': None, '_prev': arg41_1, '_next': arg43_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256, 256, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 256, 3, 3]), dtype=torch.float32, requires_grad=True, stride=(2304, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg43_1', 'op': 'placeholder', 'target': 'arg43_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_14: None}, 'type': None, '_prev': arg42_1, '_next': arg44_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg44_1', 'op': 'placeholder', 'target': 'arg44_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_14: None}, 'type': None, '_prev': arg43_1, '_next': arg45_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg45_1', 'op': 'placeholder', 'target': 'arg45_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_15: None}, 'type': None, '_prev': arg44_1, '_next': arg46_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512, 256, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 256, 3, 3]), dtype=torch.float32, requires_grad=True, stride=(2304, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg46_1', 'op': 'placeholder', 'target': 'arg46_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_15: None}, 'type': None, '_prev': arg45_1, '_next': arg47_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg47_1', 'op': 'placeholder', 'target': 'arg47_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_15: None}, 'type': None, '_prev': arg46_1, '_next': arg48_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg48_1', 'op': 'placeholder', 'target': 'arg48_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_16: None}, 'type': None, '_prev': arg47_1, '_next': arg49_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512, 512, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 512, 3, 3]), dtype=torch.float32, requires_grad=True, stride=(4608, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg49_1', 'op': 'placeholder', 'target': 'arg49_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_16: None}, 'type': None, '_prev': arg48_1, '_next': arg50_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg50_1', 'op': 'placeholder', 'target': 'arg50_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_16: None}, 'type': None, '_prev': arg49_1, '_next': arg51_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg51_1', 'op': 'placeholder', 'target': 'arg51_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_17: None}, 'type': None, '_prev': arg50_1, '_next': arg52_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512, 256, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 256, 1, 1]), dtype=torch.float32, requires_grad=True, stride=(256, 1, 1, 1), memory_format=torch.channels_last, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg52_1', 'op': 'placeholder', 'target': 'arg52_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_17: None}, 'type': None, '_prev': arg51_1, '_next': arg53_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg53_1', 'op': 'placeholder', 'target': 'arg53_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_17: None}, 'type': None, '_prev': arg52_1, '_next': arg54_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg54_1', 'op': 'placeholder', 'target': 'arg54_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_18: None}, 'type': None, '_prev': arg53_1, '_next': arg55_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512, 512, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 512, 3, 3]), dtype=torch.float32, requires_grad=True, stride=(4608, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg55_1', 'op': 'placeholder', 'target': 'arg55_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_18: None}, 'type': None, '_prev': arg54_1, '_next': arg56_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg56_1', 'op': 'placeholder', 'target': 'arg56_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_18: None}, 'type': None, '_prev': arg55_1, '_next': arg57_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg57_1', 'op': 'placeholder', 'target': 'arg57_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_19: None}, 'type': None, '_prev': arg56_1, '_next': arg58_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512, 512, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 512, 3, 3]), dtype=torch.float32, requires_grad=True, stride=(4608, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg58_1', 'op': 'placeholder', 'target': 'arg58_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_19: None}, 'type': None, '_prev': arg57_1, '_next': arg59_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg59_1', 'op': 'placeholder', 'target': 'arg59_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_19: None}, 'type': None, '_prev': arg58_1, '_next': arg60_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg60_1', 'op': 'placeholder', 'target': 'arg60_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {t: None}, 'type': None, '_prev': arg59_1, '_next': arg61_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(1000, 512)), 'tensor_meta': TensorMetadata(shape=torch.Size([1000, 512]), dtype=torch.float32, requires_grad=True, stride=(512, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg61_1', 'op': 'placeholder', 'target': 'arg61_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {addmm: None}, 'type': None, '_prev': arg60_1, '_next': arg62_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(1000,)), 'tensor_meta': TensorMetadata(shape=torch.Size([1000]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg62_1', 'op': 'placeholder', 'target': 'arg62_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training: None}, 'type': None, '_prev': arg61_1, '_next': arg63_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg63_1', 'op': 'placeholder', 'target': 'arg63_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training: None}, 'type': None, '_prev': arg62_1, '_next': arg64_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg64_1', 'op': 'placeholder', 'target': 'arg64_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {}, 'type': None, '_prev': arg63_1, '_next': arg65_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.int64, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg65_1', 'op': 'placeholder', 'target': 'arg65_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_1: None}, 'type': None, '_prev': arg64_1, '_next': arg66_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg66_1', 'op': 'placeholder', 'target': 'arg66_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_1: None}, 'type': None, '_prev': arg65_1, '_next': arg67_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg67_1', 'op': 'placeholder', 'target': 'arg67_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {}, 'type': None, '_prev': arg66_1, '_next': arg68_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.int64, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg68_1', 'op': 'placeholder', 'target': 'arg68_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_2: None}, 'type': None, '_prev': arg67_1, '_next': arg69_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg69_1', 'op': 'placeholder', 'target': 'arg69_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_2: None}, 'type': None, '_prev': arg68_1, '_next': arg70_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg70_1', 'op': 'placeholder', 'target': 'arg70_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {}, 'type': None, '_prev': arg69_1, '_next': arg71_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.int64, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg71_1', 'op': 'placeholder', 'target': 'arg71_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_3: None}, 'type': None, '_prev': arg70_1, '_next': arg72_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg72_1', 'op': 'placeholder', 'target': 'arg72_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_3: None}, 'type': None, '_prev': arg71_1, '_next': arg73_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg73_1', 'op': 'placeholder', 'target': 'arg73_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {}, 'type': None, '_prev': arg72_1, '_next': arg74_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.int64, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg74_1', 'op': 'placeholder', 'target': 'arg74_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_4: None}, 'type': None, '_prev': arg73_1, '_next': arg75_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg75_1', 'op': 'placeholder', 'target': 'arg75_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_4: None}, 'type': None, '_prev': arg74_1, '_next': arg76_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg76_1', 'op': 'placeholder', 'target': 'arg76_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {}, 'type': None, '_prev': arg75_1, '_next': arg77_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.int64, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg77_1', 'op': 'placeholder', 'target': 'arg77_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_5: None}, 'type': None, '_prev': arg76_1, '_next': arg78_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg78_1', 'op': 'placeholder', 'target': 'arg78_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_5: None}, 'type': None, '_prev': arg77_1, '_next': arg79_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg79_1', 'op': 'placeholder', 'target': 'arg79_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {}, 'type': None, '_prev': arg78_1, '_next': arg80_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.int64, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg80_1', 'op': 'placeholder', 'target': 'arg80_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_6: None}, 'type': None, '_prev': arg79_1, '_next': arg81_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg81_1', 'op': 'placeholder', 'target': 'arg81_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_6: None}, 'type': None, '_prev': arg80_1, '_next': arg82_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg82_1', 'op': 'placeholder', 'target': 'arg82_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {}, 'type': None, '_prev': arg81_1, '_next': arg83_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.int64, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg83_1', 'op': 'placeholder', 'target': 'arg83_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_7: None}, 'type': None, '_prev': arg82_1, '_next': arg84_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg84_1', 'op': 'placeholder', 'target': 'arg84_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_7: None}, 'type': None, '_prev': arg83_1, '_next': arg85_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg85_1', 'op': 'placeholder', 'target': 'arg85_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {}, 'type': None, '_prev': arg84_1, '_next': arg86_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.int64, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg86_1', 'op': 'placeholder', 'target': 'arg86_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_8: None}, 'type': None, '_prev': arg85_1, '_next': arg87_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg87_1', 'op': 'placeholder', 'target': 'arg87_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_8: None}, 'type': None, '_prev': arg86_1, '_next': arg88_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg88_1', 'op': 'placeholder', 'target': 'arg88_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {}, 'type': None, '_prev': arg87_1, '_next': arg89_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.int64, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg89_1', 'op': 'placeholder', 'target': 'arg89_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_9: None}, 'type': None, '_prev': arg88_1, '_next': arg90_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg90_1', 'op': 'placeholder', 'target': 'arg90_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_9: None}, 'type': None, '_prev': arg89_1, '_next': arg91_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg91_1', 'op': 'placeholder', 'target': 'arg91_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {}, 'type': None, '_prev': arg90_1, '_next': arg92_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.int64, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg92_1', 'op': 'placeholder', 'target': 'arg92_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_10: None}, 'type': None, '_prev': arg91_1, '_next': arg93_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg93_1', 'op': 'placeholder', 'target': 'arg93_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_10: None}, 'type': None, '_prev': arg92_1, '_next': arg94_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg94_1', 'op': 'placeholder', 'target': 'arg94_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {}, 'type': None, '_prev': arg93_1, '_next': arg95_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.int64, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg95_1', 'op': 'placeholder', 'target': 'arg95_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_11: None}, 'type': None, '_prev': arg94_1, '_next': arg96_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg96_1', 'op': 'placeholder', 'target': 'arg96_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_11: None}, 'type': None, '_prev': arg95_1, '_next': arg97_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg97_1', 'op': 'placeholder', 'target': 'arg97_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {}, 'type': None, '_prev': arg96_1, '_next': arg98_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.int64, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg98_1', 'op': 'placeholder', 'target': 'arg98_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_12: None}, 'type': None, '_prev': arg97_1, '_next': arg99_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg99_1', 'op': 'placeholder', 'target': 'arg99_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_12: None}, 'type': None, '_prev': arg98_1, '_next': arg100_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg100_1', 'op': 'placeholder', 'target': 'arg100_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {}, 'type': None, '_prev': arg99_1, '_next': arg101_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.int64, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg101_1', 'op': 'placeholder', 'target': 'arg101_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_13: None}, 'type': None, '_prev': arg100_1, '_next': arg102_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg102_1', 'op': 'placeholder', 'target': 'arg102_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_13: None}, 'type': None, '_prev': arg101_1, '_next': arg103_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg103_1', 'op': 'placeholder', 'target': 'arg103_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {}, 'type': None, '_prev': arg102_1, '_next': arg104_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.int64, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg104_1', 'op': 'placeholder', 'target': 'arg104_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_14: None}, 'type': None, '_prev': arg103_1, '_next': arg105_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg105_1', 'op': 'placeholder', 'target': 'arg105_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_14: None}, 'type': None, '_prev': arg104_1, '_next': arg106_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg106_1', 'op': 'placeholder', 'target': 'arg106_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {}, 'type': None, '_prev': arg105_1, '_next': arg107_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.int64, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg107_1', 'op': 'placeholder', 'target': 'arg107_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_15: None}, 'type': None, '_prev': arg106_1, '_next': arg108_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg108_1', 'op': 'placeholder', 'target': 'arg108_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_15: None}, 'type': None, '_prev': arg107_1, '_next': arg109_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg109_1', 'op': 'placeholder', 'target': 'arg109_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {}, 'type': None, '_prev': arg108_1, '_next': arg110_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.int64, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg110_1', 'op': 'placeholder', 'target': 'arg110_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_16: None}, 'type': None, '_prev': arg109_1, '_next': arg111_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg111_1', 'op': 'placeholder', 'target': 'arg111_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_16: None}, 'type': None, '_prev': arg110_1, '_next': arg112_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg112_1', 'op': 'placeholder', 'target': 'arg112_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {}, 'type': None, '_prev': arg111_1, '_next': arg113_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.int64, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg113_1', 'op': 'placeholder', 'target': 'arg113_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_17: None}, 'type': None, '_prev': arg112_1, '_next': arg114_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg114_1', 'op': 'placeholder', 'target': 'arg114_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_17: None}, 'type': None, '_prev': arg113_1, '_next': arg115_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg115_1', 'op': 'placeholder', 'target': 'arg115_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {}, 'type': None, '_prev': arg114_1, '_next': arg116_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.int64, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg116_1', 'op': 'placeholder', 'target': 'arg116_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_18: None}, 'type': None, '_prev': arg115_1, '_next': arg117_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg117_1', 'op': 'placeholder', 'target': 'arg117_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_18: None}, 'type': None, '_prev': arg116_1, '_next': arg118_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg118_1', 'op': 'placeholder', 'target': 'arg118_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {}, 'type': None, '_prev': arg117_1, '_next': arg119_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.int64, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg119_1', 'op': 'placeholder', 'target': 'arg119_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_19: None}, 'type': None, '_prev': arg118_1, '_next': arg120_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg120_1', 'op': 'placeholder', 'target': 'arg120_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_19: None}, 'type': None, '_prev': arg119_1, '_next': arg121_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg121_1', 'op': 'placeholder', 'target': 'arg121_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {}, 'type': None, '_prev': arg120_1, '_next': arg122_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.int64, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'arg122_1', 'op': 'placeholder', 'target': 'arg122_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution: None}, 'type': None, '_prev': arg121_1, '_next': convolution, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(1, 3, 224, 224)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 224, 224]), dtype=torch.float32, requires_grad=False, stride=(150528, 50176, 224, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'convolution', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {arg122_1: None, arg0_1: None}, '_args': (arg122_1, arg0_1, None, [2, 2], [3, 3], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training: None}, 'type': None, '_prev': arg122_1, '_next': _native_batch_norm_legit_no_training, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 268, in _forward_impl\n    x = self.conv1(x)\n', 'nn_module_stack': {'L__self___conv1': ("L['self'].conv1", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('l__self___conv1', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('l__self___conv1', 'L__self___conv1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 112, 112)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 112, 112]), dtype=torch.float32, requires_grad=False, stride=(802816, 12544, 112, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': '_native_batch_norm_legit_no_training', 'op': 'call_function', 'target': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, '_input_nodes': {convolution: None, arg1_1: None, arg2_1: None, arg62_1: None, arg63_1: None}, '_args': (convolution, arg1_1, arg2_1, arg62_1, arg63_1, 0.1, 1e-05), '_kwargs': {}, 'users': {getitem: None}, 'type': None, '_prev': convolution, '_next': getitem, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 269, in _forward_impl\n    x = self.bn1(x)\n', 'nn_module_stack': {'L__self___bn1': ("L['self'].bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('l__self___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('l__self___bn1', 'L__self___bn1')], 'seq_nr': 123, 'val': (FakeTensor(..., size=(1, 64, 112, 112)), FakeTensor(..., size=(0,)), FakeTensor(..., size=(0,)))}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'getitem', 'op': 'call_function', 'target': <built-in function getitem>, '_input_nodes': {_native_batch_norm_legit_no_training: None}, '_args': (_native_batch_norm_legit_no_training, 0), '_kwargs': {}, 'users': {relu: None}, 'type': None, '_prev': _native_batch_norm_legit_no_training, '_next': relu, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 269, in _forward_impl\n    x = self.bn1(x)\n', 'nn_module_stack': {'L__self___bn1': ("L['self'].bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('l__self___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('l__self___bn1', 'L__self___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 112, 112)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 112, 112]), dtype=torch.float32, requires_grad=False, stride=(802816, 12544, 112, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'relu', 'op': 'call_function', 'target': <OpOverload(op='aten.relu', overload='default')>, '_input_nodes': {getitem: None}, '_args': (getitem,), '_kwargs': {}, 'users': {max_pool2d_with_indices: None}, 'type': None, '_prev': getitem, '_next': max_pool2d_with_indices, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 270, in _forward_impl\n    x = self.relu(x)\n', 'nn_module_stack': {'L__self___relu': ("L['self'].relu", <class 'torch.nn.modules.activation.ReLU'>)}, 'source_fn': ('l__self___relu', <class 'torch.nn.modules.activation.ReLU'>), 'original_aten': <OpOverload(op='aten.relu', overload='default')>, 'from_node': [('l__self___relu', 'L__self___relu')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 112, 112)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 112, 112]), dtype=torch.float32, requires_grad=False, stride=(802816, 12544, 112, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'max_pool2d_with_indices', 'op': 'call_function', 'target': <OpOverload(op='aten.max_pool2d_with_indices', overload='default')>, '_input_nodes': {relu: None}, '_args': (relu, [3, 3], [2, 2], [1, 1]), '_kwargs': {}, 'users': {getitem_3: None}, 'type': None, '_prev': relu, '_next': getitem_3, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 271, in _forward_impl\n    x = self.maxpool(x)\n', 'nn_module_stack': {'L__self___maxpool': ("L['self'].maxpool", <class 'torch.nn.modules.pooling.MaxPool2d'>)}, 'source_fn': ('l__self___maxpool', <class 'torch.nn.modules.pooling.MaxPool2d'>), 'original_aten': <OpOverload(op='aten.max_pool2d_with_indices', overload='default')>, 'from_node': [('l__self___maxpool', 'L__self___maxpool')], 'seq_nr': 123, 'val': (FakeTensor(..., size=(1, 64, 56, 56)), FakeTensor(..., size=(1, 64, 56, 56), dtype=torch.int64))}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'getitem_3', 'op': 'call_function', 'target': <built-in function getitem>, '_input_nodes': {max_pool2d_with_indices: None}, '_args': (max_pool2d_with_indices, 0), '_kwargs': {}, 'users': {convolution_1: None, add: None}, 'type': None, '_prev': max_pool2d_with_indices, '_next': convolution_1, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 271, in _forward_impl\n    x = self.maxpool(x)\n', 'nn_module_stack': {'L__self___maxpool': ("L['self'].maxpool", <class 'torch.nn.modules.pooling.MaxPool2d'>)}, 'source_fn': ('l__self___maxpool', <class 'torch.nn.modules.pooling.MaxPool2d'>), 'original_aten': <OpOverload(op='aten.max_pool2d_with_indices', overload='default')>, 'from_node': [('l__self___maxpool', 'L__self___maxpool')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 56, 56)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 56, 56]), dtype=torch.float32, requires_grad=False, stride=(200704, 3136, 56, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'convolution_1', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {getitem_3: None, arg3_1: None}, '_args': (getitem_3, arg3_1, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_1: None}, 'type': None, '_prev': getitem_3, '_next': _native_batch_norm_legit_no_training_1, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 92, in forward\n    out = self.conv1(x)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___conv1': ("getattr(L['self'].layer1, '0').conv1", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___conv1', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___conv1', 'getattr_L__self___layer1___0___conv1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 56, 56)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 56, 56]), dtype=torch.float32, requires_grad=False, stride=(200704, 3136, 56, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': '_native_batch_norm_legit_no_training_1', 'op': 'call_function', 'target': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, '_input_nodes': {convolution_1: None, arg4_1: None, arg5_1: None, arg65_1: None, arg66_1: None}, '_args': (convolution_1, arg4_1, arg5_1, arg65_1, arg66_1, 0.1, 1e-05), '_kwargs': {}, 'users': {getitem_5: None}, 'type': None, '_prev': convolution_1, '_next': getitem_5, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___bn1': ("getattr(L['self'].layer1, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___bn1', 'getattr_L__self___layer1___0___bn1')], 'seq_nr': 123, 'val': (FakeTensor(..., size=(1, 64, 56, 56)), FakeTensor(..., size=(0,)), FakeTensor(..., size=(0,)))}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'getitem_5', 'op': 'call_function', 'target': <built-in function getitem>, '_input_nodes': {_native_batch_norm_legit_no_training_1: None}, '_args': (_native_batch_norm_legit_no_training_1, 0), '_kwargs': {}, 'users': {relu_1: None}, 'type': None, '_prev': _native_batch_norm_legit_no_training_1, '_next': relu_1, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___bn1': ("getattr(L['self'].layer1, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___bn1', 'getattr_L__self___layer1___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 56, 56)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 56, 56]), dtype=torch.float32, requires_grad=False, stride=(200704, 3136, 56, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'relu_1', 'op': 'call_function', 'target': <OpOverload(op='aten.relu', overload='default')>, '_input_nodes': {getitem_5: None}, '_args': (getitem_5,), '_kwargs': {}, 'users': {convolution_2: None}, 'type': None, '_prev': getitem_5, '_next': convolution_2, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 94, in forward\n    out = self.relu(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___relu': ("getattr(L['self'].layer1, '0').relu", <class 'torch.nn.modules.activation.ReLU'>)}, 'source_fn': ('getattr_l__self___layer1___0___relu', <class 'torch.nn.modules.activation.ReLU'>), 'original_aten': <OpOverload(op='aten.relu', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___relu', 'getattr_L__self___layer1___0___relu')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 56, 56)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 56, 56]), dtype=torch.float32, requires_grad=False, stride=(200704, 3136, 56, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'convolution_2', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {relu_1: None, arg6_1: None}, '_args': (relu_1, arg6_1, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_2: None}, 'type': None, '_prev': relu_1, '_next': _native_batch_norm_legit_no_training_2, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 96, in forward\n    out = self.conv2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___conv2': ("getattr(L['self'].layer1, '0').conv2", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___conv2', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___conv2', 'getattr_L__self___layer1___0___conv2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 56, 56)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 56, 56]), dtype=torch.float32, requires_grad=False, stride=(200704, 3136, 56, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': '_native_batch_norm_legit_no_training_2', 'op': 'call_function', 'target': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, '_input_nodes': {convolution_2: None, arg7_1: None, arg8_1: None, arg68_1: None, arg69_1: None}, '_args': (convolution_2, arg7_1, arg8_1, arg68_1, arg69_1, 0.1, 1e-05), '_kwargs': {}, 'users': {getitem_8: None}, 'type': None, '_prev': convolution_2, '_next': getitem_8, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___bn2': ("getattr(L['self'].layer1, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___bn2', 'getattr_L__self___layer1___0___bn2')], 'seq_nr': 123, 'val': (FakeTensor(..., size=(1, 64, 56, 56)), FakeTensor(..., size=(0,)), FakeTensor(..., size=(0,)))}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'getitem_8', 'op': 'call_function', 'target': <built-in function getitem>, '_input_nodes': {_native_batch_norm_legit_no_training_2: None}, '_args': (_native_batch_norm_legit_no_training_2, 0), '_kwargs': {}, 'users': {add: None}, 'type': None, '_prev': _native_batch_norm_legit_no_training_2, '_next': add, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___bn2': ("getattr(L['self'].layer1, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___bn2', 'getattr_L__self___layer1___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 56, 56)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 56, 56]), dtype=torch.float32, requires_grad=False, stride=(200704, 3136, 56, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'add', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {getitem_8: None, getitem_3: None}, '_args': (getitem_8, getitem_3), '_kwargs': {}, 'users': {relu_2: None}, 'type': None, '_prev': getitem_8, '_next': relu_2, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 102, in forward\n    out += identity\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>)}, 'source_fn': ('iadd', <built-in function iadd>), 'original_aten': <OpOverload(op='aten.add', overload='Tensor')>, 'from_node': [('iadd', <built-in function iadd>)], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 56, 56)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 56, 56]), dtype=torch.float32, requires_grad=False, stride=(200704, 3136, 56, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'relu_2', 'op': 'call_function', 'target': <OpOverload(op='aten.relu', overload='default')>, '_input_nodes': {add: None}, '_args': (add,), '_kwargs': {}, 'users': {convolution_3: None, add_1: None}, 'type': None, '_prev': add, '_next': convolution_3, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 103, in forward\n    out = self.relu(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___relu': ("getattr(L['self'].layer1, '0').relu", <class 'torch.nn.modules.activation.ReLU'>)}, 'source_fn': ('getattr_l__self___layer1___0___relu_1', <class 'torch.nn.modules.activation.ReLU'>), 'original_aten': <OpOverload(op='aten.relu', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___relu_1', 'getattr_L__self___layer1___0___relu')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 56, 56)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 56, 56]), dtype=torch.float32, requires_grad=False, stride=(200704, 3136, 56, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'convolution_3', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {relu_2: None, arg9_1: None}, '_args': (relu_2, arg9_1, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_3: None}, 'type': None, '_prev': relu_2, '_next': _native_batch_norm_legit_no_training_3, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 92, in forward\n    out = self.conv1(x)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___conv1': ("getattr(L['self'].layer1, '1').conv1", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___conv1', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___conv1', 'getattr_L__self___layer1___1___conv1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 56, 56)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 56, 56]), dtype=torch.float32, requires_grad=False, stride=(200704, 3136, 56, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': '_native_batch_norm_legit_no_training_3', 'op': 'call_function', 'target': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, '_input_nodes': {convolution_3: None, arg10_1: None, arg11_1: None, arg71_1: None, arg72_1: None}, '_args': (convolution_3, arg10_1, arg11_1, arg71_1, arg72_1, 0.1, 1e-05), '_kwargs': {}, 'users': {getitem_11: None}, 'type': None, '_prev': convolution_3, '_next': getitem_11, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___bn1': ("getattr(L['self'].layer1, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___bn1', 'getattr_L__self___layer1___1___bn1')], 'seq_nr': 123, 'val': (FakeTensor(..., size=(1, 64, 56, 56)), FakeTensor(..., size=(0,)), FakeTensor(..., size=(0,)))}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'getitem_11', 'op': 'call_function', 'target': <built-in function getitem>, '_input_nodes': {_native_batch_norm_legit_no_training_3: None}, '_args': (_native_batch_norm_legit_no_training_3, 0), '_kwargs': {}, 'users': {relu_3: None}, 'type': None, '_prev': _native_batch_norm_legit_no_training_3, '_next': relu_3, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___bn1': ("getattr(L['self'].layer1, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___bn1', 'getattr_L__self___layer1___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 56, 56)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 56, 56]), dtype=torch.float32, requires_grad=False, stride=(200704, 3136, 56, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'relu_3', 'op': 'call_function', 'target': <OpOverload(op='aten.relu', overload='default')>, '_input_nodes': {getitem_11: None}, '_args': (getitem_11,), '_kwargs': {}, 'users': {convolution_4: None}, 'type': None, '_prev': getitem_11, '_next': convolution_4, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 94, in forward\n    out = self.relu(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___relu': ("getattr(L['self'].layer1, '1').relu", <class 'torch.nn.modules.activation.ReLU'>)}, 'source_fn': ('getattr_l__self___layer1___1___relu', <class 'torch.nn.modules.activation.ReLU'>), 'original_aten': <OpOverload(op='aten.relu', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___relu', 'getattr_L__self___layer1___1___relu')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 56, 56)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 56, 56]), dtype=torch.float32, requires_grad=False, stride=(200704, 3136, 56, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'convolution_4', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {relu_3: None, arg12_1: None}, '_args': (relu_3, arg12_1, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_4: None}, 'type': None, '_prev': relu_3, '_next': _native_batch_norm_legit_no_training_4, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 96, in forward\n    out = self.conv2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___conv2': ("getattr(L['self'].layer1, '1').conv2", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___conv2', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___conv2', 'getattr_L__self___layer1___1___conv2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 56, 56)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 56, 56]), dtype=torch.float32, requires_grad=False, stride=(200704, 3136, 56, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': '_native_batch_norm_legit_no_training_4', 'op': 'call_function', 'target': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, '_input_nodes': {convolution_4: None, arg13_1: None, arg14_1: None, arg74_1: None, arg75_1: None}, '_args': (convolution_4, arg13_1, arg14_1, arg74_1, arg75_1, 0.1, 1e-05), '_kwargs': {}, 'users': {getitem_14: None}, 'type': None, '_prev': convolution_4, '_next': getitem_14, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___bn2': ("getattr(L['self'].layer1, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___bn2', 'getattr_L__self___layer1___1___bn2')], 'seq_nr': 123, 'val': (FakeTensor(..., size=(1, 64, 56, 56)), FakeTensor(..., size=(0,)), FakeTensor(..., size=(0,)))}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'getitem_14', 'op': 'call_function', 'target': <built-in function getitem>, '_input_nodes': {_native_batch_norm_legit_no_training_4: None}, '_args': (_native_batch_norm_legit_no_training_4, 0), '_kwargs': {}, 'users': {add_1: None}, 'type': None, '_prev': _native_batch_norm_legit_no_training_4, '_next': add_1, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___bn2': ("getattr(L['self'].layer1, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___bn2', 'getattr_L__self___layer1___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 56, 56)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 56, 56]), dtype=torch.float32, requires_grad=False, stride=(200704, 3136, 56, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'add_1', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {getitem_14: None, relu_2: None}, '_args': (getitem_14, relu_2), '_kwargs': {}, 'users': {relu_4: None}, 'type': None, '_prev': getitem_14, '_next': relu_4, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 102, in forward\n    out += identity\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>)}, 'source_fn': ('iadd_1', <built-in function iadd>), 'original_aten': <OpOverload(op='aten.add', overload='Tensor')>, 'from_node': [('iadd_1', <built-in function iadd>)], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 56, 56)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 56, 56]), dtype=torch.float32, requires_grad=False, stride=(200704, 3136, 56, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'relu_4', 'op': 'call_function', 'target': <OpOverload(op='aten.relu', overload='default')>, '_input_nodes': {add_1: None}, '_args': (add_1,), '_kwargs': {}, 'users': {convolution_5: None, convolution_7: None}, 'type': None, '_prev': add_1, '_next': convolution_5, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 103, in forward\n    out = self.relu(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___relu': ("getattr(L['self'].layer1, '1').relu", <class 'torch.nn.modules.activation.ReLU'>)}, 'source_fn': ('getattr_l__self___layer1___1___relu_1', <class 'torch.nn.modules.activation.ReLU'>), 'original_aten': <OpOverload(op='aten.relu', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___relu_1', 'getattr_L__self___layer1___1___relu')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 56, 56)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 56, 56]), dtype=torch.float32, requires_grad=False, stride=(200704, 3136, 56, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'convolution_5', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {relu_4: None, arg15_1: None}, '_args': (relu_4, arg15_1, None, [2, 2], [1, 1], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_5: None}, 'type': None, '_prev': relu_4, '_next': _native_batch_norm_legit_no_training_5, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 92, in forward\n    out = self.conv1(x)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___conv1': ("getattr(L['self'].layer2, '0').conv1", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___conv1', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___conv1', 'getattr_L__self___layer2___0___conv1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': '_native_batch_norm_legit_no_training_5', 'op': 'call_function', 'target': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, '_input_nodes': {convolution_5: None, arg16_1: None, arg17_1: None, arg77_1: None, arg78_1: None}, '_args': (convolution_5, arg16_1, arg17_1, arg77_1, arg78_1, 0.1, 1e-05), '_kwargs': {}, 'users': {getitem_17: None}, 'type': None, '_prev': convolution_5, '_next': getitem_17, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___bn1': ("getattr(L['self'].layer2, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___bn1', 'getattr_L__self___layer2___0___bn1')], 'seq_nr': 123, 'val': (FakeTensor(..., size=(1, 128, 28, 28)), FakeTensor(..., size=(0,)), FakeTensor(..., size=(0,)))}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'getitem_17', 'op': 'call_function', 'target': <built-in function getitem>, '_input_nodes': {_native_batch_norm_legit_no_training_5: None}, '_args': (_native_batch_norm_legit_no_training_5, 0), '_kwargs': {}, 'users': {relu_5: None}, 'type': None, '_prev': _native_batch_norm_legit_no_training_5, '_next': relu_5, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___bn1': ("getattr(L['self'].layer2, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___bn1', 'getattr_L__self___layer2___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'relu_5', 'op': 'call_function', 'target': <OpOverload(op='aten.relu', overload='default')>, '_input_nodes': {getitem_17: None}, '_args': (getitem_17,), '_kwargs': {}, 'users': {convolution_6: None}, 'type': None, '_prev': getitem_17, '_next': convolution_6, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 94, in forward\n    out = self.relu(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___relu': ("getattr(L['self'].layer2, '0').relu", <class 'torch.nn.modules.activation.ReLU'>)}, 'source_fn': ('getattr_l__self___layer2___0___relu', <class 'torch.nn.modules.activation.ReLU'>), 'original_aten': <OpOverload(op='aten.relu', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___relu', 'getattr_L__self___layer2___0___relu')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'convolution_6', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {relu_5: None, arg18_1: None}, '_args': (relu_5, arg18_1, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_6: None}, 'type': None, '_prev': relu_5, '_next': _native_batch_norm_legit_no_training_6, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 96, in forward\n    out = self.conv2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___conv2': ("getattr(L['self'].layer2, '0').conv2", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___conv2', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___conv2', 'getattr_L__self___layer2___0___conv2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': '_native_batch_norm_legit_no_training_6', 'op': 'call_function', 'target': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, '_input_nodes': {convolution_6: None, arg19_1: None, arg20_1: None, arg80_1: None, arg81_1: None}, '_args': (convolution_6, arg19_1, arg20_1, arg80_1, arg81_1, 0.1, 1e-05), '_kwargs': {}, 'users': {getitem_20: None}, 'type': None, '_prev': convolution_6, '_next': getitem_20, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___bn2': ("getattr(L['self'].layer2, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___bn2', 'getattr_L__self___layer2___0___bn2')], 'seq_nr': 123, 'val': (FakeTensor(..., size=(1, 128, 28, 28)), FakeTensor(..., size=(0,)), FakeTensor(..., size=(0,)))}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'getitem_20', 'op': 'call_function', 'target': <built-in function getitem>, '_input_nodes': {_native_batch_norm_legit_no_training_6: None}, '_args': (_native_batch_norm_legit_no_training_6, 0), '_kwargs': {}, 'users': {add_2: None}, 'type': None, '_prev': _native_batch_norm_legit_no_training_6, '_next': convolution_7, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___bn2': ("getattr(L['self'].layer2, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___bn2', 'getattr_L__self___layer2___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'convolution_7', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {relu_4: None, arg21_1: None}, '_args': (relu_4, arg21_1, None, [2, 2], [0, 0], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_7: None}, 'type': None, '_prev': getitem_20, '_next': _native_batch_norm_legit_no_training_7, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___downsample': ("getattr(L['self'].layer2, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer2___0___downsample_0': ("getattr(getattr(L['self'].layer2, '0').downsample, '0')", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___downsample_0', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___downsample_0', 'getattr_L__self___layer2___0___downsample_0')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': '_native_batch_norm_legit_no_training_7', 'op': 'call_function', 'target': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, '_input_nodes': {convolution_7: None, arg22_1: None, arg23_1: None, arg83_1: None, arg84_1: None}, '_args': (convolution_7, arg22_1, arg23_1, arg83_1, arg84_1, 0.1, 1e-05), '_kwargs': {}, 'users': {getitem_23: None}, 'type': None, '_prev': convolution_7, '_next': getitem_23, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___downsample': ("getattr(L['self'].layer2, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer2___0___downsample_1': ("getattr(getattr(L['self'].layer2, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___downsample_1', 'getattr_L__self___layer2___0___downsample_1')], 'seq_nr': 123, 'val': (FakeTensor(..., size=(1, 128, 28, 28)), FakeTensor(..., size=(0,)), FakeTensor(..., size=(0,)))}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'getitem_23', 'op': 'call_function', 'target': <built-in function getitem>, '_input_nodes': {_native_batch_norm_legit_no_training_7: None}, '_args': (_native_batch_norm_legit_no_training_7, 0), '_kwargs': {}, 'users': {add_2: None}, 'type': None, '_prev': _native_batch_norm_legit_no_training_7, '_next': add_2, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___downsample': ("getattr(L['self'].layer2, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer2___0___downsample_1': ("getattr(getattr(L['self'].layer2, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___downsample_1', 'getattr_L__self___layer2___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'add_2', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {getitem_20: None, getitem_23: None}, '_args': (getitem_20, getitem_23), '_kwargs': {}, 'users': {relu_6: None}, 'type': None, '_prev': getitem_23, '_next': relu_6, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 102, in forward\n    out += identity\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>)}, 'source_fn': ('iadd_2', <built-in function iadd>), 'original_aten': <OpOverload(op='aten.add', overload='Tensor')>, 'from_node': [('iadd_2', <built-in function iadd>)], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'relu_6', 'op': 'call_function', 'target': <OpOverload(op='aten.relu', overload='default')>, '_input_nodes': {add_2: None}, '_args': (add_2,), '_kwargs': {}, 'users': {convolution_8: None, add_3: None}, 'type': None, '_prev': add_2, '_next': convolution_8, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 103, in forward\n    out = self.relu(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___relu': ("getattr(L['self'].layer2, '0').relu", <class 'torch.nn.modules.activation.ReLU'>)}, 'source_fn': ('getattr_l__self___layer2___0___relu_1', <class 'torch.nn.modules.activation.ReLU'>), 'original_aten': <OpOverload(op='aten.relu', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___relu_1', 'getattr_L__self___layer2___0___relu')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'convolution_8', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {relu_6: None, arg24_1: None}, '_args': (relu_6, arg24_1, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_8: None}, 'type': None, '_prev': relu_6, '_next': _native_batch_norm_legit_no_training_8, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 92, in forward\n    out = self.conv1(x)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___conv1': ("getattr(L['self'].layer2, '1').conv1", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___conv1', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___conv1', 'getattr_L__self___layer2___1___conv1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': '_native_batch_norm_legit_no_training_8', 'op': 'call_function', 'target': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, '_input_nodes': {convolution_8: None, arg25_1: None, arg26_1: None, arg86_1: None, arg87_1: None}, '_args': (convolution_8, arg25_1, arg26_1, arg86_1, arg87_1, 0.1, 1e-05), '_kwargs': {}, 'users': {getitem_26: None}, 'type': None, '_prev': convolution_8, '_next': getitem_26, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___bn1': ("getattr(L['self'].layer2, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___bn1', 'getattr_L__self___layer2___1___bn1')], 'seq_nr': 123, 'val': (FakeTensor(..., size=(1, 128, 28, 28)), FakeTensor(..., size=(0,)), FakeTensor(..., size=(0,)))}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'getitem_26', 'op': 'call_function', 'target': <built-in function getitem>, '_input_nodes': {_native_batch_norm_legit_no_training_8: None}, '_args': (_native_batch_norm_legit_no_training_8, 0), '_kwargs': {}, 'users': {relu_7: None}, 'type': None, '_prev': _native_batch_norm_legit_no_training_8, '_next': relu_7, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___bn1': ("getattr(L['self'].layer2, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___bn1', 'getattr_L__self___layer2___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'relu_7', 'op': 'call_function', 'target': <OpOverload(op='aten.relu', overload='default')>, '_input_nodes': {getitem_26: None}, '_args': (getitem_26,), '_kwargs': {}, 'users': {convolution_9: None}, 'type': None, '_prev': getitem_26, '_next': convolution_9, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 94, in forward\n    out = self.relu(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___relu': ("getattr(L['self'].layer2, '1').relu", <class 'torch.nn.modules.activation.ReLU'>)}, 'source_fn': ('getattr_l__self___layer2___1___relu', <class 'torch.nn.modules.activation.ReLU'>), 'original_aten': <OpOverload(op='aten.relu', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___relu', 'getattr_L__self___layer2___1___relu')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'convolution_9', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {relu_7: None, arg27_1: None}, '_args': (relu_7, arg27_1, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_9: None}, 'type': None, '_prev': relu_7, '_next': _native_batch_norm_legit_no_training_9, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 96, in forward\n    out = self.conv2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___conv2': ("getattr(L['self'].layer2, '1').conv2", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___conv2', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___conv2', 'getattr_L__self___layer2___1___conv2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': '_native_batch_norm_legit_no_training_9', 'op': 'call_function', 'target': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, '_input_nodes': {convolution_9: None, arg28_1: None, arg29_1: None, arg89_1: None, arg90_1: None}, '_args': (convolution_9, arg28_1, arg29_1, arg89_1, arg90_1, 0.1, 1e-05), '_kwargs': {}, 'users': {getitem_29: None}, 'type': None, '_prev': convolution_9, '_next': getitem_29, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___bn2': ("getattr(L['self'].layer2, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___bn2', 'getattr_L__self___layer2___1___bn2')], 'seq_nr': 123, 'val': (FakeTensor(..., size=(1, 128, 28, 28)), FakeTensor(..., size=(0,)), FakeTensor(..., size=(0,)))}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'getitem_29', 'op': 'call_function', 'target': <built-in function getitem>, '_input_nodes': {_native_batch_norm_legit_no_training_9: None}, '_args': (_native_batch_norm_legit_no_training_9, 0), '_kwargs': {}, 'users': {add_3: None}, 'type': None, '_prev': _native_batch_norm_legit_no_training_9, '_next': add_3, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___bn2': ("getattr(L['self'].layer2, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___bn2', 'getattr_L__self___layer2___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'add_3', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {getitem_29: None, relu_6: None}, '_args': (getitem_29, relu_6), '_kwargs': {}, 'users': {relu_8: None}, 'type': None, '_prev': getitem_29, '_next': relu_8, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 102, in forward\n    out += identity\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>)}, 'source_fn': ('iadd_3', <built-in function iadd>), 'original_aten': <OpOverload(op='aten.add', overload='Tensor')>, 'from_node': [('iadd_3', <built-in function iadd>)], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'relu_8', 'op': 'call_function', 'target': <OpOverload(op='aten.relu', overload='default')>, '_input_nodes': {add_3: None}, '_args': (add_3,), '_kwargs': {}, 'users': {convolution_10: None, convolution_12: None}, 'type': None, '_prev': add_3, '_next': convolution_10, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 103, in forward\n    out = self.relu(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___relu': ("getattr(L['self'].layer2, '1').relu", <class 'torch.nn.modules.activation.ReLU'>)}, 'source_fn': ('getattr_l__self___layer2___1___relu_1', <class 'torch.nn.modules.activation.ReLU'>), 'original_aten': <OpOverload(op='aten.relu', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___relu_1', 'getattr_L__self___layer2___1___relu')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'convolution_10', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {relu_8: None, arg30_1: None}, '_args': (relu_8, arg30_1, None, [2, 2], [1, 1], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_10: None}, 'type': None, '_prev': relu_8, '_next': _native_batch_norm_legit_no_training_10, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 92, in forward\n    out = self.conv1(x)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___conv1': ("getattr(L['self'].layer3, '0').conv1", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___conv1', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___conv1', 'getattr_L__self___layer3___0___conv1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': '_native_batch_norm_legit_no_training_10', 'op': 'call_function', 'target': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, '_input_nodes': {convolution_10: None, arg31_1: None, arg32_1: None, arg92_1: None, arg93_1: None}, '_args': (convolution_10, arg31_1, arg32_1, arg92_1, arg93_1, 0.1, 1e-05), '_kwargs': {}, 'users': {getitem_32: None}, 'type': None, '_prev': convolution_10, '_next': getitem_32, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___bn1': ("getattr(L['self'].layer3, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___bn1', 'getattr_L__self___layer3___0___bn1')], 'seq_nr': 123, 'val': (FakeTensor(..., size=(1, 256, 14, 14)), FakeTensor(..., size=(0,)), FakeTensor(..., size=(0,)))}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'getitem_32', 'op': 'call_function', 'target': <built-in function getitem>, '_input_nodes': {_native_batch_norm_legit_no_training_10: None}, '_args': (_native_batch_norm_legit_no_training_10, 0), '_kwargs': {}, 'users': {relu_9: None}, 'type': None, '_prev': _native_batch_norm_legit_no_training_10, '_next': relu_9, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___bn1': ("getattr(L['self'].layer3, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___bn1', 'getattr_L__self___layer3___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'relu_9', 'op': 'call_function', 'target': <OpOverload(op='aten.relu', overload='default')>, '_input_nodes': {getitem_32: None}, '_args': (getitem_32,), '_kwargs': {}, 'users': {convolution_11: None}, 'type': None, '_prev': getitem_32, '_next': convolution_11, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 94, in forward\n    out = self.relu(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___relu': ("getattr(L['self'].layer3, '0').relu", <class 'torch.nn.modules.activation.ReLU'>)}, 'source_fn': ('getattr_l__self___layer3___0___relu', <class 'torch.nn.modules.activation.ReLU'>), 'original_aten': <OpOverload(op='aten.relu', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___relu', 'getattr_L__self___layer3___0___relu')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'convolution_11', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {relu_9: None, arg33_1: None}, '_args': (relu_9, arg33_1, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_11: None}, 'type': None, '_prev': relu_9, '_next': _native_batch_norm_legit_no_training_11, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 96, in forward\n    out = self.conv2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___conv2': ("getattr(L['self'].layer3, '0').conv2", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___conv2', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___conv2', 'getattr_L__self___layer3___0___conv2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': '_native_batch_norm_legit_no_training_11', 'op': 'call_function', 'target': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, '_input_nodes': {convolution_11: None, arg34_1: None, arg35_1: None, arg95_1: None, arg96_1: None}, '_args': (convolution_11, arg34_1, arg35_1, arg95_1, arg96_1, 0.1, 1e-05), '_kwargs': {}, 'users': {getitem_35: None}, 'type': None, '_prev': convolution_11, '_next': getitem_35, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___bn2': ("getattr(L['self'].layer3, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___bn2', 'getattr_L__self___layer3___0___bn2')], 'seq_nr': 123, 'val': (FakeTensor(..., size=(1, 256, 14, 14)), FakeTensor(..., size=(0,)), FakeTensor(..., size=(0,)))}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'getitem_35', 'op': 'call_function', 'target': <built-in function getitem>, '_input_nodes': {_native_batch_norm_legit_no_training_11: None}, '_args': (_native_batch_norm_legit_no_training_11, 0), '_kwargs': {}, 'users': {add_4: None}, 'type': None, '_prev': _native_batch_norm_legit_no_training_11, '_next': convolution_12, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___bn2': ("getattr(L['self'].layer3, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___bn2', 'getattr_L__self___layer3___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'convolution_12', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {relu_8: None, arg36_1: None}, '_args': (relu_8, arg36_1, None, [2, 2], [0, 0], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_12: None}, 'type': None, '_prev': getitem_35, '_next': _native_batch_norm_legit_no_training_12, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___downsample': ("getattr(L['self'].layer3, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer3___0___downsample_0': ("getattr(getattr(L['self'].layer3, '0').downsample, '0')", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___downsample_0', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___downsample_0', 'getattr_L__self___layer3___0___downsample_0')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': '_native_batch_norm_legit_no_training_12', 'op': 'call_function', 'target': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, '_input_nodes': {convolution_12: None, arg37_1: None, arg38_1: None, arg98_1: None, arg99_1: None}, '_args': (convolution_12, arg37_1, arg38_1, arg98_1, arg99_1, 0.1, 1e-05), '_kwargs': {}, 'users': {getitem_38: None}, 'type': None, '_prev': convolution_12, '_next': getitem_38, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___downsample': ("getattr(L['self'].layer3, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer3___0___downsample_1': ("getattr(getattr(L['self'].layer3, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___downsample_1', 'getattr_L__self___layer3___0___downsample_1')], 'seq_nr': 123, 'val': (FakeTensor(..., size=(1, 256, 14, 14)), FakeTensor(..., size=(0,)), FakeTensor(..., size=(0,)))}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'getitem_38', 'op': 'call_function', 'target': <built-in function getitem>, '_input_nodes': {_native_batch_norm_legit_no_training_12: None}, '_args': (_native_batch_norm_legit_no_training_12, 0), '_kwargs': {}, 'users': {add_4: None}, 'type': None, '_prev': _native_batch_norm_legit_no_training_12, '_next': add_4, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___downsample': ("getattr(L['self'].layer3, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer3___0___downsample_1': ("getattr(getattr(L['self'].layer3, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___downsample_1', 'getattr_L__self___layer3___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'add_4', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {getitem_35: None, getitem_38: None}, '_args': (getitem_35, getitem_38), '_kwargs': {}, 'users': {relu_10: None}, 'type': None, '_prev': getitem_38, '_next': relu_10, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 102, in forward\n    out += identity\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>)}, 'source_fn': ('iadd_4', <built-in function iadd>), 'original_aten': <OpOverload(op='aten.add', overload='Tensor')>, 'from_node': [('iadd_4', <built-in function iadd>)], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'relu_10', 'op': 'call_function', 'target': <OpOverload(op='aten.relu', overload='default')>, '_input_nodes': {add_4: None}, '_args': (add_4,), '_kwargs': {}, 'users': {convolution_13: None, add_5: None}, 'type': None, '_prev': add_4, '_next': convolution_13, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 103, in forward\n    out = self.relu(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___relu': ("getattr(L['self'].layer3, '0').relu", <class 'torch.nn.modules.activation.ReLU'>)}, 'source_fn': ('getattr_l__self___layer3___0___relu_1', <class 'torch.nn.modules.activation.ReLU'>), 'original_aten': <OpOverload(op='aten.relu', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___relu_1', 'getattr_L__self___layer3___0___relu')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'convolution_13', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {relu_10: None, arg39_1: None}, '_args': (relu_10, arg39_1, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_13: None}, 'type': None, '_prev': relu_10, '_next': _native_batch_norm_legit_no_training_13, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 92, in forward\n    out = self.conv1(x)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___conv1': ("getattr(L['self'].layer3, '1').conv1", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___conv1', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___conv1', 'getattr_L__self___layer3___1___conv1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': '_native_batch_norm_legit_no_training_13', 'op': 'call_function', 'target': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, '_input_nodes': {convolution_13: None, arg40_1: None, arg41_1: None, arg101_1: None, arg102_1: None}, '_args': (convolution_13, arg40_1, arg41_1, arg101_1, arg102_1, 0.1, 1e-05), '_kwargs': {}, 'users': {getitem_41: None}, 'type': None, '_prev': convolution_13, '_next': getitem_41, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___bn1': ("getattr(L['self'].layer3, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___bn1', 'getattr_L__self___layer3___1___bn1')], 'seq_nr': 123, 'val': (FakeTensor(..., size=(1, 256, 14, 14)), FakeTensor(..., size=(0,)), FakeTensor(..., size=(0,)))}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'getitem_41', 'op': 'call_function', 'target': <built-in function getitem>, '_input_nodes': {_native_batch_norm_legit_no_training_13: None}, '_args': (_native_batch_norm_legit_no_training_13, 0), '_kwargs': {}, 'users': {relu_11: None}, 'type': None, '_prev': _native_batch_norm_legit_no_training_13, '_next': relu_11, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___bn1': ("getattr(L['self'].layer3, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___bn1', 'getattr_L__self___layer3___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'relu_11', 'op': 'call_function', 'target': <OpOverload(op='aten.relu', overload='default')>, '_input_nodes': {getitem_41: None}, '_args': (getitem_41,), '_kwargs': {}, 'users': {convolution_14: None}, 'type': None, '_prev': getitem_41, '_next': convolution_14, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 94, in forward\n    out = self.relu(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___relu': ("getattr(L['self'].layer3, '1').relu", <class 'torch.nn.modules.activation.ReLU'>)}, 'source_fn': ('getattr_l__self___layer3___1___relu', <class 'torch.nn.modules.activation.ReLU'>), 'original_aten': <OpOverload(op='aten.relu', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___relu', 'getattr_L__self___layer3___1___relu')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'convolution_14', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {relu_11: None, arg42_1: None}, '_args': (relu_11, arg42_1, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_14: None}, 'type': None, '_prev': relu_11, '_next': _native_batch_norm_legit_no_training_14, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 96, in forward\n    out = self.conv2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___conv2': ("getattr(L['self'].layer3, '1').conv2", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___conv2', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___conv2', 'getattr_L__self___layer3___1___conv2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': '_native_batch_norm_legit_no_training_14', 'op': 'call_function', 'target': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, '_input_nodes': {convolution_14: None, arg43_1: None, arg44_1: None, arg104_1: None, arg105_1: None}, '_args': (convolution_14, arg43_1, arg44_1, arg104_1, arg105_1, 0.1, 1e-05), '_kwargs': {}, 'users': {getitem_44: None}, 'type': None, '_prev': convolution_14, '_next': getitem_44, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___bn2': ("getattr(L['self'].layer3, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___bn2', 'getattr_L__self___layer3___1___bn2')], 'seq_nr': 123, 'val': (FakeTensor(..., size=(1, 256, 14, 14)), FakeTensor(..., size=(0,)), FakeTensor(..., size=(0,)))}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'getitem_44', 'op': 'call_function', 'target': <built-in function getitem>, '_input_nodes': {_native_batch_norm_legit_no_training_14: None}, '_args': (_native_batch_norm_legit_no_training_14, 0), '_kwargs': {}, 'users': {add_5: None}, 'type': None, '_prev': _native_batch_norm_legit_no_training_14, '_next': add_5, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___bn2': ("getattr(L['self'].layer3, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___bn2', 'getattr_L__self___layer3___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'add_5', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {getitem_44: None, relu_10: None}, '_args': (getitem_44, relu_10), '_kwargs': {}, 'users': {relu_12: None}, 'type': None, '_prev': getitem_44, '_next': relu_12, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 102, in forward\n    out += identity\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>)}, 'source_fn': ('iadd_5', <built-in function iadd>), 'original_aten': <OpOverload(op='aten.add', overload='Tensor')>, 'from_node': [('iadd_5', <built-in function iadd>)], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'relu_12', 'op': 'call_function', 'target': <OpOverload(op='aten.relu', overload='default')>, '_input_nodes': {add_5: None}, '_args': (add_5,), '_kwargs': {}, 'users': {convolution_15: None, convolution_17: None}, 'type': None, '_prev': add_5, '_next': convolution_15, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 103, in forward\n    out = self.relu(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___relu': ("getattr(L['self'].layer3, '1').relu", <class 'torch.nn.modules.activation.ReLU'>)}, 'source_fn': ('getattr_l__self___layer3___1___relu_1', <class 'torch.nn.modules.activation.ReLU'>), 'original_aten': <OpOverload(op='aten.relu', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___relu_1', 'getattr_L__self___layer3___1___relu')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'convolution_15', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {relu_12: None, arg45_1: None}, '_args': (relu_12, arg45_1, None, [2, 2], [1, 1], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_15: None}, 'type': None, '_prev': relu_12, '_next': _native_batch_norm_legit_no_training_15, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 92, in forward\n    out = self.conv1(x)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___conv1': ("getattr(L['self'].layer4, '0').conv1", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___conv1', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___conv1', 'getattr_L__self___layer4___0___conv1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': '_native_batch_norm_legit_no_training_15', 'op': 'call_function', 'target': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, '_input_nodes': {convolution_15: None, arg46_1: None, arg47_1: None, arg107_1: None, arg108_1: None}, '_args': (convolution_15, arg46_1, arg47_1, arg107_1, arg108_1, 0.1, 1e-05), '_kwargs': {}, 'users': {getitem_47: None}, 'type': None, '_prev': convolution_15, '_next': getitem_47, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___bn1': ("getattr(L['self'].layer4, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___bn1', 'getattr_L__self___layer4___0___bn1')], 'seq_nr': 123, 'val': (FakeTensor(..., size=(1, 512, 7, 7)), FakeTensor(..., size=(0,)), FakeTensor(..., size=(0,)))}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'getitem_47', 'op': 'call_function', 'target': <built-in function getitem>, '_input_nodes': {_native_batch_norm_legit_no_training_15: None}, '_args': (_native_batch_norm_legit_no_training_15, 0), '_kwargs': {}, 'users': {relu_13: None}, 'type': None, '_prev': _native_batch_norm_legit_no_training_15, '_next': relu_13, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___bn1': ("getattr(L['self'].layer4, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___bn1', 'getattr_L__self___layer4___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'relu_13', 'op': 'call_function', 'target': <OpOverload(op='aten.relu', overload='default')>, '_input_nodes': {getitem_47: None}, '_args': (getitem_47,), '_kwargs': {}, 'users': {convolution_16: None}, 'type': None, '_prev': getitem_47, '_next': convolution_16, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 94, in forward\n    out = self.relu(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___relu': ("getattr(L['self'].layer4, '0').relu", <class 'torch.nn.modules.activation.ReLU'>)}, 'source_fn': ('getattr_l__self___layer4___0___relu', <class 'torch.nn.modules.activation.ReLU'>), 'original_aten': <OpOverload(op='aten.relu', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___relu', 'getattr_L__self___layer4___0___relu')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'convolution_16', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {relu_13: None, arg48_1: None}, '_args': (relu_13, arg48_1, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_16: None}, 'type': None, '_prev': relu_13, '_next': _native_batch_norm_legit_no_training_16, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 96, in forward\n    out = self.conv2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___conv2': ("getattr(L['self'].layer4, '0').conv2", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___conv2', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___conv2', 'getattr_L__self___layer4___0___conv2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': '_native_batch_norm_legit_no_training_16', 'op': 'call_function', 'target': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, '_input_nodes': {convolution_16: None, arg49_1: None, arg50_1: None, arg110_1: None, arg111_1: None}, '_args': (convolution_16, arg49_1, arg50_1, arg110_1, arg111_1, 0.1, 1e-05), '_kwargs': {}, 'users': {getitem_50: None}, 'type': None, '_prev': convolution_16, '_next': getitem_50, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___bn2': ("getattr(L['self'].layer4, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___bn2', 'getattr_L__self___layer4___0___bn2')], 'seq_nr': 123, 'val': (FakeTensor(..., size=(1, 512, 7, 7)), FakeTensor(..., size=(0,)), FakeTensor(..., size=(0,)))}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'getitem_50', 'op': 'call_function', 'target': <built-in function getitem>, '_input_nodes': {_native_batch_norm_legit_no_training_16: None}, '_args': (_native_batch_norm_legit_no_training_16, 0), '_kwargs': {}, 'users': {add_6: None}, 'type': None, '_prev': _native_batch_norm_legit_no_training_16, '_next': convolution_17, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___bn2': ("getattr(L['self'].layer4, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___bn2', 'getattr_L__self___layer4___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'convolution_17', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {relu_12: None, arg51_1: None}, '_args': (relu_12, arg51_1, None, [2, 2], [0, 0], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_17: None}, 'type': None, '_prev': getitem_50, '_next': _native_batch_norm_legit_no_training_17, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___downsample': ("getattr(L['self'].layer4, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer4___0___downsample_0': ("getattr(getattr(L['self'].layer4, '0').downsample, '0')", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___downsample_0', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___downsample_0', 'getattr_L__self___layer4___0___downsample_0')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': '_native_batch_norm_legit_no_training_17', 'op': 'call_function', 'target': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, '_input_nodes': {convolution_17: None, arg52_1: None, arg53_1: None, arg113_1: None, arg114_1: None}, '_args': (convolution_17, arg52_1, arg53_1, arg113_1, arg114_1, 0.1, 1e-05), '_kwargs': {}, 'users': {getitem_53: None}, 'type': None, '_prev': convolution_17, '_next': getitem_53, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___downsample': ("getattr(L['self'].layer4, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer4___0___downsample_1': ("getattr(getattr(L['self'].layer4, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___downsample_1', 'getattr_L__self___layer4___0___downsample_1')], 'seq_nr': 123, 'val': (FakeTensor(..., size=(1, 512, 7, 7)), FakeTensor(..., size=(0,)), FakeTensor(..., size=(0,)))}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'getitem_53', 'op': 'call_function', 'target': <built-in function getitem>, '_input_nodes': {_native_batch_norm_legit_no_training_17: None}, '_args': (_native_batch_norm_legit_no_training_17, 0), '_kwargs': {}, 'users': {add_6: None}, 'type': None, '_prev': _native_batch_norm_legit_no_training_17, '_next': add_6, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___downsample': ("getattr(L['self'].layer4, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer4___0___downsample_1': ("getattr(getattr(L['self'].layer4, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___downsample_1', 'getattr_L__self___layer4___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'add_6', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {getitem_50: None, getitem_53: None}, '_args': (getitem_50, getitem_53), '_kwargs': {}, 'users': {relu_14: None}, 'type': None, '_prev': getitem_53, '_next': relu_14, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 102, in forward\n    out += identity\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>)}, 'source_fn': ('iadd_6', <built-in function iadd>), 'original_aten': <OpOverload(op='aten.add', overload='Tensor')>, 'from_node': [('iadd_6', <built-in function iadd>)], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'relu_14', 'op': 'call_function', 'target': <OpOverload(op='aten.relu', overload='default')>, '_input_nodes': {add_6: None}, '_args': (add_6,), '_kwargs': {}, 'users': {convolution_18: None, add_7: None}, 'type': None, '_prev': add_6, '_next': convolution_18, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 103, in forward\n    out = self.relu(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___relu': ("getattr(L['self'].layer4, '0').relu", <class 'torch.nn.modules.activation.ReLU'>)}, 'source_fn': ('getattr_l__self___layer4___0___relu_1', <class 'torch.nn.modules.activation.ReLU'>), 'original_aten': <OpOverload(op='aten.relu', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___relu_1', 'getattr_L__self___layer4___0___relu')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'convolution_18', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {relu_14: None, arg54_1: None}, '_args': (relu_14, arg54_1, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_18: None}, 'type': None, '_prev': relu_14, '_next': _native_batch_norm_legit_no_training_18, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 92, in forward\n    out = self.conv1(x)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___conv1': ("getattr(L['self'].layer4, '1').conv1", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___conv1', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___conv1', 'getattr_L__self___layer4___1___conv1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': '_native_batch_norm_legit_no_training_18', 'op': 'call_function', 'target': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, '_input_nodes': {convolution_18: None, arg55_1: None, arg56_1: None, arg116_1: None, arg117_1: None}, '_args': (convolution_18, arg55_1, arg56_1, arg116_1, arg117_1, 0.1, 1e-05), '_kwargs': {}, 'users': {getitem_56: None}, 'type': None, '_prev': convolution_18, '_next': getitem_56, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___bn1': ("getattr(L['self'].layer4, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___bn1', 'getattr_L__self___layer4___1___bn1')], 'seq_nr': 123, 'val': (FakeTensor(..., size=(1, 512, 7, 7)), FakeTensor(..., size=(0,)), FakeTensor(..., size=(0,)))}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'getitem_56', 'op': 'call_function', 'target': <built-in function getitem>, '_input_nodes': {_native_batch_norm_legit_no_training_18: None}, '_args': (_native_batch_norm_legit_no_training_18, 0), '_kwargs': {}, 'users': {relu_15: None}, 'type': None, '_prev': _native_batch_norm_legit_no_training_18, '_next': relu_15, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___bn1': ("getattr(L['self'].layer4, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___bn1', 'getattr_L__self___layer4___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'relu_15', 'op': 'call_function', 'target': <OpOverload(op='aten.relu', overload='default')>, '_input_nodes': {getitem_56: None}, '_args': (getitem_56,), '_kwargs': {}, 'users': {convolution_19: None}, 'type': None, '_prev': getitem_56, '_next': convolution_19, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 94, in forward\n    out = self.relu(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___relu': ("getattr(L['self'].layer4, '1').relu", <class 'torch.nn.modules.activation.ReLU'>)}, 'source_fn': ('getattr_l__self___layer4___1___relu', <class 'torch.nn.modules.activation.ReLU'>), 'original_aten': <OpOverload(op='aten.relu', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___relu', 'getattr_L__self___layer4___1___relu')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'convolution_19', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {relu_15: None, arg57_1: None}, '_args': (relu_15, arg57_1, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {_native_batch_norm_legit_no_training_19: None}, 'type': None, '_prev': relu_15, '_next': _native_batch_norm_legit_no_training_19, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 96, in forward\n    out = self.conv2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___conv2': ("getattr(L['self'].layer4, '1').conv2", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___conv2', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___conv2', 'getattr_L__self___layer4___1___conv2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': '_native_batch_norm_legit_no_training_19', 'op': 'call_function', 'target': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, '_input_nodes': {convolution_19: None, arg58_1: None, arg59_1: None, arg119_1: None, arg120_1: None}, '_args': (convolution_19, arg58_1, arg59_1, arg119_1, arg120_1, 0.1, 1e-05), '_kwargs': {}, 'users': {getitem_59: None}, 'type': None, '_prev': convolution_19, '_next': getitem_59, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___bn2': ("getattr(L['self'].layer4, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___bn2', 'getattr_L__self___layer4___1___bn2')], 'seq_nr': 123, 'val': (FakeTensor(..., size=(1, 512, 7, 7)), FakeTensor(..., size=(0,)), FakeTensor(..., size=(0,)))}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'getitem_59', 'op': 'call_function', 'target': <built-in function getitem>, '_input_nodes': {_native_batch_norm_legit_no_training_19: None}, '_args': (_native_batch_norm_legit_no_training_19, 0), '_kwargs': {}, 'users': {add_7: None}, 'type': None, '_prev': _native_batch_norm_legit_no_training_19, '_next': add_7, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___bn2': ("getattr(L['self'].layer4, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___bn2', 'getattr_L__self___layer4___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'add_7', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {getitem_59: None, relu_14: None}, '_args': (getitem_59, relu_14), '_kwargs': {}, 'users': {relu_16: None}, 'type': None, '_prev': getitem_59, '_next': relu_16, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 102, in forward\n    out += identity\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>)}, 'source_fn': ('iadd_7', <built-in function iadd>), 'original_aten': <OpOverload(op='aten.add', overload='Tensor')>, 'from_node': [('iadd_7', <built-in function iadd>)], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'relu_16', 'op': 'call_function', 'target': <OpOverload(op='aten.relu', overload='default')>, '_input_nodes': {add_7: None}, '_args': (add_7,), '_kwargs': {}, 'users': {mean: None}, 'type': None, '_prev': add_7, '_next': mean, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 103, in forward\n    out = self.relu(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___relu': ("getattr(L['self'].layer4, '1').relu", <class 'torch.nn.modules.activation.ReLU'>)}, 'source_fn': ('getattr_l__self___layer4___1___relu_1', <class 'torch.nn.modules.activation.ReLU'>), 'original_aten': <OpOverload(op='aten.relu', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___relu_1', 'getattr_L__self___layer4___1___relu')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'mean', 'op': 'call_function', 'target': <OpOverload(op='aten.mean', overload='dim')>, '_input_nodes': {relu_16: None}, '_args': (relu_16, [-1, -2], True), '_kwargs': {}, 'users': {view: None}, 'type': None, '_prev': relu_16, '_next': view, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 278, in _forward_impl\n    x = self.avgpool(x)\n', 'nn_module_stack': {'L__self___avgpool': ("L['self'].avgpool", <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>)}, 'source_fn': ('l__self___avgpool', <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>), 'original_aten': <OpOverload(op='aten.mean', overload='dim')>, 'from_node': [('l__self___avgpool', 'L__self___avgpool')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(512, 1, 1, 1), memory_format=torch.channels_last, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'view', 'op': 'call_function', 'target': <OpOverload(op='aten.view', overload='default')>, '_input_nodes': {mean: None}, '_args': (mean, [1, 512]), '_kwargs': {}, 'users': {addmm: None}, 'type': None, '_prev': mean, '_next': t, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 279, in _forward_impl\n    x = torch.flatten(x, 1)\n', 'source_fn': ('flatten', <built-in method flatten of type object at 0x7f348f46ca40>), 'original_aten': <OpOverload(op='aten.view', overload='default')>, 'from_node': [('flatten', <built-in method flatten of type object at 0x7f348f46ca40>)], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512]), dtype=torch.float32, requires_grad=False, stride=(512, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 't', 'op': 'call_function', 'target': <OpOverload(op='aten.t', overload='default')>, '_input_nodes': {arg60_1: None}, '_args': (arg60_1,), '_kwargs': {}, 'users': {addmm: None}, 'type': None, '_prev': view, '_next': addmm, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 280, in _forward_impl\n    x = self.fc(x)\n', 'nn_module_stack': {'L__self___fc': ("L['self'].fc", <class 'torch.nn.modules.linear.Linear'>)}, 'source_fn': ('l__self___fc', <class 'torch.nn.modules.linear.Linear'>), 'original_aten': <OpOverload(op='aten.t', overload='default')>, 'from_node': [('l__self___fc', 'L__self___fc')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512, 1000)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 1000]), dtype=torch.float32, requires_grad=False, stride=(1, 512), memory_format=None, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'addmm', 'op': 'call_function', 'target': <OpOverload(op='aten.addmm', overload='default')>, '_input_nodes': {arg61_1: None, view: None, t: None}, '_args': (arg61_1, view, t), '_kwargs': {}, 'users': {output: None}, 'type': None, '_prev': t, '_next': output, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 280, in _forward_impl\n    x = self.fc(x)\n', 'nn_module_stack': {'L__self___fc': ("L['self'].fc", <class 'torch.nn.modules.linear.Linear'>)}, 'source_fn': ('l__self___fc', <class 'torch.nn.modules.linear.Linear'>), 'original_aten': <OpOverload(op='aten.addmm', overload='default')>, 'from_node': [('l__self___fc', 'L__self___fc')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 1000)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 1000]), dtype=torch.float32, requires_grad=False, stride=(1000, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f33faa13250>, 'name': 'output', 'op': 'output', 'target': 'output', '_input_nodes': {addmm: None}, '_args': ((addmm,),), '_kwargs': {}, 'users': {}, 'type': None, '_prev': addmm, '_next': , '_erased': False, '_repr_fn': None, 'meta': {}}
