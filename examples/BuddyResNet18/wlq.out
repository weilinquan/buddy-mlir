{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg0_1', 'op': 'placeholder', 'target': 'arg0_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution: None}, 'type': None, '_prev': , '_next': arg1_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64, 3, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 3, 7, 7]), dtype=torch.float32, requires_grad=True, stride=(147, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg1_1', 'op': 'placeholder', 'target': 'arg1_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {unsqueeze_4: None}, 'type': None, '_prev': arg0_1, '_next': arg2_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg2_1', 'op': 'placeholder', 'target': 'arg2_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {unsqueeze_6: None}, 'type': None, '_prev': arg1_1, '_next': arg3_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg3_1', 'op': 'placeholder', 'target': 'arg3_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_1: None}, 'type': None, '_prev': arg2_1, '_next': arg4_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64, 64, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 64, 3, 3]), dtype=torch.float32, requires_grad=True, stride=(576, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg4_1', 'op': 'placeholder', 'target': 'arg4_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {unsqueeze_12: None}, 'type': None, '_prev': arg3_1, '_next': arg5_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg5_1', 'op': 'placeholder', 'target': 'arg5_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {unsqueeze_14: None}, 'type': None, '_prev': arg4_1, '_next': arg6_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg6_1', 'op': 'placeholder', 'target': 'arg6_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_2: None}, 'type': None, '_prev': arg5_1, '_next': arg7_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64, 64, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 64, 3, 3]), dtype=torch.float32, requires_grad=True, stride=(576, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg7_1', 'op': 'placeholder', 'target': 'arg7_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {unsqueeze_20: None}, 'type': None, '_prev': arg6_1, '_next': arg8_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg8_1', 'op': 'placeholder', 'target': 'arg8_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {unsqueeze_22: None}, 'type': None, '_prev': arg7_1, '_next': arg9_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg9_1', 'op': 'placeholder', 'target': 'arg9_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_3: None}, 'type': None, '_prev': arg8_1, '_next': arg10_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64, 64, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 64, 3, 3]), dtype=torch.float32, requires_grad=True, stride=(576, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg10_1', 'op': 'placeholder', 'target': 'arg10_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {unsqueeze_28: None}, 'type': None, '_prev': arg9_1, '_next': arg11_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg11_1', 'op': 'placeholder', 'target': 'arg11_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {unsqueeze_30: None}, 'type': None, '_prev': arg10_1, '_next': arg12_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg12_1', 'op': 'placeholder', 'target': 'arg12_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_4: None}, 'type': None, '_prev': arg11_1, '_next': arg13_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64, 64, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 64, 3, 3]), dtype=torch.float32, requires_grad=True, stride=(576, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg13_1', 'op': 'placeholder', 'target': 'arg13_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {unsqueeze_36: None}, 'type': None, '_prev': arg12_1, '_next': arg14_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg14_1', 'op': 'placeholder', 'target': 'arg14_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {unsqueeze_38: None}, 'type': None, '_prev': arg13_1, '_next': arg15_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg15_1', 'op': 'placeholder', 'target': 'arg15_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_5: None}, 'type': None, '_prev': arg14_1, '_next': arg16_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128, 64, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 64, 3, 3]), dtype=torch.float32, requires_grad=True, stride=(576, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg16_1', 'op': 'placeholder', 'target': 'arg16_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {unsqueeze_44: None}, 'type': None, '_prev': arg15_1, '_next': arg17_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg17_1', 'op': 'placeholder', 'target': 'arg17_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {unsqueeze_46: None}, 'type': None, '_prev': arg16_1, '_next': arg18_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg18_1', 'op': 'placeholder', 'target': 'arg18_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_6: None}, 'type': None, '_prev': arg17_1, '_next': arg19_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128, 128, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 128, 3, 3]), dtype=torch.float32, requires_grad=True, stride=(1152, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg19_1', 'op': 'placeholder', 'target': 'arg19_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {unsqueeze_52: None}, 'type': None, '_prev': arg18_1, '_next': arg20_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg20_1', 'op': 'placeholder', 'target': 'arg20_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {unsqueeze_54: None}, 'type': None, '_prev': arg19_1, '_next': arg21_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg21_1', 'op': 'placeholder', 'target': 'arg21_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_7: None}, 'type': None, '_prev': arg20_1, '_next': arg22_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128, 64, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 64, 1, 1]), dtype=torch.float32, requires_grad=True, stride=(64, 1, 1, 1), memory_format=torch.channels_last, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg22_1', 'op': 'placeholder', 'target': 'arg22_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {unsqueeze_60: None}, 'type': None, '_prev': arg21_1, '_next': arg23_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg23_1', 'op': 'placeholder', 'target': 'arg23_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {unsqueeze_62: None}, 'type': None, '_prev': arg22_1, '_next': arg24_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg24_1', 'op': 'placeholder', 'target': 'arg24_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_8: None}, 'type': None, '_prev': arg23_1, '_next': arg25_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128, 128, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 128, 3, 3]), dtype=torch.float32, requires_grad=True, stride=(1152, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg25_1', 'op': 'placeholder', 'target': 'arg25_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {unsqueeze_68: None}, 'type': None, '_prev': arg24_1, '_next': arg26_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg26_1', 'op': 'placeholder', 'target': 'arg26_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {unsqueeze_70: None}, 'type': None, '_prev': arg25_1, '_next': arg27_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg27_1', 'op': 'placeholder', 'target': 'arg27_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_9: None}, 'type': None, '_prev': arg26_1, '_next': arg28_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128, 128, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 128, 3, 3]), dtype=torch.float32, requires_grad=True, stride=(1152, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg28_1', 'op': 'placeholder', 'target': 'arg28_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {unsqueeze_76: None}, 'type': None, '_prev': arg27_1, '_next': arg29_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg29_1', 'op': 'placeholder', 'target': 'arg29_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {unsqueeze_78: None}, 'type': None, '_prev': arg28_1, '_next': arg30_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg30_1', 'op': 'placeholder', 'target': 'arg30_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_10: None}, 'type': None, '_prev': arg29_1, '_next': arg31_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256, 128, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 128, 3, 3]), dtype=torch.float32, requires_grad=True, stride=(1152, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg31_1', 'op': 'placeholder', 'target': 'arg31_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {unsqueeze_84: None}, 'type': None, '_prev': arg30_1, '_next': arg32_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg32_1', 'op': 'placeholder', 'target': 'arg32_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {unsqueeze_86: None}, 'type': None, '_prev': arg31_1, '_next': arg33_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg33_1', 'op': 'placeholder', 'target': 'arg33_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_11: None}, 'type': None, '_prev': arg32_1, '_next': arg34_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256, 256, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 256, 3, 3]), dtype=torch.float32, requires_grad=True, stride=(2304, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg34_1', 'op': 'placeholder', 'target': 'arg34_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {unsqueeze_92: None}, 'type': None, '_prev': arg33_1, '_next': arg35_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg35_1', 'op': 'placeholder', 'target': 'arg35_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {unsqueeze_94: None}, 'type': None, '_prev': arg34_1, '_next': arg36_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg36_1', 'op': 'placeholder', 'target': 'arg36_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_12: None}, 'type': None, '_prev': arg35_1, '_next': arg37_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256, 128, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 128, 1, 1]), dtype=torch.float32, requires_grad=True, stride=(128, 1, 1, 1), memory_format=torch.channels_last, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg37_1', 'op': 'placeholder', 'target': 'arg37_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {unsqueeze_100: None}, 'type': None, '_prev': arg36_1, '_next': arg38_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg38_1', 'op': 'placeholder', 'target': 'arg38_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {unsqueeze_102: None}, 'type': None, '_prev': arg37_1, '_next': arg39_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg39_1', 'op': 'placeholder', 'target': 'arg39_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_13: None}, 'type': None, '_prev': arg38_1, '_next': arg40_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256, 256, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 256, 3, 3]), dtype=torch.float32, requires_grad=True, stride=(2304, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg40_1', 'op': 'placeholder', 'target': 'arg40_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {unsqueeze_108: None}, 'type': None, '_prev': arg39_1, '_next': arg41_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg41_1', 'op': 'placeholder', 'target': 'arg41_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {unsqueeze_110: None}, 'type': None, '_prev': arg40_1, '_next': arg42_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg42_1', 'op': 'placeholder', 'target': 'arg42_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_14: None}, 'type': None, '_prev': arg41_1, '_next': arg43_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256, 256, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 256, 3, 3]), dtype=torch.float32, requires_grad=True, stride=(2304, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg43_1', 'op': 'placeholder', 'target': 'arg43_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {unsqueeze_116: None}, 'type': None, '_prev': arg42_1, '_next': arg44_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg44_1', 'op': 'placeholder', 'target': 'arg44_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {unsqueeze_118: None}, 'type': None, '_prev': arg43_1, '_next': arg45_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg45_1', 'op': 'placeholder', 'target': 'arg45_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_15: None}, 'type': None, '_prev': arg44_1, '_next': arg46_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512, 256, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 256, 3, 3]), dtype=torch.float32, requires_grad=True, stride=(2304, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg46_1', 'op': 'placeholder', 'target': 'arg46_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {unsqueeze_124: None}, 'type': None, '_prev': arg45_1, '_next': arg47_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg47_1', 'op': 'placeholder', 'target': 'arg47_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {unsqueeze_126: None}, 'type': None, '_prev': arg46_1, '_next': arg48_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg48_1', 'op': 'placeholder', 'target': 'arg48_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_16: None}, 'type': None, '_prev': arg47_1, '_next': arg49_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512, 512, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 512, 3, 3]), dtype=torch.float32, requires_grad=True, stride=(4608, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg49_1', 'op': 'placeholder', 'target': 'arg49_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {unsqueeze_132: None}, 'type': None, '_prev': arg48_1, '_next': arg50_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg50_1', 'op': 'placeholder', 'target': 'arg50_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {unsqueeze_134: None}, 'type': None, '_prev': arg49_1, '_next': arg51_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg51_1', 'op': 'placeholder', 'target': 'arg51_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_17: None}, 'type': None, '_prev': arg50_1, '_next': arg52_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512, 256, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 256, 1, 1]), dtype=torch.float32, requires_grad=True, stride=(256, 1, 1, 1), memory_format=torch.channels_last, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg52_1', 'op': 'placeholder', 'target': 'arg52_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {unsqueeze_140: None}, 'type': None, '_prev': arg51_1, '_next': arg53_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg53_1', 'op': 'placeholder', 'target': 'arg53_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {unsqueeze_142: None}, 'type': None, '_prev': arg52_1, '_next': arg54_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg54_1', 'op': 'placeholder', 'target': 'arg54_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_18: None}, 'type': None, '_prev': arg53_1, '_next': arg55_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512, 512, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 512, 3, 3]), dtype=torch.float32, requires_grad=True, stride=(4608, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg55_1', 'op': 'placeholder', 'target': 'arg55_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {unsqueeze_148: None}, 'type': None, '_prev': arg54_1, '_next': arg56_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg56_1', 'op': 'placeholder', 'target': 'arg56_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {unsqueeze_150: None}, 'type': None, '_prev': arg55_1, '_next': arg57_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg57_1', 'op': 'placeholder', 'target': 'arg57_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution_19: None}, 'type': None, '_prev': arg56_1, '_next': arg58_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512, 512, 3, 3)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 512, 3, 3]), dtype=torch.float32, requires_grad=True, stride=(4608, 9, 3, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg58_1', 'op': 'placeholder', 'target': 'arg58_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {unsqueeze_156: None}, 'type': None, '_prev': arg57_1, '_next': arg59_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg59_1', 'op': 'placeholder', 'target': 'arg59_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {unsqueeze_158: None}, 'type': None, '_prev': arg58_1, '_next': arg60_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg60_1', 'op': 'placeholder', 'target': 'arg60_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {permute: None}, 'type': None, '_prev': arg59_1, '_next': arg61_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(1000, 512)), 'tensor_meta': TensorMetadata(shape=torch.Size([1000, 512]), dtype=torch.float32, requires_grad=True, stride=(512, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg61_1', 'op': 'placeholder', 'target': 'arg61_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {addmm: None}, 'type': None, '_prev': arg60_1, '_next': arg62_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(1000,)), 'tensor_meta': TensorMetadata(shape=torch.Size([1000]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg62_1', 'op': 'placeholder', 'target': 'arg62_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convert_element_type: None}, 'type': None, '_prev': arg61_1, '_next': arg63_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg63_1', 'op': 'placeholder', 'target': 'arg63_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convert_element_type_1: None}, 'type': None, '_prev': arg62_1, '_next': arg64_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg64_1', 'op': 'placeholder', 'target': 'arg64_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {}, 'type': None, '_prev': arg63_1, '_next': arg65_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.int64, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg65_1', 'op': 'placeholder', 'target': 'arg65_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convert_element_type_2: None}, 'type': None, '_prev': arg64_1, '_next': arg66_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg66_1', 'op': 'placeholder', 'target': 'arg66_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convert_element_type_3: None}, 'type': None, '_prev': arg65_1, '_next': arg67_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg67_1', 'op': 'placeholder', 'target': 'arg67_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {}, 'type': None, '_prev': arg66_1, '_next': arg68_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.int64, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg68_1', 'op': 'placeholder', 'target': 'arg68_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convert_element_type_4: None}, 'type': None, '_prev': arg67_1, '_next': arg69_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg69_1', 'op': 'placeholder', 'target': 'arg69_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convert_element_type_5: None}, 'type': None, '_prev': arg68_1, '_next': arg70_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg70_1', 'op': 'placeholder', 'target': 'arg70_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {}, 'type': None, '_prev': arg69_1, '_next': arg71_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.int64, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg71_1', 'op': 'placeholder', 'target': 'arg71_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convert_element_type_6: None}, 'type': None, '_prev': arg70_1, '_next': arg72_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg72_1', 'op': 'placeholder', 'target': 'arg72_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convert_element_type_7: None}, 'type': None, '_prev': arg71_1, '_next': arg73_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg73_1', 'op': 'placeholder', 'target': 'arg73_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {}, 'type': None, '_prev': arg72_1, '_next': arg74_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.int64, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg74_1', 'op': 'placeholder', 'target': 'arg74_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convert_element_type_8: None}, 'type': None, '_prev': arg73_1, '_next': arg75_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg75_1', 'op': 'placeholder', 'target': 'arg75_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convert_element_type_9: None}, 'type': None, '_prev': arg74_1, '_next': arg76_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg76_1', 'op': 'placeholder', 'target': 'arg76_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {}, 'type': None, '_prev': arg75_1, '_next': arg77_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.int64, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg77_1', 'op': 'placeholder', 'target': 'arg77_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convert_element_type_10: None}, 'type': None, '_prev': arg76_1, '_next': arg78_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg78_1', 'op': 'placeholder', 'target': 'arg78_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convert_element_type_11: None}, 'type': None, '_prev': arg77_1, '_next': arg79_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg79_1', 'op': 'placeholder', 'target': 'arg79_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {}, 'type': None, '_prev': arg78_1, '_next': arg80_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.int64, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg80_1', 'op': 'placeholder', 'target': 'arg80_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convert_element_type_12: None}, 'type': None, '_prev': arg79_1, '_next': arg81_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg81_1', 'op': 'placeholder', 'target': 'arg81_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convert_element_type_13: None}, 'type': None, '_prev': arg80_1, '_next': arg82_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg82_1', 'op': 'placeholder', 'target': 'arg82_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {}, 'type': None, '_prev': arg81_1, '_next': arg83_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.int64, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg83_1', 'op': 'placeholder', 'target': 'arg83_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convert_element_type_14: None}, 'type': None, '_prev': arg82_1, '_next': arg84_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg84_1', 'op': 'placeholder', 'target': 'arg84_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convert_element_type_15: None}, 'type': None, '_prev': arg83_1, '_next': arg85_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg85_1', 'op': 'placeholder', 'target': 'arg85_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {}, 'type': None, '_prev': arg84_1, '_next': arg86_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.int64, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg86_1', 'op': 'placeholder', 'target': 'arg86_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convert_element_type_16: None}, 'type': None, '_prev': arg85_1, '_next': arg87_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg87_1', 'op': 'placeholder', 'target': 'arg87_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convert_element_type_17: None}, 'type': None, '_prev': arg86_1, '_next': arg88_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg88_1', 'op': 'placeholder', 'target': 'arg88_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {}, 'type': None, '_prev': arg87_1, '_next': arg89_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.int64, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg89_1', 'op': 'placeholder', 'target': 'arg89_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convert_element_type_18: None}, 'type': None, '_prev': arg88_1, '_next': arg90_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg90_1', 'op': 'placeholder', 'target': 'arg90_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convert_element_type_19: None}, 'type': None, '_prev': arg89_1, '_next': arg91_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg91_1', 'op': 'placeholder', 'target': 'arg91_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {}, 'type': None, '_prev': arg90_1, '_next': arg92_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.int64, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg92_1', 'op': 'placeholder', 'target': 'arg92_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convert_element_type_20: None}, 'type': None, '_prev': arg91_1, '_next': arg93_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg93_1', 'op': 'placeholder', 'target': 'arg93_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convert_element_type_21: None}, 'type': None, '_prev': arg92_1, '_next': arg94_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg94_1', 'op': 'placeholder', 'target': 'arg94_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {}, 'type': None, '_prev': arg93_1, '_next': arg95_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.int64, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg95_1', 'op': 'placeholder', 'target': 'arg95_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convert_element_type_22: None}, 'type': None, '_prev': arg94_1, '_next': arg96_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg96_1', 'op': 'placeholder', 'target': 'arg96_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convert_element_type_23: None}, 'type': None, '_prev': arg95_1, '_next': arg97_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg97_1', 'op': 'placeholder', 'target': 'arg97_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {}, 'type': None, '_prev': arg96_1, '_next': arg98_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.int64, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg98_1', 'op': 'placeholder', 'target': 'arg98_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convert_element_type_24: None}, 'type': None, '_prev': arg97_1, '_next': arg99_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg99_1', 'op': 'placeholder', 'target': 'arg99_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convert_element_type_25: None}, 'type': None, '_prev': arg98_1, '_next': arg100_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg100_1', 'op': 'placeholder', 'target': 'arg100_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {}, 'type': None, '_prev': arg99_1, '_next': arg101_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.int64, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg101_1', 'op': 'placeholder', 'target': 'arg101_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convert_element_type_26: None}, 'type': None, '_prev': arg100_1, '_next': arg102_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg102_1', 'op': 'placeholder', 'target': 'arg102_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convert_element_type_27: None}, 'type': None, '_prev': arg101_1, '_next': arg103_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg103_1', 'op': 'placeholder', 'target': 'arg103_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {}, 'type': None, '_prev': arg102_1, '_next': arg104_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.int64, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg104_1', 'op': 'placeholder', 'target': 'arg104_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convert_element_type_28: None}, 'type': None, '_prev': arg103_1, '_next': arg105_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg105_1', 'op': 'placeholder', 'target': 'arg105_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convert_element_type_29: None}, 'type': None, '_prev': arg104_1, '_next': arg106_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg106_1', 'op': 'placeholder', 'target': 'arg106_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {}, 'type': None, '_prev': arg105_1, '_next': arg107_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.int64, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg107_1', 'op': 'placeholder', 'target': 'arg107_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convert_element_type_30: None}, 'type': None, '_prev': arg106_1, '_next': arg108_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg108_1', 'op': 'placeholder', 'target': 'arg108_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convert_element_type_31: None}, 'type': None, '_prev': arg107_1, '_next': arg109_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg109_1', 'op': 'placeholder', 'target': 'arg109_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {}, 'type': None, '_prev': arg108_1, '_next': arg110_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.int64, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg110_1', 'op': 'placeholder', 'target': 'arg110_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convert_element_type_32: None}, 'type': None, '_prev': arg109_1, '_next': arg111_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg111_1', 'op': 'placeholder', 'target': 'arg111_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convert_element_type_33: None}, 'type': None, '_prev': arg110_1, '_next': arg112_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg112_1', 'op': 'placeholder', 'target': 'arg112_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {}, 'type': None, '_prev': arg111_1, '_next': arg113_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.int64, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg113_1', 'op': 'placeholder', 'target': 'arg113_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convert_element_type_34: None}, 'type': None, '_prev': arg112_1, '_next': arg114_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg114_1', 'op': 'placeholder', 'target': 'arg114_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convert_element_type_35: None}, 'type': None, '_prev': arg113_1, '_next': arg115_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg115_1', 'op': 'placeholder', 'target': 'arg115_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {}, 'type': None, '_prev': arg114_1, '_next': arg116_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.int64, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg116_1', 'op': 'placeholder', 'target': 'arg116_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convert_element_type_36: None}, 'type': None, '_prev': arg115_1, '_next': arg117_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg117_1', 'op': 'placeholder', 'target': 'arg117_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convert_element_type_37: None}, 'type': None, '_prev': arg116_1, '_next': arg118_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg118_1', 'op': 'placeholder', 'target': 'arg118_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {}, 'type': None, '_prev': arg117_1, '_next': arg119_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.int64, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg119_1', 'op': 'placeholder', 'target': 'arg119_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convert_element_type_38: None}, 'type': None, '_prev': arg118_1, '_next': arg120_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg120_1', 'op': 'placeholder', 'target': 'arg120_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convert_element_type_39: None}, 'type': None, '_prev': arg119_1, '_next': arg121_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg121_1', 'op': 'placeholder', 'target': 'arg121_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {}, 'type': None, '_prev': arg120_1, '_next': arg122_1, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(), dtype=torch.int64), 'tensor_meta': TensorMetadata(shape=torch.Size([]), dtype=torch.int64, requires_grad=False, stride=(), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'arg122_1', 'op': 'placeholder', 'target': 'arg122_1', '_input_nodes': {}, '_args': (), '_kwargs': {}, 'users': {convolution: None}, 'type': None, '_prev': arg121_1, '_next': convolution, '_erased': False, '_repr_fn': None, 'meta': {'val': FakeTensor(..., size=(1, 3, 224, 224)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 3, 224, 224]), dtype=torch.float32, requires_grad=False, stride=(150528, 50176, 224, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convolution', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {arg122_1: None, arg0_1: None}, '_args': (arg122_1, arg0_1, None, [2, 2], [3, 3], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {sub: None}, 'type': None, '_prev': arg122_1, '_next': convert_element_type, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 268, in _forward_impl\n    x = self.conv1(x)\n', 'nn_module_stack': {'L__self___conv1': ("L['self'].conv1", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('l__self___conv1', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('l__self___conv1', 'L__self___conv1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 112, 112)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 112, 112]), dtype=torch.float32, requires_grad=False, stride=(802816, 12544, 112, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convert_element_type', 'op': 'call_function', 'target': <OpOverload(op='prims.convert_element_type', overload='default')>, '_input_nodes': {arg62_1: None}, '_args': (arg62_1, torch.float32), '_kwargs': {}, 'users': {unsqueeze: None}, 'type': None, '_prev': convolution, '_next': convert_element_type_1, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 269, in _forward_impl\n    x = self.bn1(x)\n', 'nn_module_stack': {'L__self___bn1': ("L['self'].bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('l__self___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('l__self___bn1', 'L__self___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convert_element_type_1', 'op': 'call_function', 'target': <OpOverload(op='prims.convert_element_type', overload='default')>, '_input_nodes': {arg63_1: None}, '_args': (arg63_1, torch.float32), '_kwargs': {}, 'users': {add: None}, 'type': None, '_prev': convert_element_type, '_next': add, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 269, in _forward_impl\n    x = self.bn1(x)\n', 'nn_module_stack': {'L__self___bn1': ("L['self'].bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('l__self___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('l__self___bn1', 'L__self___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {convert_element_type_1: None}, '_args': (convert_element_type_1, 1e-05), '_kwargs': {}, 'users': {sqrt: None}, 'type': None, '_prev': convert_element_type_1, '_next': sqrt, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 269, in _forward_impl\n    x = self.bn1(x)\n', 'nn_module_stack': {'L__self___bn1': ("L['self'].bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('l__self___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('l__self___bn1', 'L__self___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'sqrt', 'op': 'call_function', 'target': <OpOverload(op='aten.sqrt', overload='default')>, '_input_nodes': {add: None}, '_args': (add,), '_kwargs': {}, 'users': {reciprocal: None}, 'type': None, '_prev': add, '_next': reciprocal, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 269, in _forward_impl\n    x = self.bn1(x)\n', 'nn_module_stack': {'L__self___bn1': ("L['self'].bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('l__self___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('l__self___bn1', 'L__self___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'reciprocal', 'op': 'call_function', 'target': <OpOverload(op='aten.reciprocal', overload='default')>, '_input_nodes': {sqrt: None}, '_args': (sqrt,), '_kwargs': {}, 'users': {mul: None}, 'type': None, '_prev': sqrt, '_next': mul, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 269, in _forward_impl\n    x = self.bn1(x)\n', 'nn_module_stack': {'L__self___bn1': ("L['self'].bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('l__self___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('l__self___bn1', 'L__self___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {reciprocal: None}, '_args': (reciprocal, 1), '_kwargs': {}, 'users': {unsqueeze_2: None}, 'type': None, '_prev': reciprocal, '_next': unsqueeze, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 269, in _forward_impl\n    x = self.bn1(x)\n', 'nn_module_stack': {'L__self___bn1': ("L['self'].bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('l__self___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('l__self___bn1', 'L__self___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {convert_element_type: None}, '_args': (convert_element_type, -1), '_kwargs': {}, 'users': {unsqueeze_1: None}, 'type': None, '_prev': mul, '_next': unsqueeze_1, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 269, in _forward_impl\n    x = self.bn1(x)\n', 'nn_module_stack': {'L__self___bn1': ("L['self'].bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('l__self___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('l__self___bn1', 'L__self___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_1', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze: None}, '_args': (unsqueeze, -1), '_kwargs': {}, 'users': {sub: None}, 'type': None, '_prev': unsqueeze, '_next': unsqueeze_2, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 269, in _forward_impl\n    x = self.bn1(x)\n', 'nn_module_stack': {'L__self___bn1': ("L['self'].bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('l__self___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('l__self___bn1', 'L__self___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_2', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {mul: None}, '_args': (mul, -1), '_kwargs': {}, 'users': {unsqueeze_3: None}, 'type': None, '_prev': unsqueeze_1, '_next': unsqueeze_3, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 269, in _forward_impl\n    x = self.bn1(x)\n', 'nn_module_stack': {'L__self___bn1': ("L['self'].bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('l__self___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('l__self___bn1', 'L__self___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_3', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_2: None}, '_args': (unsqueeze_2, -1), '_kwargs': {}, 'users': {mul_1: None}, 'type': None, '_prev': unsqueeze_2, '_next': sub, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 269, in _forward_impl\n    x = self.bn1(x)\n', 'nn_module_stack': {'L__self___bn1': ("L['self'].bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('l__self___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('l__self___bn1', 'L__self___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'sub', 'op': 'call_function', 'target': <OpOverload(op='aten.sub', overload='Tensor')>, '_input_nodes': {convolution: None, unsqueeze_1: None}, '_args': (convolution, unsqueeze_1), '_kwargs': {}, 'users': {mul_1: None}, 'type': None, '_prev': unsqueeze_3, '_next': mul_1, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 269, in _forward_impl\n    x = self.bn1(x)\n', 'nn_module_stack': {'L__self___bn1': ("L['self'].bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('l__self___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('l__self___bn1', 'L__self___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 112, 112)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 112, 112]), dtype=torch.float32, requires_grad=False, stride=(802816, 12544, 112, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_1', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {sub: None, unsqueeze_3: None}, '_args': (sub, unsqueeze_3), '_kwargs': {}, 'users': {mul_2: None}, 'type': None, '_prev': sub, '_next': unsqueeze_4, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 269, in _forward_impl\n    x = self.bn1(x)\n', 'nn_module_stack': {'L__self___bn1': ("L['self'].bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('l__self___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('l__self___bn1', 'L__self___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 112, 112)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 112, 112]), dtype=torch.float32, requires_grad=False, stride=(802816, 12544, 112, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_4', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {arg1_1: None}, '_args': (arg1_1, -1), '_kwargs': {}, 'users': {unsqueeze_5: None}, 'type': None, '_prev': mul_1, '_next': unsqueeze_5, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 269, in _forward_impl\n    x = self.bn1(x)\n', 'nn_module_stack': {'L__self___bn1': ("L['self'].bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('l__self___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('l__self___bn1', 'L__self___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_5', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_4: None}, '_args': (unsqueeze_4, -1), '_kwargs': {}, 'users': {mul_2: None}, 'type': None, '_prev': unsqueeze_4, '_next': mul_2, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 269, in _forward_impl\n    x = self.bn1(x)\n', 'nn_module_stack': {'L__self___bn1': ("L['self'].bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('l__self___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('l__self___bn1', 'L__self___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_2', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {mul_1: None, unsqueeze_5: None}, '_args': (mul_1, unsqueeze_5), '_kwargs': {}, 'users': {add_1: None}, 'type': None, '_prev': unsqueeze_5, '_next': unsqueeze_6, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 269, in _forward_impl\n    x = self.bn1(x)\n', 'nn_module_stack': {'L__self___bn1': ("L['self'].bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('l__self___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('l__self___bn1', 'L__self___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 112, 112)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 112, 112]), dtype=torch.float32, requires_grad=False, stride=(802816, 12544, 112, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_6', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {arg2_1: None}, '_args': (arg2_1, -1), '_kwargs': {}, 'users': {unsqueeze_7: None}, 'type': None, '_prev': mul_2, '_next': unsqueeze_7, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 269, in _forward_impl\n    x = self.bn1(x)\n', 'nn_module_stack': {'L__self___bn1': ("L['self'].bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('l__self___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('l__self___bn1', 'L__self___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_7', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_6: None}, '_args': (unsqueeze_6, -1), '_kwargs': {}, 'users': {add_1: None}, 'type': None, '_prev': unsqueeze_6, '_next': add_1, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 269, in _forward_impl\n    x = self.bn1(x)\n', 'nn_module_stack': {'L__self___bn1': ("L['self'].bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('l__self___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('l__self___bn1', 'L__self___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_1', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {mul_2: None, unsqueeze_7: None}, '_args': (mul_2, unsqueeze_7), '_kwargs': {}, 'users': {relu: None}, 'type': None, '_prev': unsqueeze_7, '_next': relu, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 269, in _forward_impl\n    x = self.bn1(x)\n', 'nn_module_stack': {'L__self___bn1': ("L['self'].bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('l__self___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('l__self___bn1', 'L__self___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 112, 112)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 112, 112]), dtype=torch.float32, requires_grad=False, stride=(802816, 12544, 112, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'relu', 'op': 'call_function', 'target': <OpOverload(op='aten.relu', overload='default')>, '_input_nodes': {add_1: None}, '_args': (add_1,), '_kwargs': {}, 'users': {max_pool2d_with_indices: None}, 'type': None, '_prev': add_1, '_next': max_pool2d_with_indices, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 270, in _forward_impl\n    x = self.relu(x)\n', 'nn_module_stack': {'L__self___relu': ("L['self'].relu", <class 'torch.nn.modules.activation.ReLU'>)}, 'source_fn': ('l__self___relu', <class 'torch.nn.modules.activation.ReLU'>), 'original_aten': <OpOverload(op='aten.relu', overload='default')>, 'from_node': [('l__self___relu', 'L__self___relu')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 112, 112)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 112, 112]), dtype=torch.float32, requires_grad=False, stride=(802816, 12544, 112, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'max_pool2d_with_indices', 'op': 'call_function', 'target': <OpOverload(op='aten.max_pool2d_with_indices', overload='default')>, '_input_nodes': {relu: None}, '_args': (relu, [3, 3], [2, 2], [1, 1]), '_kwargs': {}, 'users': {getitem: None}, 'type': None, '_prev': relu, '_next': getitem, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 271, in _forward_impl\n    x = self.maxpool(x)\n', 'nn_module_stack': {'L__self___maxpool': ("L['self'].maxpool", <class 'torch.nn.modules.pooling.MaxPool2d'>)}, 'source_fn': ('l__self___maxpool', <class 'torch.nn.modules.pooling.MaxPool2d'>), 'original_aten': <OpOverload(op='aten.max_pool2d_with_indices', overload='default')>, 'from_node': [('l__self___maxpool', 'L__self___maxpool')], 'seq_nr': 123, 'val': (FakeTensor(..., size=(1, 64, 56, 56)), FakeTensor(..., size=(1, 64, 56, 56), dtype=torch.int64))}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'getitem', 'op': 'call_function', 'target': <built-in function getitem>, '_input_nodes': {max_pool2d_with_indices: None}, '_args': (max_pool2d_with_indices, 0), '_kwargs': {}, 'users': {convolution_1: None, add_6: None}, 'type': None, '_prev': max_pool2d_with_indices, '_next': convolution_1, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 271, in _forward_impl\n    x = self.maxpool(x)\n', 'nn_module_stack': {'L__self___maxpool': ("L['self'].maxpool", <class 'torch.nn.modules.pooling.MaxPool2d'>)}, 'source_fn': ('l__self___maxpool', <class 'torch.nn.modules.pooling.MaxPool2d'>), 'original_aten': <OpOverload(op='aten.max_pool2d_with_indices', overload='default')>, 'from_node': [('l__self___maxpool', 'L__self___maxpool')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 56, 56)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 56, 56]), dtype=torch.float32, requires_grad=False, stride=(200704, 3136, 56, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convolution_1', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {getitem: None, arg3_1: None}, '_args': (getitem, arg3_1, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {sub_1: None}, 'type': None, '_prev': getitem, '_next': convert_element_type_2, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 92, in forward\n    out = self.conv1(x)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___conv1': ("getattr(L['self'].layer1, '0').conv1", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___conv1', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___conv1', 'getattr_L__self___layer1___0___conv1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 56, 56)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 56, 56]), dtype=torch.float32, requires_grad=False, stride=(200704, 3136, 56, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convert_element_type_2', 'op': 'call_function', 'target': <OpOverload(op='prims.convert_element_type', overload='default')>, '_input_nodes': {arg65_1: None}, '_args': (arg65_1, torch.float32), '_kwargs': {}, 'users': {unsqueeze_8: None}, 'type': None, '_prev': convolution_1, '_next': convert_element_type_3, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___bn1': ("getattr(L['self'].layer1, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___bn1', 'getattr_L__self___layer1___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convert_element_type_3', 'op': 'call_function', 'target': <OpOverload(op='prims.convert_element_type', overload='default')>, '_input_nodes': {arg66_1: None}, '_args': (arg66_1, torch.float32), '_kwargs': {}, 'users': {add_2: None}, 'type': None, '_prev': convert_element_type_2, '_next': add_2, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___bn1': ("getattr(L['self'].layer1, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___bn1', 'getattr_L__self___layer1___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_2', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {convert_element_type_3: None}, '_args': (convert_element_type_3, 1e-05), '_kwargs': {}, 'users': {sqrt_1: None}, 'type': None, '_prev': convert_element_type_3, '_next': sqrt_1, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___bn1': ("getattr(L['self'].layer1, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___bn1', 'getattr_L__self___layer1___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'sqrt_1', 'op': 'call_function', 'target': <OpOverload(op='aten.sqrt', overload='default')>, '_input_nodes': {add_2: None}, '_args': (add_2,), '_kwargs': {}, 'users': {reciprocal_1: None}, 'type': None, '_prev': add_2, '_next': reciprocal_1, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___bn1': ("getattr(L['self'].layer1, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___bn1', 'getattr_L__self___layer1___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'reciprocal_1', 'op': 'call_function', 'target': <OpOverload(op='aten.reciprocal', overload='default')>, '_input_nodes': {sqrt_1: None}, '_args': (sqrt_1,), '_kwargs': {}, 'users': {mul_3: None}, 'type': None, '_prev': sqrt_1, '_next': mul_3, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___bn1': ("getattr(L['self'].layer1, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___bn1', 'getattr_L__self___layer1___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_3', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {reciprocal_1: None}, '_args': (reciprocal_1, 1), '_kwargs': {}, 'users': {unsqueeze_10: None}, 'type': None, '_prev': reciprocal_1, '_next': unsqueeze_8, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___bn1': ("getattr(L['self'].layer1, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___bn1', 'getattr_L__self___layer1___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_8', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {convert_element_type_2: None}, '_args': (convert_element_type_2, -1), '_kwargs': {}, 'users': {unsqueeze_9: None}, 'type': None, '_prev': mul_3, '_next': unsqueeze_9, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___bn1': ("getattr(L['self'].layer1, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___bn1', 'getattr_L__self___layer1___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_9', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_8: None}, '_args': (unsqueeze_8, -1), '_kwargs': {}, 'users': {sub_1: None}, 'type': None, '_prev': unsqueeze_8, '_next': unsqueeze_10, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___bn1': ("getattr(L['self'].layer1, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___bn1', 'getattr_L__self___layer1___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_10', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {mul_3: None}, '_args': (mul_3, -1), '_kwargs': {}, 'users': {unsqueeze_11: None}, 'type': None, '_prev': unsqueeze_9, '_next': unsqueeze_11, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___bn1': ("getattr(L['self'].layer1, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___bn1', 'getattr_L__self___layer1___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_11', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_10: None}, '_args': (unsqueeze_10, -1), '_kwargs': {}, 'users': {mul_4: None}, 'type': None, '_prev': unsqueeze_10, '_next': sub_1, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___bn1': ("getattr(L['self'].layer1, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___bn1', 'getattr_L__self___layer1___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'sub_1', 'op': 'call_function', 'target': <OpOverload(op='aten.sub', overload='Tensor')>, '_input_nodes': {convolution_1: None, unsqueeze_9: None}, '_args': (convolution_1, unsqueeze_9), '_kwargs': {}, 'users': {mul_4: None}, 'type': None, '_prev': unsqueeze_11, '_next': mul_4, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___bn1': ("getattr(L['self'].layer1, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___bn1', 'getattr_L__self___layer1___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 56, 56)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 56, 56]), dtype=torch.float32, requires_grad=False, stride=(200704, 3136, 56, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_4', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {sub_1: None, unsqueeze_11: None}, '_args': (sub_1, unsqueeze_11), '_kwargs': {}, 'users': {mul_5: None}, 'type': None, '_prev': sub_1, '_next': unsqueeze_12, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___bn1': ("getattr(L['self'].layer1, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___bn1', 'getattr_L__self___layer1___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 56, 56)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 56, 56]), dtype=torch.float32, requires_grad=False, stride=(200704, 3136, 56, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_12', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {arg4_1: None}, '_args': (arg4_1, -1), '_kwargs': {}, 'users': {unsqueeze_13: None}, 'type': None, '_prev': mul_4, '_next': unsqueeze_13, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___bn1': ("getattr(L['self'].layer1, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___bn1', 'getattr_L__self___layer1___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_13', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_12: None}, '_args': (unsqueeze_12, -1), '_kwargs': {}, 'users': {mul_5: None}, 'type': None, '_prev': unsqueeze_12, '_next': mul_5, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___bn1': ("getattr(L['self'].layer1, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___bn1', 'getattr_L__self___layer1___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_5', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {mul_4: None, unsqueeze_13: None}, '_args': (mul_4, unsqueeze_13), '_kwargs': {}, 'users': {add_3: None}, 'type': None, '_prev': unsqueeze_13, '_next': unsqueeze_14, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___bn1': ("getattr(L['self'].layer1, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___bn1', 'getattr_L__self___layer1___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 56, 56)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 56, 56]), dtype=torch.float32, requires_grad=False, stride=(200704, 3136, 56, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_14', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {arg5_1: None}, '_args': (arg5_1, -1), '_kwargs': {}, 'users': {unsqueeze_15: None}, 'type': None, '_prev': mul_5, '_next': unsqueeze_15, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___bn1': ("getattr(L['self'].layer1, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___bn1', 'getattr_L__self___layer1___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_15', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_14: None}, '_args': (unsqueeze_14, -1), '_kwargs': {}, 'users': {add_3: None}, 'type': None, '_prev': unsqueeze_14, '_next': add_3, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___bn1': ("getattr(L['self'].layer1, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___bn1', 'getattr_L__self___layer1___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_3', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {mul_5: None, unsqueeze_15: None}, '_args': (mul_5, unsqueeze_15), '_kwargs': {}, 'users': {relu_1: None}, 'type': None, '_prev': unsqueeze_15, '_next': relu_1, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___bn1': ("getattr(L['self'].layer1, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___bn1', 'getattr_L__self___layer1___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 56, 56)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 56, 56]), dtype=torch.float32, requires_grad=False, stride=(200704, 3136, 56, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'relu_1', 'op': 'call_function', 'target': <OpOverload(op='aten.relu', overload='default')>, '_input_nodes': {add_3: None}, '_args': (add_3,), '_kwargs': {}, 'users': {convolution_2: None}, 'type': None, '_prev': add_3, '_next': convolution_2, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 94, in forward\n    out = self.relu(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___relu': ("getattr(L['self'].layer1, '0').relu", <class 'torch.nn.modules.activation.ReLU'>)}, 'source_fn': ('getattr_l__self___layer1___0___relu', <class 'torch.nn.modules.activation.ReLU'>), 'original_aten': <OpOverload(op='aten.relu', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___relu', 'getattr_L__self___layer1___0___relu')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 56, 56)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 56, 56]), dtype=torch.float32, requires_grad=False, stride=(200704, 3136, 56, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convolution_2', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {relu_1: None, arg6_1: None}, '_args': (relu_1, arg6_1, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {sub_2: None}, 'type': None, '_prev': relu_1, '_next': convert_element_type_4, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 96, in forward\n    out = self.conv2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___conv2': ("getattr(L['self'].layer1, '0').conv2", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___conv2', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___conv2', 'getattr_L__self___layer1___0___conv2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 56, 56)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 56, 56]), dtype=torch.float32, requires_grad=False, stride=(200704, 3136, 56, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convert_element_type_4', 'op': 'call_function', 'target': <OpOverload(op='prims.convert_element_type', overload='default')>, '_input_nodes': {arg68_1: None}, '_args': (arg68_1, torch.float32), '_kwargs': {}, 'users': {unsqueeze_16: None}, 'type': None, '_prev': convolution_2, '_next': convert_element_type_5, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___bn2': ("getattr(L['self'].layer1, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___bn2', 'getattr_L__self___layer1___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convert_element_type_5', 'op': 'call_function', 'target': <OpOverload(op='prims.convert_element_type', overload='default')>, '_input_nodes': {arg69_1: None}, '_args': (arg69_1, torch.float32), '_kwargs': {}, 'users': {add_4: None}, 'type': None, '_prev': convert_element_type_4, '_next': add_4, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___bn2': ("getattr(L['self'].layer1, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___bn2', 'getattr_L__self___layer1___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_4', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {convert_element_type_5: None}, '_args': (convert_element_type_5, 1e-05), '_kwargs': {}, 'users': {sqrt_2: None}, 'type': None, '_prev': convert_element_type_5, '_next': sqrt_2, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___bn2': ("getattr(L['self'].layer1, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___bn2', 'getattr_L__self___layer1___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'sqrt_2', 'op': 'call_function', 'target': <OpOverload(op='aten.sqrt', overload='default')>, '_input_nodes': {add_4: None}, '_args': (add_4,), '_kwargs': {}, 'users': {reciprocal_2: None}, 'type': None, '_prev': add_4, '_next': reciprocal_2, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___bn2': ("getattr(L['self'].layer1, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___bn2', 'getattr_L__self___layer1___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'reciprocal_2', 'op': 'call_function', 'target': <OpOverload(op='aten.reciprocal', overload='default')>, '_input_nodes': {sqrt_2: None}, '_args': (sqrt_2,), '_kwargs': {}, 'users': {mul_6: None}, 'type': None, '_prev': sqrt_2, '_next': mul_6, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___bn2': ("getattr(L['self'].layer1, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___bn2', 'getattr_L__self___layer1___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_6', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {reciprocal_2: None}, '_args': (reciprocal_2, 1), '_kwargs': {}, 'users': {unsqueeze_18: None}, 'type': None, '_prev': reciprocal_2, '_next': unsqueeze_16, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___bn2': ("getattr(L['self'].layer1, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___bn2', 'getattr_L__self___layer1___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_16', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {convert_element_type_4: None}, '_args': (convert_element_type_4, -1), '_kwargs': {}, 'users': {unsqueeze_17: None}, 'type': None, '_prev': mul_6, '_next': unsqueeze_17, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___bn2': ("getattr(L['self'].layer1, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___bn2', 'getattr_L__self___layer1___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_17', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_16: None}, '_args': (unsqueeze_16, -1), '_kwargs': {}, 'users': {sub_2: None}, 'type': None, '_prev': unsqueeze_16, '_next': unsqueeze_18, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___bn2': ("getattr(L['self'].layer1, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___bn2', 'getattr_L__self___layer1___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_18', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {mul_6: None}, '_args': (mul_6, -1), '_kwargs': {}, 'users': {unsqueeze_19: None}, 'type': None, '_prev': unsqueeze_17, '_next': unsqueeze_19, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___bn2': ("getattr(L['self'].layer1, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___bn2', 'getattr_L__self___layer1___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_19', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_18: None}, '_args': (unsqueeze_18, -1), '_kwargs': {}, 'users': {mul_7: None}, 'type': None, '_prev': unsqueeze_18, '_next': sub_2, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___bn2': ("getattr(L['self'].layer1, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___bn2', 'getattr_L__self___layer1___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'sub_2', 'op': 'call_function', 'target': <OpOverload(op='aten.sub', overload='Tensor')>, '_input_nodes': {convolution_2: None, unsqueeze_17: None}, '_args': (convolution_2, unsqueeze_17), '_kwargs': {}, 'users': {mul_7: None}, 'type': None, '_prev': unsqueeze_19, '_next': mul_7, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___bn2': ("getattr(L['self'].layer1, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___bn2', 'getattr_L__self___layer1___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 56, 56)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 56, 56]), dtype=torch.float32, requires_grad=False, stride=(200704, 3136, 56, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_7', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {sub_2: None, unsqueeze_19: None}, '_args': (sub_2, unsqueeze_19), '_kwargs': {}, 'users': {mul_8: None}, 'type': None, '_prev': sub_2, '_next': unsqueeze_20, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___bn2': ("getattr(L['self'].layer1, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___bn2', 'getattr_L__self___layer1___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 56, 56)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 56, 56]), dtype=torch.float32, requires_grad=False, stride=(200704, 3136, 56, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_20', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {arg7_1: None}, '_args': (arg7_1, -1), '_kwargs': {}, 'users': {unsqueeze_21: None}, 'type': None, '_prev': mul_7, '_next': unsqueeze_21, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___bn2': ("getattr(L['self'].layer1, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___bn2', 'getattr_L__self___layer1___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_21', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_20: None}, '_args': (unsqueeze_20, -1), '_kwargs': {}, 'users': {mul_8: None}, 'type': None, '_prev': unsqueeze_20, '_next': mul_8, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___bn2': ("getattr(L['self'].layer1, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___bn2', 'getattr_L__self___layer1___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_8', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {mul_7: None, unsqueeze_21: None}, '_args': (mul_7, unsqueeze_21), '_kwargs': {}, 'users': {add_5: None}, 'type': None, '_prev': unsqueeze_21, '_next': unsqueeze_22, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___bn2': ("getattr(L['self'].layer1, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___bn2', 'getattr_L__self___layer1___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 56, 56)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 56, 56]), dtype=torch.float32, requires_grad=False, stride=(200704, 3136, 56, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_22', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {arg8_1: None}, '_args': (arg8_1, -1), '_kwargs': {}, 'users': {unsqueeze_23: None}, 'type': None, '_prev': mul_8, '_next': unsqueeze_23, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___bn2': ("getattr(L['self'].layer1, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___bn2', 'getattr_L__self___layer1___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_23', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_22: None}, '_args': (unsqueeze_22, -1), '_kwargs': {}, 'users': {add_5: None}, 'type': None, '_prev': unsqueeze_22, '_next': add_5, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___bn2': ("getattr(L['self'].layer1, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___bn2', 'getattr_L__self___layer1___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_5', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {mul_8: None, unsqueeze_23: None}, '_args': (mul_8, unsqueeze_23), '_kwargs': {}, 'users': {add_6: None}, 'type': None, '_prev': unsqueeze_23, '_next': add_6, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___bn2': ("getattr(L['self'].layer1, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___bn2', 'getattr_L__self___layer1___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 56, 56)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 56, 56]), dtype=torch.float32, requires_grad=False, stride=(200704, 3136, 56, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_6', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {add_5: None, getitem: None}, '_args': (add_5, getitem), '_kwargs': {}, 'users': {relu_2: None}, 'type': None, '_prev': add_5, '_next': relu_2, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 102, in forward\n    out += identity\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>)}, 'source_fn': ('iadd', <built-in function iadd>), 'original_aten': <OpOverload(op='aten.add', overload='Tensor')>, 'from_node': [('iadd', <built-in function iadd>)], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 56, 56)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 56, 56]), dtype=torch.float32, requires_grad=False, stride=(200704, 3136, 56, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'relu_2', 'op': 'call_function', 'target': <OpOverload(op='aten.relu', overload='default')>, '_input_nodes': {add_6: None}, '_args': (add_6,), '_kwargs': {}, 'users': {convolution_3: None, add_11: None}, 'type': None, '_prev': add_6, '_next': convolution_3, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 103, in forward\n    out = self.relu(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_0': ("getattr(L['self'].layer1, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___0___relu': ("getattr(L['self'].layer1, '0').relu", <class 'torch.nn.modules.activation.ReLU'>)}, 'source_fn': ('getattr_l__self___layer1___0___relu_1', <class 'torch.nn.modules.activation.ReLU'>), 'original_aten': <OpOverload(op='aten.relu', overload='default')>, 'from_node': [('getattr_l__self___layer1___0___relu_1', 'getattr_L__self___layer1___0___relu')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 56, 56)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 56, 56]), dtype=torch.float32, requires_grad=False, stride=(200704, 3136, 56, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convolution_3', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {relu_2: None, arg9_1: None}, '_args': (relu_2, arg9_1, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {sub_3: None}, 'type': None, '_prev': relu_2, '_next': convert_element_type_6, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 92, in forward\n    out = self.conv1(x)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___conv1': ("getattr(L['self'].layer1, '1').conv1", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___conv1', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___conv1', 'getattr_L__self___layer1___1___conv1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 56, 56)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 56, 56]), dtype=torch.float32, requires_grad=False, stride=(200704, 3136, 56, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convert_element_type_6', 'op': 'call_function', 'target': <OpOverload(op='prims.convert_element_type', overload='default')>, '_input_nodes': {arg71_1: None}, '_args': (arg71_1, torch.float32), '_kwargs': {}, 'users': {unsqueeze_24: None}, 'type': None, '_prev': convolution_3, '_next': convert_element_type_7, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___bn1': ("getattr(L['self'].layer1, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___bn1', 'getattr_L__self___layer1___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convert_element_type_7', 'op': 'call_function', 'target': <OpOverload(op='prims.convert_element_type', overload='default')>, '_input_nodes': {arg72_1: None}, '_args': (arg72_1, torch.float32), '_kwargs': {}, 'users': {add_7: None}, 'type': None, '_prev': convert_element_type_6, '_next': add_7, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___bn1': ("getattr(L['self'].layer1, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___bn1', 'getattr_L__self___layer1___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_7', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {convert_element_type_7: None}, '_args': (convert_element_type_7, 1e-05), '_kwargs': {}, 'users': {sqrt_3: None}, 'type': None, '_prev': convert_element_type_7, '_next': sqrt_3, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___bn1': ("getattr(L['self'].layer1, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___bn1', 'getattr_L__self___layer1___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'sqrt_3', 'op': 'call_function', 'target': <OpOverload(op='aten.sqrt', overload='default')>, '_input_nodes': {add_7: None}, '_args': (add_7,), '_kwargs': {}, 'users': {reciprocal_3: None}, 'type': None, '_prev': add_7, '_next': reciprocal_3, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___bn1': ("getattr(L['self'].layer1, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___bn1', 'getattr_L__self___layer1___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'reciprocal_3', 'op': 'call_function', 'target': <OpOverload(op='aten.reciprocal', overload='default')>, '_input_nodes': {sqrt_3: None}, '_args': (sqrt_3,), '_kwargs': {}, 'users': {mul_9: None}, 'type': None, '_prev': sqrt_3, '_next': mul_9, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___bn1': ("getattr(L['self'].layer1, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___bn1', 'getattr_L__self___layer1___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_9', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {reciprocal_3: None}, '_args': (reciprocal_3, 1), '_kwargs': {}, 'users': {unsqueeze_26: None}, 'type': None, '_prev': reciprocal_3, '_next': unsqueeze_24, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___bn1': ("getattr(L['self'].layer1, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___bn1', 'getattr_L__self___layer1___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_24', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {convert_element_type_6: None}, '_args': (convert_element_type_6, -1), '_kwargs': {}, 'users': {unsqueeze_25: None}, 'type': None, '_prev': mul_9, '_next': unsqueeze_25, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___bn1': ("getattr(L['self'].layer1, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___bn1', 'getattr_L__self___layer1___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_25', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_24: None}, '_args': (unsqueeze_24, -1), '_kwargs': {}, 'users': {sub_3: None}, 'type': None, '_prev': unsqueeze_24, '_next': unsqueeze_26, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___bn1': ("getattr(L['self'].layer1, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___bn1', 'getattr_L__self___layer1___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_26', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {mul_9: None}, '_args': (mul_9, -1), '_kwargs': {}, 'users': {unsqueeze_27: None}, 'type': None, '_prev': unsqueeze_25, '_next': unsqueeze_27, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___bn1': ("getattr(L['self'].layer1, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___bn1', 'getattr_L__self___layer1___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_27', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_26: None}, '_args': (unsqueeze_26, -1), '_kwargs': {}, 'users': {mul_10: None}, 'type': None, '_prev': unsqueeze_26, '_next': sub_3, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___bn1': ("getattr(L['self'].layer1, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___bn1', 'getattr_L__self___layer1___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'sub_3', 'op': 'call_function', 'target': <OpOverload(op='aten.sub', overload='Tensor')>, '_input_nodes': {convolution_3: None, unsqueeze_25: None}, '_args': (convolution_3, unsqueeze_25), '_kwargs': {}, 'users': {mul_10: None}, 'type': None, '_prev': unsqueeze_27, '_next': mul_10, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___bn1': ("getattr(L['self'].layer1, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___bn1', 'getattr_L__self___layer1___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 56, 56)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 56, 56]), dtype=torch.float32, requires_grad=False, stride=(200704, 3136, 56, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_10', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {sub_3: None, unsqueeze_27: None}, '_args': (sub_3, unsqueeze_27), '_kwargs': {}, 'users': {mul_11: None}, 'type': None, '_prev': sub_3, '_next': unsqueeze_28, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___bn1': ("getattr(L['self'].layer1, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___bn1', 'getattr_L__self___layer1___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 56, 56)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 56, 56]), dtype=torch.float32, requires_grad=False, stride=(200704, 3136, 56, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_28', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {arg10_1: None}, '_args': (arg10_1, -1), '_kwargs': {}, 'users': {unsqueeze_29: None}, 'type': None, '_prev': mul_10, '_next': unsqueeze_29, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___bn1': ("getattr(L['self'].layer1, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___bn1', 'getattr_L__self___layer1___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_29', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_28: None}, '_args': (unsqueeze_28, -1), '_kwargs': {}, 'users': {mul_11: None}, 'type': None, '_prev': unsqueeze_28, '_next': mul_11, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___bn1': ("getattr(L['self'].layer1, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___bn1', 'getattr_L__self___layer1___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_11', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {mul_10: None, unsqueeze_29: None}, '_args': (mul_10, unsqueeze_29), '_kwargs': {}, 'users': {add_8: None}, 'type': None, '_prev': unsqueeze_29, '_next': unsqueeze_30, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___bn1': ("getattr(L['self'].layer1, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___bn1', 'getattr_L__self___layer1___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 56, 56)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 56, 56]), dtype=torch.float32, requires_grad=False, stride=(200704, 3136, 56, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_30', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {arg11_1: None}, '_args': (arg11_1, -1), '_kwargs': {}, 'users': {unsqueeze_31: None}, 'type': None, '_prev': mul_11, '_next': unsqueeze_31, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___bn1': ("getattr(L['self'].layer1, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___bn1', 'getattr_L__self___layer1___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_31', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_30: None}, '_args': (unsqueeze_30, -1), '_kwargs': {}, 'users': {add_8: None}, 'type': None, '_prev': unsqueeze_30, '_next': add_8, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___bn1': ("getattr(L['self'].layer1, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___bn1', 'getattr_L__self___layer1___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_8', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {mul_11: None, unsqueeze_31: None}, '_args': (mul_11, unsqueeze_31), '_kwargs': {}, 'users': {relu_3: None}, 'type': None, '_prev': unsqueeze_31, '_next': relu_3, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___bn1': ("getattr(L['self'].layer1, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___bn1', 'getattr_L__self___layer1___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 56, 56)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 56, 56]), dtype=torch.float32, requires_grad=False, stride=(200704, 3136, 56, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'relu_3', 'op': 'call_function', 'target': <OpOverload(op='aten.relu', overload='default')>, '_input_nodes': {add_8: None}, '_args': (add_8,), '_kwargs': {}, 'users': {convolution_4: None}, 'type': None, '_prev': add_8, '_next': convolution_4, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 94, in forward\n    out = self.relu(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___relu': ("getattr(L['self'].layer1, '1').relu", <class 'torch.nn.modules.activation.ReLU'>)}, 'source_fn': ('getattr_l__self___layer1___1___relu', <class 'torch.nn.modules.activation.ReLU'>), 'original_aten': <OpOverload(op='aten.relu', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___relu', 'getattr_L__self___layer1___1___relu')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 56, 56)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 56, 56]), dtype=torch.float32, requires_grad=False, stride=(200704, 3136, 56, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convolution_4', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {relu_3: None, arg12_1: None}, '_args': (relu_3, arg12_1, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {sub_4: None}, 'type': None, '_prev': relu_3, '_next': convert_element_type_8, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 96, in forward\n    out = self.conv2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___conv2': ("getattr(L['self'].layer1, '1').conv2", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___conv2', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___conv2', 'getattr_L__self___layer1___1___conv2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 56, 56)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 56, 56]), dtype=torch.float32, requires_grad=False, stride=(200704, 3136, 56, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convert_element_type_8', 'op': 'call_function', 'target': <OpOverload(op='prims.convert_element_type', overload='default')>, '_input_nodes': {arg74_1: None}, '_args': (arg74_1, torch.float32), '_kwargs': {}, 'users': {unsqueeze_32: None}, 'type': None, '_prev': convolution_4, '_next': convert_element_type_9, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___bn2': ("getattr(L['self'].layer1, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___bn2', 'getattr_L__self___layer1___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convert_element_type_9', 'op': 'call_function', 'target': <OpOverload(op='prims.convert_element_type', overload='default')>, '_input_nodes': {arg75_1: None}, '_args': (arg75_1, torch.float32), '_kwargs': {}, 'users': {add_9: None}, 'type': None, '_prev': convert_element_type_8, '_next': add_9, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___bn2': ("getattr(L['self'].layer1, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___bn2', 'getattr_L__self___layer1___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_9', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {convert_element_type_9: None}, '_args': (convert_element_type_9, 1e-05), '_kwargs': {}, 'users': {sqrt_4: None}, 'type': None, '_prev': convert_element_type_9, '_next': sqrt_4, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___bn2': ("getattr(L['self'].layer1, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___bn2', 'getattr_L__self___layer1___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'sqrt_4', 'op': 'call_function', 'target': <OpOverload(op='aten.sqrt', overload='default')>, '_input_nodes': {add_9: None}, '_args': (add_9,), '_kwargs': {}, 'users': {reciprocal_4: None}, 'type': None, '_prev': add_9, '_next': reciprocal_4, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___bn2': ("getattr(L['self'].layer1, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___bn2', 'getattr_L__self___layer1___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'reciprocal_4', 'op': 'call_function', 'target': <OpOverload(op='aten.reciprocal', overload='default')>, '_input_nodes': {sqrt_4: None}, '_args': (sqrt_4,), '_kwargs': {}, 'users': {mul_12: None}, 'type': None, '_prev': sqrt_4, '_next': mul_12, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___bn2': ("getattr(L['self'].layer1, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___bn2', 'getattr_L__self___layer1___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_12', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {reciprocal_4: None}, '_args': (reciprocal_4, 1), '_kwargs': {}, 'users': {unsqueeze_34: None}, 'type': None, '_prev': reciprocal_4, '_next': unsqueeze_32, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___bn2': ("getattr(L['self'].layer1, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___bn2', 'getattr_L__self___layer1___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64,)), 'tensor_meta': TensorMetadata(shape=torch.Size([64]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_32', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {convert_element_type_8: None}, '_args': (convert_element_type_8, -1), '_kwargs': {}, 'users': {unsqueeze_33: None}, 'type': None, '_prev': mul_12, '_next': unsqueeze_33, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___bn2': ("getattr(L['self'].layer1, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___bn2', 'getattr_L__self___layer1___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_33', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_32: None}, '_args': (unsqueeze_32, -1), '_kwargs': {}, 'users': {sub_4: None}, 'type': None, '_prev': unsqueeze_32, '_next': unsqueeze_34, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___bn2': ("getattr(L['self'].layer1, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___bn2', 'getattr_L__self___layer1___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_34', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {mul_12: None}, '_args': (mul_12, -1), '_kwargs': {}, 'users': {unsqueeze_35: None}, 'type': None, '_prev': unsqueeze_33, '_next': unsqueeze_35, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___bn2': ("getattr(L['self'].layer1, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___bn2', 'getattr_L__self___layer1___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_35', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_34: None}, '_args': (unsqueeze_34, -1), '_kwargs': {}, 'users': {mul_13: None}, 'type': None, '_prev': unsqueeze_34, '_next': sub_4, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___bn2': ("getattr(L['self'].layer1, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___bn2', 'getattr_L__self___layer1___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'sub_4', 'op': 'call_function', 'target': <OpOverload(op='aten.sub', overload='Tensor')>, '_input_nodes': {convolution_4: None, unsqueeze_33: None}, '_args': (convolution_4, unsqueeze_33), '_kwargs': {}, 'users': {mul_13: None}, 'type': None, '_prev': unsqueeze_35, '_next': mul_13, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___bn2': ("getattr(L['self'].layer1, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___bn2', 'getattr_L__self___layer1___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 56, 56)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 56, 56]), dtype=torch.float32, requires_grad=False, stride=(200704, 3136, 56, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_13', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {sub_4: None, unsqueeze_35: None}, '_args': (sub_4, unsqueeze_35), '_kwargs': {}, 'users': {mul_14: None}, 'type': None, '_prev': sub_4, '_next': unsqueeze_36, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___bn2': ("getattr(L['self'].layer1, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___bn2', 'getattr_L__self___layer1___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 56, 56)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 56, 56]), dtype=torch.float32, requires_grad=False, stride=(200704, 3136, 56, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_36', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {arg13_1: None}, '_args': (arg13_1, -1), '_kwargs': {}, 'users': {unsqueeze_37: None}, 'type': None, '_prev': mul_13, '_next': unsqueeze_37, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___bn2': ("getattr(L['self'].layer1, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___bn2', 'getattr_L__self___layer1___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_37', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_36: None}, '_args': (unsqueeze_36, -1), '_kwargs': {}, 'users': {mul_14: None}, 'type': None, '_prev': unsqueeze_36, '_next': mul_14, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___bn2': ("getattr(L['self'].layer1, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___bn2', 'getattr_L__self___layer1___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_14', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {mul_13: None, unsqueeze_37: None}, '_args': (mul_13, unsqueeze_37), '_kwargs': {}, 'users': {add_10: None}, 'type': None, '_prev': unsqueeze_37, '_next': unsqueeze_38, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___bn2': ("getattr(L['self'].layer1, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___bn2', 'getattr_L__self___layer1___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 56, 56)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 56, 56]), dtype=torch.float32, requires_grad=False, stride=(200704, 3136, 56, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_38', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {arg14_1: None}, '_args': (arg14_1, -1), '_kwargs': {}, 'users': {unsqueeze_39: None}, 'type': None, '_prev': mul_14, '_next': unsqueeze_39, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___bn2': ("getattr(L['self'].layer1, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___bn2', 'getattr_L__self___layer1___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_39', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_38: None}, '_args': (unsqueeze_38, -1), '_kwargs': {}, 'users': {add_10: None}, 'type': None, '_prev': unsqueeze_38, '_next': add_10, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___bn2': ("getattr(L['self'].layer1, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___bn2', 'getattr_L__self___layer1___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(64, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([64, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_10', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {mul_14: None, unsqueeze_39: None}, '_args': (mul_14, unsqueeze_39), '_kwargs': {}, 'users': {add_11: None}, 'type': None, '_prev': unsqueeze_39, '_next': add_11, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___bn2': ("getattr(L['self'].layer1, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer1___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___bn2', 'getattr_L__self___layer1___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 56, 56)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 56, 56]), dtype=torch.float32, requires_grad=False, stride=(200704, 3136, 56, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_11', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {add_10: None, relu_2: None}, '_args': (add_10, relu_2), '_kwargs': {}, 'users': {relu_4: None}, 'type': None, '_prev': add_10, '_next': relu_4, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 102, in forward\n    out += identity\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>)}, 'source_fn': ('iadd_1', <built-in function iadd>), 'original_aten': <OpOverload(op='aten.add', overload='Tensor')>, 'from_node': [('iadd_1', <built-in function iadd>)], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 56, 56)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 56, 56]), dtype=torch.float32, requires_grad=False, stride=(200704, 3136, 56, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'relu_4', 'op': 'call_function', 'target': <OpOverload(op='aten.relu', overload='default')>, '_input_nodes': {add_11: None}, '_args': (add_11,), '_kwargs': {}, 'users': {convolution_5: None, convolution_7: None}, 'type': None, '_prev': add_11, '_next': convolution_5, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 273, in _forward_impl\n    x = self.layer1(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 103, in forward\n    out = self.relu(out)\n', 'nn_module_stack': {'L__self___layer1': ("L['self'].layer1", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer1_1': ("getattr(L['self'].layer1, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer1___1___relu': ("getattr(L['self'].layer1, '1').relu", <class 'torch.nn.modules.activation.ReLU'>)}, 'source_fn': ('getattr_l__self___layer1___1___relu_1', <class 'torch.nn.modules.activation.ReLU'>), 'original_aten': <OpOverload(op='aten.relu', overload='default')>, 'from_node': [('getattr_l__self___layer1___1___relu_1', 'getattr_L__self___layer1___1___relu')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 64, 56, 56)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 64, 56, 56]), dtype=torch.float32, requires_grad=False, stride=(200704, 3136, 56, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convolution_5', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {relu_4: None, arg15_1: None}, '_args': (relu_4, arg15_1, None, [2, 2], [1, 1], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {sub_5: None}, 'type': None, '_prev': relu_4, '_next': convert_element_type_10, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 92, in forward\n    out = self.conv1(x)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___conv1': ("getattr(L['self'].layer2, '0').conv1", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___conv1', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___conv1', 'getattr_L__self___layer2___0___conv1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convert_element_type_10', 'op': 'call_function', 'target': <OpOverload(op='prims.convert_element_type', overload='default')>, '_input_nodes': {arg77_1: None}, '_args': (arg77_1, torch.float32), '_kwargs': {}, 'users': {unsqueeze_40: None}, 'type': None, '_prev': convolution_5, '_next': convert_element_type_11, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___bn1': ("getattr(L['self'].layer2, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___bn1', 'getattr_L__self___layer2___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convert_element_type_11', 'op': 'call_function', 'target': <OpOverload(op='prims.convert_element_type', overload='default')>, '_input_nodes': {arg78_1: None}, '_args': (arg78_1, torch.float32), '_kwargs': {}, 'users': {add_12: None}, 'type': None, '_prev': convert_element_type_10, '_next': add_12, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___bn1': ("getattr(L['self'].layer2, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___bn1', 'getattr_L__self___layer2___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_12', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {convert_element_type_11: None}, '_args': (convert_element_type_11, 1e-05), '_kwargs': {}, 'users': {sqrt_5: None}, 'type': None, '_prev': convert_element_type_11, '_next': sqrt_5, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___bn1': ("getattr(L['self'].layer2, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___bn1', 'getattr_L__self___layer2___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'sqrt_5', 'op': 'call_function', 'target': <OpOverload(op='aten.sqrt', overload='default')>, '_input_nodes': {add_12: None}, '_args': (add_12,), '_kwargs': {}, 'users': {reciprocal_5: None}, 'type': None, '_prev': add_12, '_next': reciprocal_5, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___bn1': ("getattr(L['self'].layer2, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___bn1', 'getattr_L__self___layer2___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'reciprocal_5', 'op': 'call_function', 'target': <OpOverload(op='aten.reciprocal', overload='default')>, '_input_nodes': {sqrt_5: None}, '_args': (sqrt_5,), '_kwargs': {}, 'users': {mul_15: None}, 'type': None, '_prev': sqrt_5, '_next': mul_15, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___bn1': ("getattr(L['self'].layer2, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___bn1', 'getattr_L__self___layer2___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_15', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {reciprocal_5: None}, '_args': (reciprocal_5, 1), '_kwargs': {}, 'users': {unsqueeze_42: None}, 'type': None, '_prev': reciprocal_5, '_next': unsqueeze_40, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___bn1': ("getattr(L['self'].layer2, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___bn1', 'getattr_L__self___layer2___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_40', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {convert_element_type_10: None}, '_args': (convert_element_type_10, -1), '_kwargs': {}, 'users': {unsqueeze_41: None}, 'type': None, '_prev': mul_15, '_next': unsqueeze_41, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___bn1': ("getattr(L['self'].layer2, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___bn1', 'getattr_L__self___layer2___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_41', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_40: None}, '_args': (unsqueeze_40, -1), '_kwargs': {}, 'users': {sub_5: None}, 'type': None, '_prev': unsqueeze_40, '_next': unsqueeze_42, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___bn1': ("getattr(L['self'].layer2, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___bn1', 'getattr_L__self___layer2___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_42', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {mul_15: None}, '_args': (mul_15, -1), '_kwargs': {}, 'users': {unsqueeze_43: None}, 'type': None, '_prev': unsqueeze_41, '_next': unsqueeze_43, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___bn1': ("getattr(L['self'].layer2, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___bn1', 'getattr_L__self___layer2___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_43', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_42: None}, '_args': (unsqueeze_42, -1), '_kwargs': {}, 'users': {mul_16: None}, 'type': None, '_prev': unsqueeze_42, '_next': sub_5, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___bn1': ("getattr(L['self'].layer2, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___bn1', 'getattr_L__self___layer2___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'sub_5', 'op': 'call_function', 'target': <OpOverload(op='aten.sub', overload='Tensor')>, '_input_nodes': {convolution_5: None, unsqueeze_41: None}, '_args': (convolution_5, unsqueeze_41), '_kwargs': {}, 'users': {mul_16: None}, 'type': None, '_prev': unsqueeze_43, '_next': mul_16, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___bn1': ("getattr(L['self'].layer2, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___bn1', 'getattr_L__self___layer2___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_16', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {sub_5: None, unsqueeze_43: None}, '_args': (sub_5, unsqueeze_43), '_kwargs': {}, 'users': {mul_17: None}, 'type': None, '_prev': sub_5, '_next': unsqueeze_44, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___bn1': ("getattr(L['self'].layer2, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___bn1', 'getattr_L__self___layer2___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_44', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {arg16_1: None}, '_args': (arg16_1, -1), '_kwargs': {}, 'users': {unsqueeze_45: None}, 'type': None, '_prev': mul_16, '_next': unsqueeze_45, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___bn1': ("getattr(L['self'].layer2, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___bn1', 'getattr_L__self___layer2___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_45', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_44: None}, '_args': (unsqueeze_44, -1), '_kwargs': {}, 'users': {mul_17: None}, 'type': None, '_prev': unsqueeze_44, '_next': mul_17, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___bn1': ("getattr(L['self'].layer2, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___bn1', 'getattr_L__self___layer2___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_17', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {mul_16: None, unsqueeze_45: None}, '_args': (mul_16, unsqueeze_45), '_kwargs': {}, 'users': {add_13: None}, 'type': None, '_prev': unsqueeze_45, '_next': unsqueeze_46, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___bn1': ("getattr(L['self'].layer2, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___bn1', 'getattr_L__self___layer2___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_46', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {arg17_1: None}, '_args': (arg17_1, -1), '_kwargs': {}, 'users': {unsqueeze_47: None}, 'type': None, '_prev': mul_17, '_next': unsqueeze_47, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___bn1': ("getattr(L['self'].layer2, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___bn1', 'getattr_L__self___layer2___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_47', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_46: None}, '_args': (unsqueeze_46, -1), '_kwargs': {}, 'users': {add_13: None}, 'type': None, '_prev': unsqueeze_46, '_next': add_13, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___bn1': ("getattr(L['self'].layer2, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___bn1', 'getattr_L__self___layer2___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_13', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {mul_17: None, unsqueeze_47: None}, '_args': (mul_17, unsqueeze_47), '_kwargs': {}, 'users': {relu_5: None}, 'type': None, '_prev': unsqueeze_47, '_next': relu_5, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___bn1': ("getattr(L['self'].layer2, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___bn1', 'getattr_L__self___layer2___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'relu_5', 'op': 'call_function', 'target': <OpOverload(op='aten.relu', overload='default')>, '_input_nodes': {add_13: None}, '_args': (add_13,), '_kwargs': {}, 'users': {convolution_6: None}, 'type': None, '_prev': add_13, '_next': convolution_6, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 94, in forward\n    out = self.relu(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___relu': ("getattr(L['self'].layer2, '0').relu", <class 'torch.nn.modules.activation.ReLU'>)}, 'source_fn': ('getattr_l__self___layer2___0___relu', <class 'torch.nn.modules.activation.ReLU'>), 'original_aten': <OpOverload(op='aten.relu', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___relu', 'getattr_L__self___layer2___0___relu')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convolution_6', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {relu_5: None, arg18_1: None}, '_args': (relu_5, arg18_1, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {sub_6: None}, 'type': None, '_prev': relu_5, '_next': convert_element_type_12, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 96, in forward\n    out = self.conv2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___conv2': ("getattr(L['self'].layer2, '0').conv2", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___conv2', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___conv2', 'getattr_L__self___layer2___0___conv2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convert_element_type_12', 'op': 'call_function', 'target': <OpOverload(op='prims.convert_element_type', overload='default')>, '_input_nodes': {arg80_1: None}, '_args': (arg80_1, torch.float32), '_kwargs': {}, 'users': {unsqueeze_48: None}, 'type': None, '_prev': convolution_6, '_next': convert_element_type_13, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___bn2': ("getattr(L['self'].layer2, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___bn2', 'getattr_L__self___layer2___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convert_element_type_13', 'op': 'call_function', 'target': <OpOverload(op='prims.convert_element_type', overload='default')>, '_input_nodes': {arg81_1: None}, '_args': (arg81_1, torch.float32), '_kwargs': {}, 'users': {add_14: None}, 'type': None, '_prev': convert_element_type_12, '_next': add_14, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___bn2': ("getattr(L['self'].layer2, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___bn2', 'getattr_L__self___layer2___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_14', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {convert_element_type_13: None}, '_args': (convert_element_type_13, 1e-05), '_kwargs': {}, 'users': {sqrt_6: None}, 'type': None, '_prev': convert_element_type_13, '_next': sqrt_6, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___bn2': ("getattr(L['self'].layer2, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___bn2', 'getattr_L__self___layer2___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'sqrt_6', 'op': 'call_function', 'target': <OpOverload(op='aten.sqrt', overload='default')>, '_input_nodes': {add_14: None}, '_args': (add_14,), '_kwargs': {}, 'users': {reciprocal_6: None}, 'type': None, '_prev': add_14, '_next': reciprocal_6, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___bn2': ("getattr(L['self'].layer2, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___bn2', 'getattr_L__self___layer2___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'reciprocal_6', 'op': 'call_function', 'target': <OpOverload(op='aten.reciprocal', overload='default')>, '_input_nodes': {sqrt_6: None}, '_args': (sqrt_6,), '_kwargs': {}, 'users': {mul_18: None}, 'type': None, '_prev': sqrt_6, '_next': mul_18, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___bn2': ("getattr(L['self'].layer2, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___bn2', 'getattr_L__self___layer2___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_18', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {reciprocal_6: None}, '_args': (reciprocal_6, 1), '_kwargs': {}, 'users': {unsqueeze_50: None}, 'type': None, '_prev': reciprocal_6, '_next': unsqueeze_48, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___bn2': ("getattr(L['self'].layer2, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___bn2', 'getattr_L__self___layer2___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_48', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {convert_element_type_12: None}, '_args': (convert_element_type_12, -1), '_kwargs': {}, 'users': {unsqueeze_49: None}, 'type': None, '_prev': mul_18, '_next': unsqueeze_49, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___bn2': ("getattr(L['self'].layer2, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___bn2', 'getattr_L__self___layer2___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_49', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_48: None}, '_args': (unsqueeze_48, -1), '_kwargs': {}, 'users': {sub_6: None}, 'type': None, '_prev': unsqueeze_48, '_next': unsqueeze_50, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___bn2': ("getattr(L['self'].layer2, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___bn2', 'getattr_L__self___layer2___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_50', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {mul_18: None}, '_args': (mul_18, -1), '_kwargs': {}, 'users': {unsqueeze_51: None}, 'type': None, '_prev': unsqueeze_49, '_next': unsqueeze_51, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___bn2': ("getattr(L['self'].layer2, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___bn2', 'getattr_L__self___layer2___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_51', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_50: None}, '_args': (unsqueeze_50, -1), '_kwargs': {}, 'users': {mul_19: None}, 'type': None, '_prev': unsqueeze_50, '_next': sub_6, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___bn2': ("getattr(L['self'].layer2, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___bn2', 'getattr_L__self___layer2___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'sub_6', 'op': 'call_function', 'target': <OpOverload(op='aten.sub', overload='Tensor')>, '_input_nodes': {convolution_6: None, unsqueeze_49: None}, '_args': (convolution_6, unsqueeze_49), '_kwargs': {}, 'users': {mul_19: None}, 'type': None, '_prev': unsqueeze_51, '_next': mul_19, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___bn2': ("getattr(L['self'].layer2, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___bn2', 'getattr_L__self___layer2___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_19', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {sub_6: None, unsqueeze_51: None}, '_args': (sub_6, unsqueeze_51), '_kwargs': {}, 'users': {mul_20: None}, 'type': None, '_prev': sub_6, '_next': unsqueeze_52, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___bn2': ("getattr(L['self'].layer2, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___bn2', 'getattr_L__self___layer2___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_52', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {arg19_1: None}, '_args': (arg19_1, -1), '_kwargs': {}, 'users': {unsqueeze_53: None}, 'type': None, '_prev': mul_19, '_next': unsqueeze_53, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___bn2': ("getattr(L['self'].layer2, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___bn2', 'getattr_L__self___layer2___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_53', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_52: None}, '_args': (unsqueeze_52, -1), '_kwargs': {}, 'users': {mul_20: None}, 'type': None, '_prev': unsqueeze_52, '_next': mul_20, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___bn2': ("getattr(L['self'].layer2, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___bn2', 'getattr_L__self___layer2___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_20', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {mul_19: None, unsqueeze_53: None}, '_args': (mul_19, unsqueeze_53), '_kwargs': {}, 'users': {add_15: None}, 'type': None, '_prev': unsqueeze_53, '_next': unsqueeze_54, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___bn2': ("getattr(L['self'].layer2, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___bn2', 'getattr_L__self___layer2___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_54', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {arg20_1: None}, '_args': (arg20_1, -1), '_kwargs': {}, 'users': {unsqueeze_55: None}, 'type': None, '_prev': mul_20, '_next': unsqueeze_55, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___bn2': ("getattr(L['self'].layer2, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___bn2', 'getattr_L__self___layer2___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_55', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_54: None}, '_args': (unsqueeze_54, -1), '_kwargs': {}, 'users': {add_15: None}, 'type': None, '_prev': unsqueeze_54, '_next': add_15, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___bn2': ("getattr(L['self'].layer2, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___bn2', 'getattr_L__self___layer2___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_15', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {mul_20: None, unsqueeze_55: None}, '_args': (mul_20, unsqueeze_55), '_kwargs': {}, 'users': {add_18: None}, 'type': None, '_prev': unsqueeze_55, '_next': convolution_7, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___bn2': ("getattr(L['self'].layer2, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___bn2', 'getattr_L__self___layer2___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convolution_7', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {relu_4: None, arg21_1: None}, '_args': (relu_4, arg21_1, None, [2, 2], [0, 0], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {sub_7: None}, 'type': None, '_prev': add_15, '_next': convert_element_type_14, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___downsample': ("getattr(L['self'].layer2, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer2___0___downsample_0': ("getattr(getattr(L['self'].layer2, '0').downsample, '0')", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___downsample_0', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___downsample_0', 'getattr_L__self___layer2___0___downsample_0')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convert_element_type_14', 'op': 'call_function', 'target': <OpOverload(op='prims.convert_element_type', overload='default')>, '_input_nodes': {arg83_1: None}, '_args': (arg83_1, torch.float32), '_kwargs': {}, 'users': {unsqueeze_56: None}, 'type': None, '_prev': convolution_7, '_next': convert_element_type_15, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___downsample': ("getattr(L['self'].layer2, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer2___0___downsample_1': ("getattr(getattr(L['self'].layer2, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___downsample_1', 'getattr_L__self___layer2___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convert_element_type_15', 'op': 'call_function', 'target': <OpOverload(op='prims.convert_element_type', overload='default')>, '_input_nodes': {arg84_1: None}, '_args': (arg84_1, torch.float32), '_kwargs': {}, 'users': {add_16: None}, 'type': None, '_prev': convert_element_type_14, '_next': add_16, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___downsample': ("getattr(L['self'].layer2, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer2___0___downsample_1': ("getattr(getattr(L['self'].layer2, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___downsample_1', 'getattr_L__self___layer2___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_16', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {convert_element_type_15: None}, '_args': (convert_element_type_15, 1e-05), '_kwargs': {}, 'users': {sqrt_7: None}, 'type': None, '_prev': convert_element_type_15, '_next': sqrt_7, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___downsample': ("getattr(L['self'].layer2, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer2___0___downsample_1': ("getattr(getattr(L['self'].layer2, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___downsample_1', 'getattr_L__self___layer2___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'sqrt_7', 'op': 'call_function', 'target': <OpOverload(op='aten.sqrt', overload='default')>, '_input_nodes': {add_16: None}, '_args': (add_16,), '_kwargs': {}, 'users': {reciprocal_7: None}, 'type': None, '_prev': add_16, '_next': reciprocal_7, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___downsample': ("getattr(L['self'].layer2, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer2___0___downsample_1': ("getattr(getattr(L['self'].layer2, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___downsample_1', 'getattr_L__self___layer2___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'reciprocal_7', 'op': 'call_function', 'target': <OpOverload(op='aten.reciprocal', overload='default')>, '_input_nodes': {sqrt_7: None}, '_args': (sqrt_7,), '_kwargs': {}, 'users': {mul_21: None}, 'type': None, '_prev': sqrt_7, '_next': mul_21, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___downsample': ("getattr(L['self'].layer2, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer2___0___downsample_1': ("getattr(getattr(L['self'].layer2, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___downsample_1', 'getattr_L__self___layer2___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_21', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {reciprocal_7: None}, '_args': (reciprocal_7, 1), '_kwargs': {}, 'users': {unsqueeze_58: None}, 'type': None, '_prev': reciprocal_7, '_next': unsqueeze_56, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___downsample': ("getattr(L['self'].layer2, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer2___0___downsample_1': ("getattr(getattr(L['self'].layer2, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___downsample_1', 'getattr_L__self___layer2___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_56', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {convert_element_type_14: None}, '_args': (convert_element_type_14, -1), '_kwargs': {}, 'users': {unsqueeze_57: None}, 'type': None, '_prev': mul_21, '_next': unsqueeze_57, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___downsample': ("getattr(L['self'].layer2, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer2___0___downsample_1': ("getattr(getattr(L['self'].layer2, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___downsample_1', 'getattr_L__self___layer2___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_57', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_56: None}, '_args': (unsqueeze_56, -1), '_kwargs': {}, 'users': {sub_7: None}, 'type': None, '_prev': unsqueeze_56, '_next': unsqueeze_58, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___downsample': ("getattr(L['self'].layer2, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer2___0___downsample_1': ("getattr(getattr(L['self'].layer2, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___downsample_1', 'getattr_L__self___layer2___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_58', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {mul_21: None}, '_args': (mul_21, -1), '_kwargs': {}, 'users': {unsqueeze_59: None}, 'type': None, '_prev': unsqueeze_57, '_next': unsqueeze_59, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___downsample': ("getattr(L['self'].layer2, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer2___0___downsample_1': ("getattr(getattr(L['self'].layer2, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___downsample_1', 'getattr_L__self___layer2___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_59', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_58: None}, '_args': (unsqueeze_58, -1), '_kwargs': {}, 'users': {mul_22: None}, 'type': None, '_prev': unsqueeze_58, '_next': sub_7, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___downsample': ("getattr(L['self'].layer2, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer2___0___downsample_1': ("getattr(getattr(L['self'].layer2, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___downsample_1', 'getattr_L__self___layer2___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'sub_7', 'op': 'call_function', 'target': <OpOverload(op='aten.sub', overload='Tensor')>, '_input_nodes': {convolution_7: None, unsqueeze_57: None}, '_args': (convolution_7, unsqueeze_57), '_kwargs': {}, 'users': {mul_22: None}, 'type': None, '_prev': unsqueeze_59, '_next': mul_22, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___downsample': ("getattr(L['self'].layer2, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer2___0___downsample_1': ("getattr(getattr(L['self'].layer2, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___downsample_1', 'getattr_L__self___layer2___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_22', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {sub_7: None, unsqueeze_59: None}, '_args': (sub_7, unsqueeze_59), '_kwargs': {}, 'users': {mul_23: None}, 'type': None, '_prev': sub_7, '_next': unsqueeze_60, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___downsample': ("getattr(L['self'].layer2, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer2___0___downsample_1': ("getattr(getattr(L['self'].layer2, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___downsample_1', 'getattr_L__self___layer2___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_60', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {arg22_1: None}, '_args': (arg22_1, -1), '_kwargs': {}, 'users': {unsqueeze_61: None}, 'type': None, '_prev': mul_22, '_next': unsqueeze_61, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___downsample': ("getattr(L['self'].layer2, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer2___0___downsample_1': ("getattr(getattr(L['self'].layer2, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___downsample_1', 'getattr_L__self___layer2___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_61', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_60: None}, '_args': (unsqueeze_60, -1), '_kwargs': {}, 'users': {mul_23: None}, 'type': None, '_prev': unsqueeze_60, '_next': mul_23, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___downsample': ("getattr(L['self'].layer2, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer2___0___downsample_1': ("getattr(getattr(L['self'].layer2, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___downsample_1', 'getattr_L__self___layer2___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_23', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {mul_22: None, unsqueeze_61: None}, '_args': (mul_22, unsqueeze_61), '_kwargs': {}, 'users': {add_17: None}, 'type': None, '_prev': unsqueeze_61, '_next': unsqueeze_62, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___downsample': ("getattr(L['self'].layer2, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer2___0___downsample_1': ("getattr(getattr(L['self'].layer2, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___downsample_1', 'getattr_L__self___layer2___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_62', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {arg23_1: None}, '_args': (arg23_1, -1), '_kwargs': {}, 'users': {unsqueeze_63: None}, 'type': None, '_prev': mul_23, '_next': unsqueeze_63, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___downsample': ("getattr(L['self'].layer2, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer2___0___downsample_1': ("getattr(getattr(L['self'].layer2, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___downsample_1', 'getattr_L__self___layer2___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_63', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_62: None}, '_args': (unsqueeze_62, -1), '_kwargs': {}, 'users': {add_17: None}, 'type': None, '_prev': unsqueeze_62, '_next': add_17, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___downsample': ("getattr(L['self'].layer2, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer2___0___downsample_1': ("getattr(getattr(L['self'].layer2, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___downsample_1', 'getattr_L__self___layer2___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_17', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {mul_23: None, unsqueeze_63: None}, '_args': (mul_23, unsqueeze_63), '_kwargs': {}, 'users': {add_18: None}, 'type': None, '_prev': unsqueeze_63, '_next': add_18, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___downsample': ("getattr(L['self'].layer2, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer2___0___downsample_1': ("getattr(getattr(L['self'].layer2, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___downsample_1', 'getattr_L__self___layer2___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_18', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {add_15: None, add_17: None}, '_args': (add_15, add_17), '_kwargs': {}, 'users': {relu_6: None}, 'type': None, '_prev': add_17, '_next': relu_6, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 102, in forward\n    out += identity\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>)}, 'source_fn': ('iadd_2', <built-in function iadd>), 'original_aten': <OpOverload(op='aten.add', overload='Tensor')>, 'from_node': [('iadd_2', <built-in function iadd>)], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'relu_6', 'op': 'call_function', 'target': <OpOverload(op='aten.relu', overload='default')>, '_input_nodes': {add_18: None}, '_args': (add_18,), '_kwargs': {}, 'users': {convolution_8: None, add_23: None}, 'type': None, '_prev': add_18, '_next': convolution_8, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 103, in forward\n    out = self.relu(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_0': ("getattr(L['self'].layer2, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___0___relu': ("getattr(L['self'].layer2, '0').relu", <class 'torch.nn.modules.activation.ReLU'>)}, 'source_fn': ('getattr_l__self___layer2___0___relu_1', <class 'torch.nn.modules.activation.ReLU'>), 'original_aten': <OpOverload(op='aten.relu', overload='default')>, 'from_node': [('getattr_l__self___layer2___0___relu_1', 'getattr_L__self___layer2___0___relu')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convolution_8', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {relu_6: None, arg24_1: None}, '_args': (relu_6, arg24_1, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {sub_8: None}, 'type': None, '_prev': relu_6, '_next': convert_element_type_16, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 92, in forward\n    out = self.conv1(x)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___conv1': ("getattr(L['self'].layer2, '1').conv1", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___conv1', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___conv1', 'getattr_L__self___layer2___1___conv1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convert_element_type_16', 'op': 'call_function', 'target': <OpOverload(op='prims.convert_element_type', overload='default')>, '_input_nodes': {arg86_1: None}, '_args': (arg86_1, torch.float32), '_kwargs': {}, 'users': {unsqueeze_64: None}, 'type': None, '_prev': convolution_8, '_next': convert_element_type_17, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___bn1': ("getattr(L['self'].layer2, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___bn1', 'getattr_L__self___layer2___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convert_element_type_17', 'op': 'call_function', 'target': <OpOverload(op='prims.convert_element_type', overload='default')>, '_input_nodes': {arg87_1: None}, '_args': (arg87_1, torch.float32), '_kwargs': {}, 'users': {add_19: None}, 'type': None, '_prev': convert_element_type_16, '_next': add_19, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___bn1': ("getattr(L['self'].layer2, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___bn1', 'getattr_L__self___layer2___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_19', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {convert_element_type_17: None}, '_args': (convert_element_type_17, 1e-05), '_kwargs': {}, 'users': {sqrt_8: None}, 'type': None, '_prev': convert_element_type_17, '_next': sqrt_8, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___bn1': ("getattr(L['self'].layer2, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___bn1', 'getattr_L__self___layer2___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'sqrt_8', 'op': 'call_function', 'target': <OpOverload(op='aten.sqrt', overload='default')>, '_input_nodes': {add_19: None}, '_args': (add_19,), '_kwargs': {}, 'users': {reciprocal_8: None}, 'type': None, '_prev': add_19, '_next': reciprocal_8, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___bn1': ("getattr(L['self'].layer2, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___bn1', 'getattr_L__self___layer2___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'reciprocal_8', 'op': 'call_function', 'target': <OpOverload(op='aten.reciprocal', overload='default')>, '_input_nodes': {sqrt_8: None}, '_args': (sqrt_8,), '_kwargs': {}, 'users': {mul_24: None}, 'type': None, '_prev': sqrt_8, '_next': mul_24, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___bn1': ("getattr(L['self'].layer2, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___bn1', 'getattr_L__self___layer2___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_24', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {reciprocal_8: None}, '_args': (reciprocal_8, 1), '_kwargs': {}, 'users': {unsqueeze_66: None}, 'type': None, '_prev': reciprocal_8, '_next': unsqueeze_64, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___bn1': ("getattr(L['self'].layer2, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___bn1', 'getattr_L__self___layer2___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_64', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {convert_element_type_16: None}, '_args': (convert_element_type_16, -1), '_kwargs': {}, 'users': {unsqueeze_65: None}, 'type': None, '_prev': mul_24, '_next': unsqueeze_65, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___bn1': ("getattr(L['self'].layer2, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___bn1', 'getattr_L__self___layer2___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_65', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_64: None}, '_args': (unsqueeze_64, -1), '_kwargs': {}, 'users': {sub_8: None}, 'type': None, '_prev': unsqueeze_64, '_next': unsqueeze_66, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___bn1': ("getattr(L['self'].layer2, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___bn1', 'getattr_L__self___layer2___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_66', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {mul_24: None}, '_args': (mul_24, -1), '_kwargs': {}, 'users': {unsqueeze_67: None}, 'type': None, '_prev': unsqueeze_65, '_next': unsqueeze_67, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___bn1': ("getattr(L['self'].layer2, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___bn1', 'getattr_L__self___layer2___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_67', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_66: None}, '_args': (unsqueeze_66, -1), '_kwargs': {}, 'users': {mul_25: None}, 'type': None, '_prev': unsqueeze_66, '_next': sub_8, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___bn1': ("getattr(L['self'].layer2, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___bn1', 'getattr_L__self___layer2___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'sub_8', 'op': 'call_function', 'target': <OpOverload(op='aten.sub', overload='Tensor')>, '_input_nodes': {convolution_8: None, unsqueeze_65: None}, '_args': (convolution_8, unsqueeze_65), '_kwargs': {}, 'users': {mul_25: None}, 'type': None, '_prev': unsqueeze_67, '_next': mul_25, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___bn1': ("getattr(L['self'].layer2, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___bn1', 'getattr_L__self___layer2___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_25', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {sub_8: None, unsqueeze_67: None}, '_args': (sub_8, unsqueeze_67), '_kwargs': {}, 'users': {mul_26: None}, 'type': None, '_prev': sub_8, '_next': unsqueeze_68, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___bn1': ("getattr(L['self'].layer2, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___bn1', 'getattr_L__self___layer2___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_68', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {arg25_1: None}, '_args': (arg25_1, -1), '_kwargs': {}, 'users': {unsqueeze_69: None}, 'type': None, '_prev': mul_25, '_next': unsqueeze_69, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___bn1': ("getattr(L['self'].layer2, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___bn1', 'getattr_L__self___layer2___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_69', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_68: None}, '_args': (unsqueeze_68, -1), '_kwargs': {}, 'users': {mul_26: None}, 'type': None, '_prev': unsqueeze_68, '_next': mul_26, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___bn1': ("getattr(L['self'].layer2, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___bn1', 'getattr_L__self___layer2___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_26', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {mul_25: None, unsqueeze_69: None}, '_args': (mul_25, unsqueeze_69), '_kwargs': {}, 'users': {add_20: None}, 'type': None, '_prev': unsqueeze_69, '_next': unsqueeze_70, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___bn1': ("getattr(L['self'].layer2, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___bn1', 'getattr_L__self___layer2___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_70', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {arg26_1: None}, '_args': (arg26_1, -1), '_kwargs': {}, 'users': {unsqueeze_71: None}, 'type': None, '_prev': mul_26, '_next': unsqueeze_71, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___bn1': ("getattr(L['self'].layer2, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___bn1', 'getattr_L__self___layer2___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_71', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_70: None}, '_args': (unsqueeze_70, -1), '_kwargs': {}, 'users': {add_20: None}, 'type': None, '_prev': unsqueeze_70, '_next': add_20, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___bn1': ("getattr(L['self'].layer2, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___bn1', 'getattr_L__self___layer2___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_20', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {mul_26: None, unsqueeze_71: None}, '_args': (mul_26, unsqueeze_71), '_kwargs': {}, 'users': {relu_7: None}, 'type': None, '_prev': unsqueeze_71, '_next': relu_7, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___bn1': ("getattr(L['self'].layer2, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___bn1', 'getattr_L__self___layer2___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'relu_7', 'op': 'call_function', 'target': <OpOverload(op='aten.relu', overload='default')>, '_input_nodes': {add_20: None}, '_args': (add_20,), '_kwargs': {}, 'users': {convolution_9: None}, 'type': None, '_prev': add_20, '_next': convolution_9, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 94, in forward\n    out = self.relu(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___relu': ("getattr(L['self'].layer2, '1').relu", <class 'torch.nn.modules.activation.ReLU'>)}, 'source_fn': ('getattr_l__self___layer2___1___relu', <class 'torch.nn.modules.activation.ReLU'>), 'original_aten': <OpOverload(op='aten.relu', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___relu', 'getattr_L__self___layer2___1___relu')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convolution_9', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {relu_7: None, arg27_1: None}, '_args': (relu_7, arg27_1, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {sub_9: None}, 'type': None, '_prev': relu_7, '_next': convert_element_type_18, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 96, in forward\n    out = self.conv2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___conv2': ("getattr(L['self'].layer2, '1').conv2", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___conv2', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___conv2', 'getattr_L__self___layer2___1___conv2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convert_element_type_18', 'op': 'call_function', 'target': <OpOverload(op='prims.convert_element_type', overload='default')>, '_input_nodes': {arg89_1: None}, '_args': (arg89_1, torch.float32), '_kwargs': {}, 'users': {unsqueeze_72: None}, 'type': None, '_prev': convolution_9, '_next': convert_element_type_19, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___bn2': ("getattr(L['self'].layer2, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___bn2', 'getattr_L__self___layer2___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convert_element_type_19', 'op': 'call_function', 'target': <OpOverload(op='prims.convert_element_type', overload='default')>, '_input_nodes': {arg90_1: None}, '_args': (arg90_1, torch.float32), '_kwargs': {}, 'users': {add_21: None}, 'type': None, '_prev': convert_element_type_18, '_next': add_21, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___bn2': ("getattr(L['self'].layer2, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___bn2', 'getattr_L__self___layer2___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_21', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {convert_element_type_19: None}, '_args': (convert_element_type_19, 1e-05), '_kwargs': {}, 'users': {sqrt_9: None}, 'type': None, '_prev': convert_element_type_19, '_next': sqrt_9, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___bn2': ("getattr(L['self'].layer2, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___bn2', 'getattr_L__self___layer2___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'sqrt_9', 'op': 'call_function', 'target': <OpOverload(op='aten.sqrt', overload='default')>, '_input_nodes': {add_21: None}, '_args': (add_21,), '_kwargs': {}, 'users': {reciprocal_9: None}, 'type': None, '_prev': add_21, '_next': reciprocal_9, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___bn2': ("getattr(L['self'].layer2, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___bn2', 'getattr_L__self___layer2___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'reciprocal_9', 'op': 'call_function', 'target': <OpOverload(op='aten.reciprocal', overload='default')>, '_input_nodes': {sqrt_9: None}, '_args': (sqrt_9,), '_kwargs': {}, 'users': {mul_27: None}, 'type': None, '_prev': sqrt_9, '_next': mul_27, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___bn2': ("getattr(L['self'].layer2, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___bn2', 'getattr_L__self___layer2___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_27', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {reciprocal_9: None}, '_args': (reciprocal_9, 1), '_kwargs': {}, 'users': {unsqueeze_74: None}, 'type': None, '_prev': reciprocal_9, '_next': unsqueeze_72, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___bn2': ("getattr(L['self'].layer2, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___bn2', 'getattr_L__self___layer2___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128,)), 'tensor_meta': TensorMetadata(shape=torch.Size([128]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_72', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {convert_element_type_18: None}, '_args': (convert_element_type_18, -1), '_kwargs': {}, 'users': {unsqueeze_73: None}, 'type': None, '_prev': mul_27, '_next': unsqueeze_73, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___bn2': ("getattr(L['self'].layer2, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___bn2', 'getattr_L__self___layer2___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_73', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_72: None}, '_args': (unsqueeze_72, -1), '_kwargs': {}, 'users': {sub_9: None}, 'type': None, '_prev': unsqueeze_72, '_next': unsqueeze_74, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___bn2': ("getattr(L['self'].layer2, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___bn2', 'getattr_L__self___layer2___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_74', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {mul_27: None}, '_args': (mul_27, -1), '_kwargs': {}, 'users': {unsqueeze_75: None}, 'type': None, '_prev': unsqueeze_73, '_next': unsqueeze_75, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___bn2': ("getattr(L['self'].layer2, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___bn2', 'getattr_L__self___layer2___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_75', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_74: None}, '_args': (unsqueeze_74, -1), '_kwargs': {}, 'users': {mul_28: None}, 'type': None, '_prev': unsqueeze_74, '_next': sub_9, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___bn2': ("getattr(L['self'].layer2, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___bn2', 'getattr_L__self___layer2___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'sub_9', 'op': 'call_function', 'target': <OpOverload(op='aten.sub', overload='Tensor')>, '_input_nodes': {convolution_9: None, unsqueeze_73: None}, '_args': (convolution_9, unsqueeze_73), '_kwargs': {}, 'users': {mul_28: None}, 'type': None, '_prev': unsqueeze_75, '_next': mul_28, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___bn2': ("getattr(L['self'].layer2, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___bn2', 'getattr_L__self___layer2___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_28', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {sub_9: None, unsqueeze_75: None}, '_args': (sub_9, unsqueeze_75), '_kwargs': {}, 'users': {mul_29: None}, 'type': None, '_prev': sub_9, '_next': unsqueeze_76, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___bn2': ("getattr(L['self'].layer2, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___bn2', 'getattr_L__self___layer2___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_76', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {arg28_1: None}, '_args': (arg28_1, -1), '_kwargs': {}, 'users': {unsqueeze_77: None}, 'type': None, '_prev': mul_28, '_next': unsqueeze_77, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___bn2': ("getattr(L['self'].layer2, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___bn2', 'getattr_L__self___layer2___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_77', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_76: None}, '_args': (unsqueeze_76, -1), '_kwargs': {}, 'users': {mul_29: None}, 'type': None, '_prev': unsqueeze_76, '_next': mul_29, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___bn2': ("getattr(L['self'].layer2, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___bn2', 'getattr_L__self___layer2___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_29', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {mul_28: None, unsqueeze_77: None}, '_args': (mul_28, unsqueeze_77), '_kwargs': {}, 'users': {add_22: None}, 'type': None, '_prev': unsqueeze_77, '_next': unsqueeze_78, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___bn2': ("getattr(L['self'].layer2, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___bn2', 'getattr_L__self___layer2___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_78', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {arg29_1: None}, '_args': (arg29_1, -1), '_kwargs': {}, 'users': {unsqueeze_79: None}, 'type': None, '_prev': mul_29, '_next': unsqueeze_79, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___bn2': ("getattr(L['self'].layer2, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___bn2', 'getattr_L__self___layer2___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_79', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_78: None}, '_args': (unsqueeze_78, -1), '_kwargs': {}, 'users': {add_22: None}, 'type': None, '_prev': unsqueeze_78, '_next': add_22, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___bn2': ("getattr(L['self'].layer2, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___bn2', 'getattr_L__self___layer2___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(128, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([128, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_22', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {mul_29: None, unsqueeze_79: None}, '_args': (mul_29, unsqueeze_79), '_kwargs': {}, 'users': {add_23: None}, 'type': None, '_prev': unsqueeze_79, '_next': add_23, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___bn2': ("getattr(L['self'].layer2, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer2___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___bn2', 'getattr_L__self___layer2___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_23', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {add_22: None, relu_6: None}, '_args': (add_22, relu_6), '_kwargs': {}, 'users': {relu_8: None}, 'type': None, '_prev': add_22, '_next': relu_8, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 102, in forward\n    out += identity\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>)}, 'source_fn': ('iadd_3', <built-in function iadd>), 'original_aten': <OpOverload(op='aten.add', overload='Tensor')>, 'from_node': [('iadd_3', <built-in function iadd>)], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'relu_8', 'op': 'call_function', 'target': <OpOverload(op='aten.relu', overload='default')>, '_input_nodes': {add_23: None}, '_args': (add_23,), '_kwargs': {}, 'users': {convolution_10: None, convolution_12: None}, 'type': None, '_prev': add_23, '_next': convolution_10, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 274, in _forward_impl\n    x = self.layer2(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 103, in forward\n    out = self.relu(out)\n', 'nn_module_stack': {'L__self___layer2': ("L['self'].layer2", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer2_1': ("getattr(L['self'].layer2, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer2___1___relu': ("getattr(L['self'].layer2, '1').relu", <class 'torch.nn.modules.activation.ReLU'>)}, 'source_fn': ('getattr_l__self___layer2___1___relu_1', <class 'torch.nn.modules.activation.ReLU'>), 'original_aten': <OpOverload(op='aten.relu', overload='default')>, 'from_node': [('getattr_l__self___layer2___1___relu_1', 'getattr_L__self___layer2___1___relu')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 128, 28, 28)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 128, 28, 28]), dtype=torch.float32, requires_grad=False, stride=(100352, 784, 28, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convolution_10', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {relu_8: None, arg30_1: None}, '_args': (relu_8, arg30_1, None, [2, 2], [1, 1], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {sub_10: None}, 'type': None, '_prev': relu_8, '_next': convert_element_type_20, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 92, in forward\n    out = self.conv1(x)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___conv1': ("getattr(L['self'].layer3, '0').conv1", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___conv1', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___conv1', 'getattr_L__self___layer3___0___conv1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convert_element_type_20', 'op': 'call_function', 'target': <OpOverload(op='prims.convert_element_type', overload='default')>, '_input_nodes': {arg92_1: None}, '_args': (arg92_1, torch.float32), '_kwargs': {}, 'users': {unsqueeze_80: None}, 'type': None, '_prev': convolution_10, '_next': convert_element_type_21, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___bn1': ("getattr(L['self'].layer3, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___bn1', 'getattr_L__self___layer3___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convert_element_type_21', 'op': 'call_function', 'target': <OpOverload(op='prims.convert_element_type', overload='default')>, '_input_nodes': {arg93_1: None}, '_args': (arg93_1, torch.float32), '_kwargs': {}, 'users': {add_24: None}, 'type': None, '_prev': convert_element_type_20, '_next': add_24, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___bn1': ("getattr(L['self'].layer3, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___bn1', 'getattr_L__self___layer3___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_24', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {convert_element_type_21: None}, '_args': (convert_element_type_21, 1e-05), '_kwargs': {}, 'users': {sqrt_10: None}, 'type': None, '_prev': convert_element_type_21, '_next': sqrt_10, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___bn1': ("getattr(L['self'].layer3, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___bn1', 'getattr_L__self___layer3___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'sqrt_10', 'op': 'call_function', 'target': <OpOverload(op='aten.sqrt', overload='default')>, '_input_nodes': {add_24: None}, '_args': (add_24,), '_kwargs': {}, 'users': {reciprocal_10: None}, 'type': None, '_prev': add_24, '_next': reciprocal_10, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___bn1': ("getattr(L['self'].layer3, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___bn1', 'getattr_L__self___layer3___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'reciprocal_10', 'op': 'call_function', 'target': <OpOverload(op='aten.reciprocal', overload='default')>, '_input_nodes': {sqrt_10: None}, '_args': (sqrt_10,), '_kwargs': {}, 'users': {mul_30: None}, 'type': None, '_prev': sqrt_10, '_next': mul_30, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___bn1': ("getattr(L['self'].layer3, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___bn1', 'getattr_L__self___layer3___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_30', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {reciprocal_10: None}, '_args': (reciprocal_10, 1), '_kwargs': {}, 'users': {unsqueeze_82: None}, 'type': None, '_prev': reciprocal_10, '_next': unsqueeze_80, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___bn1': ("getattr(L['self'].layer3, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___bn1', 'getattr_L__self___layer3___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_80', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {convert_element_type_20: None}, '_args': (convert_element_type_20, -1), '_kwargs': {}, 'users': {unsqueeze_81: None}, 'type': None, '_prev': mul_30, '_next': unsqueeze_81, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___bn1': ("getattr(L['self'].layer3, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___bn1', 'getattr_L__self___layer3___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_81', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_80: None}, '_args': (unsqueeze_80, -1), '_kwargs': {}, 'users': {sub_10: None}, 'type': None, '_prev': unsqueeze_80, '_next': unsqueeze_82, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___bn1': ("getattr(L['self'].layer3, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___bn1', 'getattr_L__self___layer3___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_82', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {mul_30: None}, '_args': (mul_30, -1), '_kwargs': {}, 'users': {unsqueeze_83: None}, 'type': None, '_prev': unsqueeze_81, '_next': unsqueeze_83, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___bn1': ("getattr(L['self'].layer3, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___bn1', 'getattr_L__self___layer3___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_83', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_82: None}, '_args': (unsqueeze_82, -1), '_kwargs': {}, 'users': {mul_31: None}, 'type': None, '_prev': unsqueeze_82, '_next': sub_10, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___bn1': ("getattr(L['self'].layer3, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___bn1', 'getattr_L__self___layer3___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'sub_10', 'op': 'call_function', 'target': <OpOverload(op='aten.sub', overload='Tensor')>, '_input_nodes': {convolution_10: None, unsqueeze_81: None}, '_args': (convolution_10, unsqueeze_81), '_kwargs': {}, 'users': {mul_31: None}, 'type': None, '_prev': unsqueeze_83, '_next': mul_31, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___bn1': ("getattr(L['self'].layer3, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___bn1', 'getattr_L__self___layer3___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_31', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {sub_10: None, unsqueeze_83: None}, '_args': (sub_10, unsqueeze_83), '_kwargs': {}, 'users': {mul_32: None}, 'type': None, '_prev': sub_10, '_next': unsqueeze_84, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___bn1': ("getattr(L['self'].layer3, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___bn1', 'getattr_L__self___layer3___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_84', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {arg31_1: None}, '_args': (arg31_1, -1), '_kwargs': {}, 'users': {unsqueeze_85: None}, 'type': None, '_prev': mul_31, '_next': unsqueeze_85, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___bn1': ("getattr(L['self'].layer3, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___bn1', 'getattr_L__self___layer3___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_85', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_84: None}, '_args': (unsqueeze_84, -1), '_kwargs': {}, 'users': {mul_32: None}, 'type': None, '_prev': unsqueeze_84, '_next': mul_32, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___bn1': ("getattr(L['self'].layer3, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___bn1', 'getattr_L__self___layer3___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_32', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {mul_31: None, unsqueeze_85: None}, '_args': (mul_31, unsqueeze_85), '_kwargs': {}, 'users': {add_25: None}, 'type': None, '_prev': unsqueeze_85, '_next': unsqueeze_86, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___bn1': ("getattr(L['self'].layer3, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___bn1', 'getattr_L__self___layer3___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_86', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {arg32_1: None}, '_args': (arg32_1, -1), '_kwargs': {}, 'users': {unsqueeze_87: None}, 'type': None, '_prev': mul_32, '_next': unsqueeze_87, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___bn1': ("getattr(L['self'].layer3, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___bn1', 'getattr_L__self___layer3___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_87', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_86: None}, '_args': (unsqueeze_86, -1), '_kwargs': {}, 'users': {add_25: None}, 'type': None, '_prev': unsqueeze_86, '_next': add_25, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___bn1': ("getattr(L['self'].layer3, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___bn1', 'getattr_L__self___layer3___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_25', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {mul_32: None, unsqueeze_87: None}, '_args': (mul_32, unsqueeze_87), '_kwargs': {}, 'users': {relu_9: None}, 'type': None, '_prev': unsqueeze_87, '_next': relu_9, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___bn1': ("getattr(L['self'].layer3, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___bn1', 'getattr_L__self___layer3___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'relu_9', 'op': 'call_function', 'target': <OpOverload(op='aten.relu', overload='default')>, '_input_nodes': {add_25: None}, '_args': (add_25,), '_kwargs': {}, 'users': {convolution_11: None}, 'type': None, '_prev': add_25, '_next': convolution_11, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 94, in forward\n    out = self.relu(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___relu': ("getattr(L['self'].layer3, '0').relu", <class 'torch.nn.modules.activation.ReLU'>)}, 'source_fn': ('getattr_l__self___layer3___0___relu', <class 'torch.nn.modules.activation.ReLU'>), 'original_aten': <OpOverload(op='aten.relu', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___relu', 'getattr_L__self___layer3___0___relu')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convolution_11', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {relu_9: None, arg33_1: None}, '_args': (relu_9, arg33_1, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {sub_11: None}, 'type': None, '_prev': relu_9, '_next': convert_element_type_22, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 96, in forward\n    out = self.conv2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___conv2': ("getattr(L['self'].layer3, '0').conv2", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___conv2', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___conv2', 'getattr_L__self___layer3___0___conv2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convert_element_type_22', 'op': 'call_function', 'target': <OpOverload(op='prims.convert_element_type', overload='default')>, '_input_nodes': {arg95_1: None}, '_args': (arg95_1, torch.float32), '_kwargs': {}, 'users': {unsqueeze_88: None}, 'type': None, '_prev': convolution_11, '_next': convert_element_type_23, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___bn2': ("getattr(L['self'].layer3, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___bn2', 'getattr_L__self___layer3___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convert_element_type_23', 'op': 'call_function', 'target': <OpOverload(op='prims.convert_element_type', overload='default')>, '_input_nodes': {arg96_1: None}, '_args': (arg96_1, torch.float32), '_kwargs': {}, 'users': {add_26: None}, 'type': None, '_prev': convert_element_type_22, '_next': add_26, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___bn2': ("getattr(L['self'].layer3, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___bn2', 'getattr_L__self___layer3___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_26', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {convert_element_type_23: None}, '_args': (convert_element_type_23, 1e-05), '_kwargs': {}, 'users': {sqrt_11: None}, 'type': None, '_prev': convert_element_type_23, '_next': sqrt_11, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___bn2': ("getattr(L['self'].layer3, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___bn2', 'getattr_L__self___layer3___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'sqrt_11', 'op': 'call_function', 'target': <OpOverload(op='aten.sqrt', overload='default')>, '_input_nodes': {add_26: None}, '_args': (add_26,), '_kwargs': {}, 'users': {reciprocal_11: None}, 'type': None, '_prev': add_26, '_next': reciprocal_11, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___bn2': ("getattr(L['self'].layer3, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___bn2', 'getattr_L__self___layer3___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'reciprocal_11', 'op': 'call_function', 'target': <OpOverload(op='aten.reciprocal', overload='default')>, '_input_nodes': {sqrt_11: None}, '_args': (sqrt_11,), '_kwargs': {}, 'users': {mul_33: None}, 'type': None, '_prev': sqrt_11, '_next': mul_33, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___bn2': ("getattr(L['self'].layer3, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___bn2', 'getattr_L__self___layer3___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_33', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {reciprocal_11: None}, '_args': (reciprocal_11, 1), '_kwargs': {}, 'users': {unsqueeze_90: None}, 'type': None, '_prev': reciprocal_11, '_next': unsqueeze_88, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___bn2': ("getattr(L['self'].layer3, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___bn2', 'getattr_L__self___layer3___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_88', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {convert_element_type_22: None}, '_args': (convert_element_type_22, -1), '_kwargs': {}, 'users': {unsqueeze_89: None}, 'type': None, '_prev': mul_33, '_next': unsqueeze_89, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___bn2': ("getattr(L['self'].layer3, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___bn2', 'getattr_L__self___layer3___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_89', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_88: None}, '_args': (unsqueeze_88, -1), '_kwargs': {}, 'users': {sub_11: None}, 'type': None, '_prev': unsqueeze_88, '_next': unsqueeze_90, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___bn2': ("getattr(L['self'].layer3, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___bn2', 'getattr_L__self___layer3___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_90', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {mul_33: None}, '_args': (mul_33, -1), '_kwargs': {}, 'users': {unsqueeze_91: None}, 'type': None, '_prev': unsqueeze_89, '_next': unsqueeze_91, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___bn2': ("getattr(L['self'].layer3, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___bn2', 'getattr_L__self___layer3___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_91', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_90: None}, '_args': (unsqueeze_90, -1), '_kwargs': {}, 'users': {mul_34: None}, 'type': None, '_prev': unsqueeze_90, '_next': sub_11, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___bn2': ("getattr(L['self'].layer3, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___bn2', 'getattr_L__self___layer3___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'sub_11', 'op': 'call_function', 'target': <OpOverload(op='aten.sub', overload='Tensor')>, '_input_nodes': {convolution_11: None, unsqueeze_89: None}, '_args': (convolution_11, unsqueeze_89), '_kwargs': {}, 'users': {mul_34: None}, 'type': None, '_prev': unsqueeze_91, '_next': mul_34, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___bn2': ("getattr(L['self'].layer3, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___bn2', 'getattr_L__self___layer3___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_34', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {sub_11: None, unsqueeze_91: None}, '_args': (sub_11, unsqueeze_91), '_kwargs': {}, 'users': {mul_35: None}, 'type': None, '_prev': sub_11, '_next': unsqueeze_92, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___bn2': ("getattr(L['self'].layer3, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___bn2', 'getattr_L__self___layer3___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_92', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {arg34_1: None}, '_args': (arg34_1, -1), '_kwargs': {}, 'users': {unsqueeze_93: None}, 'type': None, '_prev': mul_34, '_next': unsqueeze_93, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___bn2': ("getattr(L['self'].layer3, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___bn2', 'getattr_L__self___layer3___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_93', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_92: None}, '_args': (unsqueeze_92, -1), '_kwargs': {}, 'users': {mul_35: None}, 'type': None, '_prev': unsqueeze_92, '_next': mul_35, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___bn2': ("getattr(L['self'].layer3, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___bn2', 'getattr_L__self___layer3___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_35', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {mul_34: None, unsqueeze_93: None}, '_args': (mul_34, unsqueeze_93), '_kwargs': {}, 'users': {add_27: None}, 'type': None, '_prev': unsqueeze_93, '_next': unsqueeze_94, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___bn2': ("getattr(L['self'].layer3, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___bn2', 'getattr_L__self___layer3___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_94', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {arg35_1: None}, '_args': (arg35_1, -1), '_kwargs': {}, 'users': {unsqueeze_95: None}, 'type': None, '_prev': mul_35, '_next': unsqueeze_95, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___bn2': ("getattr(L['self'].layer3, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___bn2', 'getattr_L__self___layer3___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_95', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_94: None}, '_args': (unsqueeze_94, -1), '_kwargs': {}, 'users': {add_27: None}, 'type': None, '_prev': unsqueeze_94, '_next': add_27, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___bn2': ("getattr(L['self'].layer3, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___bn2', 'getattr_L__self___layer3___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_27', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {mul_35: None, unsqueeze_95: None}, '_args': (mul_35, unsqueeze_95), '_kwargs': {}, 'users': {add_30: None}, 'type': None, '_prev': unsqueeze_95, '_next': convolution_12, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___bn2': ("getattr(L['self'].layer3, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___bn2', 'getattr_L__self___layer3___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convolution_12', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {relu_8: None, arg36_1: None}, '_args': (relu_8, arg36_1, None, [2, 2], [0, 0], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {sub_12: None}, 'type': None, '_prev': add_27, '_next': convert_element_type_24, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___downsample': ("getattr(L['self'].layer3, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer3___0___downsample_0': ("getattr(getattr(L['self'].layer3, '0').downsample, '0')", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___downsample_0', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___downsample_0', 'getattr_L__self___layer3___0___downsample_0')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convert_element_type_24', 'op': 'call_function', 'target': <OpOverload(op='prims.convert_element_type', overload='default')>, '_input_nodes': {arg98_1: None}, '_args': (arg98_1, torch.float32), '_kwargs': {}, 'users': {unsqueeze_96: None}, 'type': None, '_prev': convolution_12, '_next': convert_element_type_25, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___downsample': ("getattr(L['self'].layer3, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer3___0___downsample_1': ("getattr(getattr(L['self'].layer3, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___downsample_1', 'getattr_L__self___layer3___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convert_element_type_25', 'op': 'call_function', 'target': <OpOverload(op='prims.convert_element_type', overload='default')>, '_input_nodes': {arg99_1: None}, '_args': (arg99_1, torch.float32), '_kwargs': {}, 'users': {add_28: None}, 'type': None, '_prev': convert_element_type_24, '_next': add_28, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___downsample': ("getattr(L['self'].layer3, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer3___0___downsample_1': ("getattr(getattr(L['self'].layer3, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___downsample_1', 'getattr_L__self___layer3___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_28', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {convert_element_type_25: None}, '_args': (convert_element_type_25, 1e-05), '_kwargs': {}, 'users': {sqrt_12: None}, 'type': None, '_prev': convert_element_type_25, '_next': sqrt_12, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___downsample': ("getattr(L['self'].layer3, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer3___0___downsample_1': ("getattr(getattr(L['self'].layer3, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___downsample_1', 'getattr_L__self___layer3___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'sqrt_12', 'op': 'call_function', 'target': <OpOverload(op='aten.sqrt', overload='default')>, '_input_nodes': {add_28: None}, '_args': (add_28,), '_kwargs': {}, 'users': {reciprocal_12: None}, 'type': None, '_prev': add_28, '_next': reciprocal_12, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___downsample': ("getattr(L['self'].layer3, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer3___0___downsample_1': ("getattr(getattr(L['self'].layer3, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___downsample_1', 'getattr_L__self___layer3___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'reciprocal_12', 'op': 'call_function', 'target': <OpOverload(op='aten.reciprocal', overload='default')>, '_input_nodes': {sqrt_12: None}, '_args': (sqrt_12,), '_kwargs': {}, 'users': {mul_36: None}, 'type': None, '_prev': sqrt_12, '_next': mul_36, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___downsample': ("getattr(L['self'].layer3, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer3___0___downsample_1': ("getattr(getattr(L['self'].layer3, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___downsample_1', 'getattr_L__self___layer3___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_36', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {reciprocal_12: None}, '_args': (reciprocal_12, 1), '_kwargs': {}, 'users': {unsqueeze_98: None}, 'type': None, '_prev': reciprocal_12, '_next': unsqueeze_96, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___downsample': ("getattr(L['self'].layer3, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer3___0___downsample_1': ("getattr(getattr(L['self'].layer3, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___downsample_1', 'getattr_L__self___layer3___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_96', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {convert_element_type_24: None}, '_args': (convert_element_type_24, -1), '_kwargs': {}, 'users': {unsqueeze_97: None}, 'type': None, '_prev': mul_36, '_next': unsqueeze_97, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___downsample': ("getattr(L['self'].layer3, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer3___0___downsample_1': ("getattr(getattr(L['self'].layer3, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___downsample_1', 'getattr_L__self___layer3___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_97', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_96: None}, '_args': (unsqueeze_96, -1), '_kwargs': {}, 'users': {sub_12: None}, 'type': None, '_prev': unsqueeze_96, '_next': unsqueeze_98, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___downsample': ("getattr(L['self'].layer3, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer3___0___downsample_1': ("getattr(getattr(L['self'].layer3, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___downsample_1', 'getattr_L__self___layer3___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_98', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {mul_36: None}, '_args': (mul_36, -1), '_kwargs': {}, 'users': {unsqueeze_99: None}, 'type': None, '_prev': unsqueeze_97, '_next': unsqueeze_99, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___downsample': ("getattr(L['self'].layer3, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer3___0___downsample_1': ("getattr(getattr(L['self'].layer3, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___downsample_1', 'getattr_L__self___layer3___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_99', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_98: None}, '_args': (unsqueeze_98, -1), '_kwargs': {}, 'users': {mul_37: None}, 'type': None, '_prev': unsqueeze_98, '_next': sub_12, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___downsample': ("getattr(L['self'].layer3, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer3___0___downsample_1': ("getattr(getattr(L['self'].layer3, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___downsample_1', 'getattr_L__self___layer3___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'sub_12', 'op': 'call_function', 'target': <OpOverload(op='aten.sub', overload='Tensor')>, '_input_nodes': {convolution_12: None, unsqueeze_97: None}, '_args': (convolution_12, unsqueeze_97), '_kwargs': {}, 'users': {mul_37: None}, 'type': None, '_prev': unsqueeze_99, '_next': mul_37, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___downsample': ("getattr(L['self'].layer3, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer3___0___downsample_1': ("getattr(getattr(L['self'].layer3, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___downsample_1', 'getattr_L__self___layer3___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_37', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {sub_12: None, unsqueeze_99: None}, '_args': (sub_12, unsqueeze_99), '_kwargs': {}, 'users': {mul_38: None}, 'type': None, '_prev': sub_12, '_next': unsqueeze_100, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___downsample': ("getattr(L['self'].layer3, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer3___0___downsample_1': ("getattr(getattr(L['self'].layer3, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___downsample_1', 'getattr_L__self___layer3___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_100', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {arg37_1: None}, '_args': (arg37_1, -1), '_kwargs': {}, 'users': {unsqueeze_101: None}, 'type': None, '_prev': mul_37, '_next': unsqueeze_101, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___downsample': ("getattr(L['self'].layer3, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer3___0___downsample_1': ("getattr(getattr(L['self'].layer3, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___downsample_1', 'getattr_L__self___layer3___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_101', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_100: None}, '_args': (unsqueeze_100, -1), '_kwargs': {}, 'users': {mul_38: None}, 'type': None, '_prev': unsqueeze_100, '_next': mul_38, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___downsample': ("getattr(L['self'].layer3, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer3___0___downsample_1': ("getattr(getattr(L['self'].layer3, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___downsample_1', 'getattr_L__self___layer3___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_38', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {mul_37: None, unsqueeze_101: None}, '_args': (mul_37, unsqueeze_101), '_kwargs': {}, 'users': {add_29: None}, 'type': None, '_prev': unsqueeze_101, '_next': unsqueeze_102, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___downsample': ("getattr(L['self'].layer3, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer3___0___downsample_1': ("getattr(getattr(L['self'].layer3, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___downsample_1', 'getattr_L__self___layer3___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_102', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {arg38_1: None}, '_args': (arg38_1, -1), '_kwargs': {}, 'users': {unsqueeze_103: None}, 'type': None, '_prev': mul_38, '_next': unsqueeze_103, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___downsample': ("getattr(L['self'].layer3, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer3___0___downsample_1': ("getattr(getattr(L['self'].layer3, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___downsample_1', 'getattr_L__self___layer3___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_103', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_102: None}, '_args': (unsqueeze_102, -1), '_kwargs': {}, 'users': {add_29: None}, 'type': None, '_prev': unsqueeze_102, '_next': add_29, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___downsample': ("getattr(L['self'].layer3, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer3___0___downsample_1': ("getattr(getattr(L['self'].layer3, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___downsample_1', 'getattr_L__self___layer3___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_29', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {mul_38: None, unsqueeze_103: None}, '_args': (mul_38, unsqueeze_103), '_kwargs': {}, 'users': {add_30: None}, 'type': None, '_prev': unsqueeze_103, '_next': add_30, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___downsample': ("getattr(L['self'].layer3, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer3___0___downsample_1': ("getattr(getattr(L['self'].layer3, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___downsample_1', 'getattr_L__self___layer3___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_30', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {add_27: None, add_29: None}, '_args': (add_27, add_29), '_kwargs': {}, 'users': {relu_10: None}, 'type': None, '_prev': add_29, '_next': relu_10, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 102, in forward\n    out += identity\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>)}, 'source_fn': ('iadd_4', <built-in function iadd>), 'original_aten': <OpOverload(op='aten.add', overload='Tensor')>, 'from_node': [('iadd_4', <built-in function iadd>)], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'relu_10', 'op': 'call_function', 'target': <OpOverload(op='aten.relu', overload='default')>, '_input_nodes': {add_30: None}, '_args': (add_30,), '_kwargs': {}, 'users': {convolution_13: None, add_35: None}, 'type': None, '_prev': add_30, '_next': convolution_13, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 103, in forward\n    out = self.relu(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_0': ("getattr(L['self'].layer3, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___0___relu': ("getattr(L['self'].layer3, '0').relu", <class 'torch.nn.modules.activation.ReLU'>)}, 'source_fn': ('getattr_l__self___layer3___0___relu_1', <class 'torch.nn.modules.activation.ReLU'>), 'original_aten': <OpOverload(op='aten.relu', overload='default')>, 'from_node': [('getattr_l__self___layer3___0___relu_1', 'getattr_L__self___layer3___0___relu')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convolution_13', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {relu_10: None, arg39_1: None}, '_args': (relu_10, arg39_1, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {sub_13: None}, 'type': None, '_prev': relu_10, '_next': convert_element_type_26, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 92, in forward\n    out = self.conv1(x)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___conv1': ("getattr(L['self'].layer3, '1').conv1", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___conv1', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___conv1', 'getattr_L__self___layer3___1___conv1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convert_element_type_26', 'op': 'call_function', 'target': <OpOverload(op='prims.convert_element_type', overload='default')>, '_input_nodes': {arg101_1: None}, '_args': (arg101_1, torch.float32), '_kwargs': {}, 'users': {unsqueeze_104: None}, 'type': None, '_prev': convolution_13, '_next': convert_element_type_27, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___bn1': ("getattr(L['self'].layer3, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___bn1', 'getattr_L__self___layer3___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convert_element_type_27', 'op': 'call_function', 'target': <OpOverload(op='prims.convert_element_type', overload='default')>, '_input_nodes': {arg102_1: None}, '_args': (arg102_1, torch.float32), '_kwargs': {}, 'users': {add_31: None}, 'type': None, '_prev': convert_element_type_26, '_next': add_31, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___bn1': ("getattr(L['self'].layer3, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___bn1', 'getattr_L__self___layer3___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_31', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {convert_element_type_27: None}, '_args': (convert_element_type_27, 1e-05), '_kwargs': {}, 'users': {sqrt_13: None}, 'type': None, '_prev': convert_element_type_27, '_next': sqrt_13, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___bn1': ("getattr(L['self'].layer3, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___bn1', 'getattr_L__self___layer3___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'sqrt_13', 'op': 'call_function', 'target': <OpOverload(op='aten.sqrt', overload='default')>, '_input_nodes': {add_31: None}, '_args': (add_31,), '_kwargs': {}, 'users': {reciprocal_13: None}, 'type': None, '_prev': add_31, '_next': reciprocal_13, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___bn1': ("getattr(L['self'].layer3, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___bn1', 'getattr_L__self___layer3___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'reciprocal_13', 'op': 'call_function', 'target': <OpOverload(op='aten.reciprocal', overload='default')>, '_input_nodes': {sqrt_13: None}, '_args': (sqrt_13,), '_kwargs': {}, 'users': {mul_39: None}, 'type': None, '_prev': sqrt_13, '_next': mul_39, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___bn1': ("getattr(L['self'].layer3, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___bn1', 'getattr_L__self___layer3___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_39', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {reciprocal_13: None}, '_args': (reciprocal_13, 1), '_kwargs': {}, 'users': {unsqueeze_106: None}, 'type': None, '_prev': reciprocal_13, '_next': unsqueeze_104, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___bn1': ("getattr(L['self'].layer3, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___bn1', 'getattr_L__self___layer3___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_104', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {convert_element_type_26: None}, '_args': (convert_element_type_26, -1), '_kwargs': {}, 'users': {unsqueeze_105: None}, 'type': None, '_prev': mul_39, '_next': unsqueeze_105, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___bn1': ("getattr(L['self'].layer3, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___bn1', 'getattr_L__self___layer3___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_105', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_104: None}, '_args': (unsqueeze_104, -1), '_kwargs': {}, 'users': {sub_13: None}, 'type': None, '_prev': unsqueeze_104, '_next': unsqueeze_106, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___bn1': ("getattr(L['self'].layer3, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___bn1', 'getattr_L__self___layer3___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_106', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {mul_39: None}, '_args': (mul_39, -1), '_kwargs': {}, 'users': {unsqueeze_107: None}, 'type': None, '_prev': unsqueeze_105, '_next': unsqueeze_107, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___bn1': ("getattr(L['self'].layer3, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___bn1', 'getattr_L__self___layer3___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_107', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_106: None}, '_args': (unsqueeze_106, -1), '_kwargs': {}, 'users': {mul_40: None}, 'type': None, '_prev': unsqueeze_106, '_next': sub_13, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___bn1': ("getattr(L['self'].layer3, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___bn1', 'getattr_L__self___layer3___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'sub_13', 'op': 'call_function', 'target': <OpOverload(op='aten.sub', overload='Tensor')>, '_input_nodes': {convolution_13: None, unsqueeze_105: None}, '_args': (convolution_13, unsqueeze_105), '_kwargs': {}, 'users': {mul_40: None}, 'type': None, '_prev': unsqueeze_107, '_next': mul_40, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___bn1': ("getattr(L['self'].layer3, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___bn1', 'getattr_L__self___layer3___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_40', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {sub_13: None, unsqueeze_107: None}, '_args': (sub_13, unsqueeze_107), '_kwargs': {}, 'users': {mul_41: None}, 'type': None, '_prev': sub_13, '_next': unsqueeze_108, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___bn1': ("getattr(L['self'].layer3, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___bn1', 'getattr_L__self___layer3___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_108', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {arg40_1: None}, '_args': (arg40_1, -1), '_kwargs': {}, 'users': {unsqueeze_109: None}, 'type': None, '_prev': mul_40, '_next': unsqueeze_109, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___bn1': ("getattr(L['self'].layer3, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___bn1', 'getattr_L__self___layer3___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_109', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_108: None}, '_args': (unsqueeze_108, -1), '_kwargs': {}, 'users': {mul_41: None}, 'type': None, '_prev': unsqueeze_108, '_next': mul_41, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___bn1': ("getattr(L['self'].layer3, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___bn1', 'getattr_L__self___layer3___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_41', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {mul_40: None, unsqueeze_109: None}, '_args': (mul_40, unsqueeze_109), '_kwargs': {}, 'users': {add_32: None}, 'type': None, '_prev': unsqueeze_109, '_next': unsqueeze_110, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___bn1': ("getattr(L['self'].layer3, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___bn1', 'getattr_L__self___layer3___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_110', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {arg41_1: None}, '_args': (arg41_1, -1), '_kwargs': {}, 'users': {unsqueeze_111: None}, 'type': None, '_prev': mul_41, '_next': unsqueeze_111, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___bn1': ("getattr(L['self'].layer3, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___bn1', 'getattr_L__self___layer3___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_111', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_110: None}, '_args': (unsqueeze_110, -1), '_kwargs': {}, 'users': {add_32: None}, 'type': None, '_prev': unsqueeze_110, '_next': add_32, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___bn1': ("getattr(L['self'].layer3, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___bn1', 'getattr_L__self___layer3___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_32', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {mul_41: None, unsqueeze_111: None}, '_args': (mul_41, unsqueeze_111), '_kwargs': {}, 'users': {relu_11: None}, 'type': None, '_prev': unsqueeze_111, '_next': relu_11, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___bn1': ("getattr(L['self'].layer3, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___bn1', 'getattr_L__self___layer3___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'relu_11', 'op': 'call_function', 'target': <OpOverload(op='aten.relu', overload='default')>, '_input_nodes': {add_32: None}, '_args': (add_32,), '_kwargs': {}, 'users': {convolution_14: None}, 'type': None, '_prev': add_32, '_next': convolution_14, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 94, in forward\n    out = self.relu(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___relu': ("getattr(L['self'].layer3, '1').relu", <class 'torch.nn.modules.activation.ReLU'>)}, 'source_fn': ('getattr_l__self___layer3___1___relu', <class 'torch.nn.modules.activation.ReLU'>), 'original_aten': <OpOverload(op='aten.relu', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___relu', 'getattr_L__self___layer3___1___relu')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convolution_14', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {relu_11: None, arg42_1: None}, '_args': (relu_11, arg42_1, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {sub_14: None}, 'type': None, '_prev': relu_11, '_next': convert_element_type_28, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 96, in forward\n    out = self.conv2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___conv2': ("getattr(L['self'].layer3, '1').conv2", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___conv2', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___conv2', 'getattr_L__self___layer3___1___conv2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convert_element_type_28', 'op': 'call_function', 'target': <OpOverload(op='prims.convert_element_type', overload='default')>, '_input_nodes': {arg104_1: None}, '_args': (arg104_1, torch.float32), '_kwargs': {}, 'users': {unsqueeze_112: None}, 'type': None, '_prev': convolution_14, '_next': convert_element_type_29, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___bn2': ("getattr(L['self'].layer3, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___bn2', 'getattr_L__self___layer3___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convert_element_type_29', 'op': 'call_function', 'target': <OpOverload(op='prims.convert_element_type', overload='default')>, '_input_nodes': {arg105_1: None}, '_args': (arg105_1, torch.float32), '_kwargs': {}, 'users': {add_33: None}, 'type': None, '_prev': convert_element_type_28, '_next': add_33, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___bn2': ("getattr(L['self'].layer3, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___bn2', 'getattr_L__self___layer3___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_33', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {convert_element_type_29: None}, '_args': (convert_element_type_29, 1e-05), '_kwargs': {}, 'users': {sqrt_14: None}, 'type': None, '_prev': convert_element_type_29, '_next': sqrt_14, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___bn2': ("getattr(L['self'].layer3, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___bn2', 'getattr_L__self___layer3___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'sqrt_14', 'op': 'call_function', 'target': <OpOverload(op='aten.sqrt', overload='default')>, '_input_nodes': {add_33: None}, '_args': (add_33,), '_kwargs': {}, 'users': {reciprocal_14: None}, 'type': None, '_prev': add_33, '_next': reciprocal_14, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___bn2': ("getattr(L['self'].layer3, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___bn2', 'getattr_L__self___layer3___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'reciprocal_14', 'op': 'call_function', 'target': <OpOverload(op='aten.reciprocal', overload='default')>, '_input_nodes': {sqrt_14: None}, '_args': (sqrt_14,), '_kwargs': {}, 'users': {mul_42: None}, 'type': None, '_prev': sqrt_14, '_next': mul_42, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___bn2': ("getattr(L['self'].layer3, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___bn2', 'getattr_L__self___layer3___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_42', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {reciprocal_14: None}, '_args': (reciprocal_14, 1), '_kwargs': {}, 'users': {unsqueeze_114: None}, 'type': None, '_prev': reciprocal_14, '_next': unsqueeze_112, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___bn2': ("getattr(L['self'].layer3, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___bn2', 'getattr_L__self___layer3___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256,)), 'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_112', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {convert_element_type_28: None}, '_args': (convert_element_type_28, -1), '_kwargs': {}, 'users': {unsqueeze_113: None}, 'type': None, '_prev': mul_42, '_next': unsqueeze_113, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___bn2': ("getattr(L['self'].layer3, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___bn2', 'getattr_L__self___layer3___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_113', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_112: None}, '_args': (unsqueeze_112, -1), '_kwargs': {}, 'users': {sub_14: None}, 'type': None, '_prev': unsqueeze_112, '_next': unsqueeze_114, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___bn2': ("getattr(L['self'].layer3, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___bn2', 'getattr_L__self___layer3___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_114', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {mul_42: None}, '_args': (mul_42, -1), '_kwargs': {}, 'users': {unsqueeze_115: None}, 'type': None, '_prev': unsqueeze_113, '_next': unsqueeze_115, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___bn2': ("getattr(L['self'].layer3, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___bn2', 'getattr_L__self___layer3___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_115', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_114: None}, '_args': (unsqueeze_114, -1), '_kwargs': {}, 'users': {mul_43: None}, 'type': None, '_prev': unsqueeze_114, '_next': sub_14, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___bn2': ("getattr(L['self'].layer3, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___bn2', 'getattr_L__self___layer3___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'sub_14', 'op': 'call_function', 'target': <OpOverload(op='aten.sub', overload='Tensor')>, '_input_nodes': {convolution_14: None, unsqueeze_113: None}, '_args': (convolution_14, unsqueeze_113), '_kwargs': {}, 'users': {mul_43: None}, 'type': None, '_prev': unsqueeze_115, '_next': mul_43, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___bn2': ("getattr(L['self'].layer3, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___bn2', 'getattr_L__self___layer3___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_43', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {sub_14: None, unsqueeze_115: None}, '_args': (sub_14, unsqueeze_115), '_kwargs': {}, 'users': {mul_44: None}, 'type': None, '_prev': sub_14, '_next': unsqueeze_116, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___bn2': ("getattr(L['self'].layer3, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___bn2', 'getattr_L__self___layer3___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_116', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {arg43_1: None}, '_args': (arg43_1, -1), '_kwargs': {}, 'users': {unsqueeze_117: None}, 'type': None, '_prev': mul_43, '_next': unsqueeze_117, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___bn2': ("getattr(L['self'].layer3, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___bn2', 'getattr_L__self___layer3___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_117', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_116: None}, '_args': (unsqueeze_116, -1), '_kwargs': {}, 'users': {mul_44: None}, 'type': None, '_prev': unsqueeze_116, '_next': mul_44, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___bn2': ("getattr(L['self'].layer3, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___bn2', 'getattr_L__self___layer3___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_44', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {mul_43: None, unsqueeze_117: None}, '_args': (mul_43, unsqueeze_117), '_kwargs': {}, 'users': {add_34: None}, 'type': None, '_prev': unsqueeze_117, '_next': unsqueeze_118, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___bn2': ("getattr(L['self'].layer3, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___bn2', 'getattr_L__self___layer3___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_118', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {arg44_1: None}, '_args': (arg44_1, -1), '_kwargs': {}, 'users': {unsqueeze_119: None}, 'type': None, '_prev': mul_44, '_next': unsqueeze_119, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___bn2': ("getattr(L['self'].layer3, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___bn2', 'getattr_L__self___layer3___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_119', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_118: None}, '_args': (unsqueeze_118, -1), '_kwargs': {}, 'users': {add_34: None}, 'type': None, '_prev': unsqueeze_118, '_next': add_34, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___bn2': ("getattr(L['self'].layer3, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___bn2', 'getattr_L__self___layer3___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(256, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([256, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_34', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {mul_44: None, unsqueeze_119: None}, '_args': (mul_44, unsqueeze_119), '_kwargs': {}, 'users': {add_35: None}, 'type': None, '_prev': unsqueeze_119, '_next': add_35, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___bn2': ("getattr(L['self'].layer3, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer3___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___bn2', 'getattr_L__self___layer3___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_35', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {add_34: None, relu_10: None}, '_args': (add_34, relu_10), '_kwargs': {}, 'users': {relu_12: None}, 'type': None, '_prev': add_34, '_next': relu_12, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 102, in forward\n    out += identity\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>)}, 'source_fn': ('iadd_5', <built-in function iadd>), 'original_aten': <OpOverload(op='aten.add', overload='Tensor')>, 'from_node': [('iadd_5', <built-in function iadd>)], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'relu_12', 'op': 'call_function', 'target': <OpOverload(op='aten.relu', overload='default')>, '_input_nodes': {add_35: None}, '_args': (add_35,), '_kwargs': {}, 'users': {convolution_15: None, convolution_17: None}, 'type': None, '_prev': add_35, '_next': convolution_15, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 275, in _forward_impl\n    x = self.layer3(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 103, in forward\n    out = self.relu(out)\n', 'nn_module_stack': {'L__self___layer3': ("L['self'].layer3", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer3_1': ("getattr(L['self'].layer3, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer3___1___relu': ("getattr(L['self'].layer3, '1').relu", <class 'torch.nn.modules.activation.ReLU'>)}, 'source_fn': ('getattr_l__self___layer3___1___relu_1', <class 'torch.nn.modules.activation.ReLU'>), 'original_aten': <OpOverload(op='aten.relu', overload='default')>, 'from_node': [('getattr_l__self___layer3___1___relu_1', 'getattr_L__self___layer3___1___relu')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 256, 14, 14)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 256, 14, 14]), dtype=torch.float32, requires_grad=False, stride=(50176, 196, 14, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convolution_15', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {relu_12: None, arg45_1: None}, '_args': (relu_12, arg45_1, None, [2, 2], [1, 1], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {sub_15: None}, 'type': None, '_prev': relu_12, '_next': convert_element_type_30, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 92, in forward\n    out = self.conv1(x)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___conv1': ("getattr(L['self'].layer4, '0').conv1", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___conv1', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___conv1', 'getattr_L__self___layer4___0___conv1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convert_element_type_30', 'op': 'call_function', 'target': <OpOverload(op='prims.convert_element_type', overload='default')>, '_input_nodes': {arg107_1: None}, '_args': (arg107_1, torch.float32), '_kwargs': {}, 'users': {unsqueeze_120: None}, 'type': None, '_prev': convolution_15, '_next': convert_element_type_31, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___bn1': ("getattr(L['self'].layer4, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___bn1', 'getattr_L__self___layer4___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convert_element_type_31', 'op': 'call_function', 'target': <OpOverload(op='prims.convert_element_type', overload='default')>, '_input_nodes': {arg108_1: None}, '_args': (arg108_1, torch.float32), '_kwargs': {}, 'users': {add_36: None}, 'type': None, '_prev': convert_element_type_30, '_next': add_36, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___bn1': ("getattr(L['self'].layer4, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___bn1', 'getattr_L__self___layer4___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_36', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {convert_element_type_31: None}, '_args': (convert_element_type_31, 1e-05), '_kwargs': {}, 'users': {sqrt_15: None}, 'type': None, '_prev': convert_element_type_31, '_next': sqrt_15, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___bn1': ("getattr(L['self'].layer4, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___bn1', 'getattr_L__self___layer4___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'sqrt_15', 'op': 'call_function', 'target': <OpOverload(op='aten.sqrt', overload='default')>, '_input_nodes': {add_36: None}, '_args': (add_36,), '_kwargs': {}, 'users': {reciprocal_15: None}, 'type': None, '_prev': add_36, '_next': reciprocal_15, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___bn1': ("getattr(L['self'].layer4, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___bn1', 'getattr_L__self___layer4___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'reciprocal_15', 'op': 'call_function', 'target': <OpOverload(op='aten.reciprocal', overload='default')>, '_input_nodes': {sqrt_15: None}, '_args': (sqrt_15,), '_kwargs': {}, 'users': {mul_45: None}, 'type': None, '_prev': sqrt_15, '_next': mul_45, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___bn1': ("getattr(L['self'].layer4, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___bn1', 'getattr_L__self___layer4___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_45', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {reciprocal_15: None}, '_args': (reciprocal_15, 1), '_kwargs': {}, 'users': {unsqueeze_122: None}, 'type': None, '_prev': reciprocal_15, '_next': unsqueeze_120, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___bn1': ("getattr(L['self'].layer4, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___bn1', 'getattr_L__self___layer4___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_120', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {convert_element_type_30: None}, '_args': (convert_element_type_30, -1), '_kwargs': {}, 'users': {unsqueeze_121: None}, 'type': None, '_prev': mul_45, '_next': unsqueeze_121, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___bn1': ("getattr(L['self'].layer4, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___bn1', 'getattr_L__self___layer4___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_121', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_120: None}, '_args': (unsqueeze_120, -1), '_kwargs': {}, 'users': {sub_15: None}, 'type': None, '_prev': unsqueeze_120, '_next': unsqueeze_122, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___bn1': ("getattr(L['self'].layer4, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___bn1', 'getattr_L__self___layer4___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_122', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {mul_45: None}, '_args': (mul_45, -1), '_kwargs': {}, 'users': {unsqueeze_123: None}, 'type': None, '_prev': unsqueeze_121, '_next': unsqueeze_123, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___bn1': ("getattr(L['self'].layer4, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___bn1', 'getattr_L__self___layer4___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_123', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_122: None}, '_args': (unsqueeze_122, -1), '_kwargs': {}, 'users': {mul_46: None}, 'type': None, '_prev': unsqueeze_122, '_next': sub_15, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___bn1': ("getattr(L['self'].layer4, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___bn1', 'getattr_L__self___layer4___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'sub_15', 'op': 'call_function', 'target': <OpOverload(op='aten.sub', overload='Tensor')>, '_input_nodes': {convolution_15: None, unsqueeze_121: None}, '_args': (convolution_15, unsqueeze_121), '_kwargs': {}, 'users': {mul_46: None}, 'type': None, '_prev': unsqueeze_123, '_next': mul_46, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___bn1': ("getattr(L['self'].layer4, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___bn1', 'getattr_L__self___layer4___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_46', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {sub_15: None, unsqueeze_123: None}, '_args': (sub_15, unsqueeze_123), '_kwargs': {}, 'users': {mul_47: None}, 'type': None, '_prev': sub_15, '_next': unsqueeze_124, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___bn1': ("getattr(L['self'].layer4, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___bn1', 'getattr_L__self___layer4___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_124', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {arg46_1: None}, '_args': (arg46_1, -1), '_kwargs': {}, 'users': {unsqueeze_125: None}, 'type': None, '_prev': mul_46, '_next': unsqueeze_125, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___bn1': ("getattr(L['self'].layer4, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___bn1', 'getattr_L__self___layer4___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_125', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_124: None}, '_args': (unsqueeze_124, -1), '_kwargs': {}, 'users': {mul_47: None}, 'type': None, '_prev': unsqueeze_124, '_next': mul_47, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___bn1': ("getattr(L['self'].layer4, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___bn1', 'getattr_L__self___layer4___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_47', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {mul_46: None, unsqueeze_125: None}, '_args': (mul_46, unsqueeze_125), '_kwargs': {}, 'users': {add_37: None}, 'type': None, '_prev': unsqueeze_125, '_next': unsqueeze_126, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___bn1': ("getattr(L['self'].layer4, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___bn1', 'getattr_L__self___layer4___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_126', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {arg47_1: None}, '_args': (arg47_1, -1), '_kwargs': {}, 'users': {unsqueeze_127: None}, 'type': None, '_prev': mul_47, '_next': unsqueeze_127, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___bn1': ("getattr(L['self'].layer4, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___bn1', 'getattr_L__self___layer4___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_127', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_126: None}, '_args': (unsqueeze_126, -1), '_kwargs': {}, 'users': {add_37: None}, 'type': None, '_prev': unsqueeze_126, '_next': add_37, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___bn1': ("getattr(L['self'].layer4, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___bn1', 'getattr_L__self___layer4___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_37', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {mul_47: None, unsqueeze_127: None}, '_args': (mul_47, unsqueeze_127), '_kwargs': {}, 'users': {relu_13: None}, 'type': None, '_prev': unsqueeze_127, '_next': relu_13, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___bn1': ("getattr(L['self'].layer4, '0').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___bn1', 'getattr_L__self___layer4___0___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'relu_13', 'op': 'call_function', 'target': <OpOverload(op='aten.relu', overload='default')>, '_input_nodes': {add_37: None}, '_args': (add_37,), '_kwargs': {}, 'users': {convolution_16: None}, 'type': None, '_prev': add_37, '_next': convolution_16, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 94, in forward\n    out = self.relu(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___relu': ("getattr(L['self'].layer4, '0').relu", <class 'torch.nn.modules.activation.ReLU'>)}, 'source_fn': ('getattr_l__self___layer4___0___relu', <class 'torch.nn.modules.activation.ReLU'>), 'original_aten': <OpOverload(op='aten.relu', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___relu', 'getattr_L__self___layer4___0___relu')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convolution_16', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {relu_13: None, arg48_1: None}, '_args': (relu_13, arg48_1, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {sub_16: None}, 'type': None, '_prev': relu_13, '_next': convert_element_type_32, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 96, in forward\n    out = self.conv2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___conv2': ("getattr(L['self'].layer4, '0').conv2", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___conv2', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___conv2', 'getattr_L__self___layer4___0___conv2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convert_element_type_32', 'op': 'call_function', 'target': <OpOverload(op='prims.convert_element_type', overload='default')>, '_input_nodes': {arg110_1: None}, '_args': (arg110_1, torch.float32), '_kwargs': {}, 'users': {unsqueeze_128: None}, 'type': None, '_prev': convolution_16, '_next': convert_element_type_33, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___bn2': ("getattr(L['self'].layer4, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___bn2', 'getattr_L__self___layer4___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convert_element_type_33', 'op': 'call_function', 'target': <OpOverload(op='prims.convert_element_type', overload='default')>, '_input_nodes': {arg111_1: None}, '_args': (arg111_1, torch.float32), '_kwargs': {}, 'users': {add_38: None}, 'type': None, '_prev': convert_element_type_32, '_next': add_38, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___bn2': ("getattr(L['self'].layer4, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___bn2', 'getattr_L__self___layer4___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_38', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {convert_element_type_33: None}, '_args': (convert_element_type_33, 1e-05), '_kwargs': {}, 'users': {sqrt_16: None}, 'type': None, '_prev': convert_element_type_33, '_next': sqrt_16, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___bn2': ("getattr(L['self'].layer4, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___bn2', 'getattr_L__self___layer4___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'sqrt_16', 'op': 'call_function', 'target': <OpOverload(op='aten.sqrt', overload='default')>, '_input_nodes': {add_38: None}, '_args': (add_38,), '_kwargs': {}, 'users': {reciprocal_16: None}, 'type': None, '_prev': add_38, '_next': reciprocal_16, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___bn2': ("getattr(L['self'].layer4, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___bn2', 'getattr_L__self___layer4___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'reciprocal_16', 'op': 'call_function', 'target': <OpOverload(op='aten.reciprocal', overload='default')>, '_input_nodes': {sqrt_16: None}, '_args': (sqrt_16,), '_kwargs': {}, 'users': {mul_48: None}, 'type': None, '_prev': sqrt_16, '_next': mul_48, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___bn2': ("getattr(L['self'].layer4, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___bn2', 'getattr_L__self___layer4___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_48', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {reciprocal_16: None}, '_args': (reciprocal_16, 1), '_kwargs': {}, 'users': {unsqueeze_130: None}, 'type': None, '_prev': reciprocal_16, '_next': unsqueeze_128, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___bn2': ("getattr(L['self'].layer4, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___bn2', 'getattr_L__self___layer4___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_128', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {convert_element_type_32: None}, '_args': (convert_element_type_32, -1), '_kwargs': {}, 'users': {unsqueeze_129: None}, 'type': None, '_prev': mul_48, '_next': unsqueeze_129, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___bn2': ("getattr(L['self'].layer4, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___bn2', 'getattr_L__self___layer4___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_129', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_128: None}, '_args': (unsqueeze_128, -1), '_kwargs': {}, 'users': {sub_16: None}, 'type': None, '_prev': unsqueeze_128, '_next': unsqueeze_130, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___bn2': ("getattr(L['self'].layer4, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___bn2', 'getattr_L__self___layer4___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_130', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {mul_48: None}, '_args': (mul_48, -1), '_kwargs': {}, 'users': {unsqueeze_131: None}, 'type': None, '_prev': unsqueeze_129, '_next': unsqueeze_131, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___bn2': ("getattr(L['self'].layer4, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___bn2', 'getattr_L__self___layer4___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_131', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_130: None}, '_args': (unsqueeze_130, -1), '_kwargs': {}, 'users': {mul_49: None}, 'type': None, '_prev': unsqueeze_130, '_next': sub_16, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___bn2': ("getattr(L['self'].layer4, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___bn2', 'getattr_L__self___layer4___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'sub_16', 'op': 'call_function', 'target': <OpOverload(op='aten.sub', overload='Tensor')>, '_input_nodes': {convolution_16: None, unsqueeze_129: None}, '_args': (convolution_16, unsqueeze_129), '_kwargs': {}, 'users': {mul_49: None}, 'type': None, '_prev': unsqueeze_131, '_next': mul_49, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___bn2': ("getattr(L['self'].layer4, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___bn2', 'getattr_L__self___layer4___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_49', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {sub_16: None, unsqueeze_131: None}, '_args': (sub_16, unsqueeze_131), '_kwargs': {}, 'users': {mul_50: None}, 'type': None, '_prev': sub_16, '_next': unsqueeze_132, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___bn2': ("getattr(L['self'].layer4, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___bn2', 'getattr_L__self___layer4___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_132', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {arg49_1: None}, '_args': (arg49_1, -1), '_kwargs': {}, 'users': {unsqueeze_133: None}, 'type': None, '_prev': mul_49, '_next': unsqueeze_133, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___bn2': ("getattr(L['self'].layer4, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___bn2', 'getattr_L__self___layer4___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_133', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_132: None}, '_args': (unsqueeze_132, -1), '_kwargs': {}, 'users': {mul_50: None}, 'type': None, '_prev': unsqueeze_132, '_next': mul_50, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___bn2': ("getattr(L['self'].layer4, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___bn2', 'getattr_L__self___layer4___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_50', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {mul_49: None, unsqueeze_133: None}, '_args': (mul_49, unsqueeze_133), '_kwargs': {}, 'users': {add_39: None}, 'type': None, '_prev': unsqueeze_133, '_next': unsqueeze_134, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___bn2': ("getattr(L['self'].layer4, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___bn2', 'getattr_L__self___layer4___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_134', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {arg50_1: None}, '_args': (arg50_1, -1), '_kwargs': {}, 'users': {unsqueeze_135: None}, 'type': None, '_prev': mul_50, '_next': unsqueeze_135, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___bn2': ("getattr(L['self'].layer4, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___bn2', 'getattr_L__self___layer4___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_135', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_134: None}, '_args': (unsqueeze_134, -1), '_kwargs': {}, 'users': {add_39: None}, 'type': None, '_prev': unsqueeze_134, '_next': add_39, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___bn2': ("getattr(L['self'].layer4, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___bn2', 'getattr_L__self___layer4___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_39', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {mul_50: None, unsqueeze_135: None}, '_args': (mul_50, unsqueeze_135), '_kwargs': {}, 'users': {add_42: None}, 'type': None, '_prev': unsqueeze_135, '_next': convolution_17, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___bn2': ("getattr(L['self'].layer4, '0').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___bn2', 'getattr_L__self___layer4___0___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convolution_17', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {relu_12: None, arg51_1: None}, '_args': (relu_12, arg51_1, None, [2, 2], [0, 0], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {sub_17: None}, 'type': None, '_prev': add_39, '_next': convert_element_type_34, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___downsample': ("getattr(L['self'].layer4, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer4___0___downsample_0': ("getattr(getattr(L['self'].layer4, '0').downsample, '0')", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___downsample_0', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___downsample_0', 'getattr_L__self___layer4___0___downsample_0')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convert_element_type_34', 'op': 'call_function', 'target': <OpOverload(op='prims.convert_element_type', overload='default')>, '_input_nodes': {arg113_1: None}, '_args': (arg113_1, torch.float32), '_kwargs': {}, 'users': {unsqueeze_136: None}, 'type': None, '_prev': convolution_17, '_next': convert_element_type_35, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___downsample': ("getattr(L['self'].layer4, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer4___0___downsample_1': ("getattr(getattr(L['self'].layer4, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___downsample_1', 'getattr_L__self___layer4___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convert_element_type_35', 'op': 'call_function', 'target': <OpOverload(op='prims.convert_element_type', overload='default')>, '_input_nodes': {arg114_1: None}, '_args': (arg114_1, torch.float32), '_kwargs': {}, 'users': {add_40: None}, 'type': None, '_prev': convert_element_type_34, '_next': add_40, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___downsample': ("getattr(L['self'].layer4, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer4___0___downsample_1': ("getattr(getattr(L['self'].layer4, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___downsample_1', 'getattr_L__self___layer4___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_40', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {convert_element_type_35: None}, '_args': (convert_element_type_35, 1e-05), '_kwargs': {}, 'users': {sqrt_17: None}, 'type': None, '_prev': convert_element_type_35, '_next': sqrt_17, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___downsample': ("getattr(L['self'].layer4, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer4___0___downsample_1': ("getattr(getattr(L['self'].layer4, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___downsample_1', 'getattr_L__self___layer4___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'sqrt_17', 'op': 'call_function', 'target': <OpOverload(op='aten.sqrt', overload='default')>, '_input_nodes': {add_40: None}, '_args': (add_40,), '_kwargs': {}, 'users': {reciprocal_17: None}, 'type': None, '_prev': add_40, '_next': reciprocal_17, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___downsample': ("getattr(L['self'].layer4, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer4___0___downsample_1': ("getattr(getattr(L['self'].layer4, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___downsample_1', 'getattr_L__self___layer4___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'reciprocal_17', 'op': 'call_function', 'target': <OpOverload(op='aten.reciprocal', overload='default')>, '_input_nodes': {sqrt_17: None}, '_args': (sqrt_17,), '_kwargs': {}, 'users': {mul_51: None}, 'type': None, '_prev': sqrt_17, '_next': mul_51, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___downsample': ("getattr(L['self'].layer4, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer4___0___downsample_1': ("getattr(getattr(L['self'].layer4, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___downsample_1', 'getattr_L__self___layer4___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_51', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {reciprocal_17: None}, '_args': (reciprocal_17, 1), '_kwargs': {}, 'users': {unsqueeze_138: None}, 'type': None, '_prev': reciprocal_17, '_next': unsqueeze_136, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___downsample': ("getattr(L['self'].layer4, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer4___0___downsample_1': ("getattr(getattr(L['self'].layer4, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___downsample_1', 'getattr_L__self___layer4___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_136', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {convert_element_type_34: None}, '_args': (convert_element_type_34, -1), '_kwargs': {}, 'users': {unsqueeze_137: None}, 'type': None, '_prev': mul_51, '_next': unsqueeze_137, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___downsample': ("getattr(L['self'].layer4, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer4___0___downsample_1': ("getattr(getattr(L['self'].layer4, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___downsample_1', 'getattr_L__self___layer4___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_137', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_136: None}, '_args': (unsqueeze_136, -1), '_kwargs': {}, 'users': {sub_17: None}, 'type': None, '_prev': unsqueeze_136, '_next': unsqueeze_138, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___downsample': ("getattr(L['self'].layer4, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer4___0___downsample_1': ("getattr(getattr(L['self'].layer4, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___downsample_1', 'getattr_L__self___layer4___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_138', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {mul_51: None}, '_args': (mul_51, -1), '_kwargs': {}, 'users': {unsqueeze_139: None}, 'type': None, '_prev': unsqueeze_137, '_next': unsqueeze_139, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___downsample': ("getattr(L['self'].layer4, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer4___0___downsample_1': ("getattr(getattr(L['self'].layer4, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___downsample_1', 'getattr_L__self___layer4___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_139', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_138: None}, '_args': (unsqueeze_138, -1), '_kwargs': {}, 'users': {mul_52: None}, 'type': None, '_prev': unsqueeze_138, '_next': sub_17, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___downsample': ("getattr(L['self'].layer4, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer4___0___downsample_1': ("getattr(getattr(L['self'].layer4, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___downsample_1', 'getattr_L__self___layer4___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'sub_17', 'op': 'call_function', 'target': <OpOverload(op='aten.sub', overload='Tensor')>, '_input_nodes': {convolution_17: None, unsqueeze_137: None}, '_args': (convolution_17, unsqueeze_137), '_kwargs': {}, 'users': {mul_52: None}, 'type': None, '_prev': unsqueeze_139, '_next': mul_52, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___downsample': ("getattr(L['self'].layer4, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer4___0___downsample_1': ("getattr(getattr(L['self'].layer4, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___downsample_1', 'getattr_L__self___layer4___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_52', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {sub_17: None, unsqueeze_139: None}, '_args': (sub_17, unsqueeze_139), '_kwargs': {}, 'users': {mul_53: None}, 'type': None, '_prev': sub_17, '_next': unsqueeze_140, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___downsample': ("getattr(L['self'].layer4, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer4___0___downsample_1': ("getattr(getattr(L['self'].layer4, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___downsample_1', 'getattr_L__self___layer4___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_140', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {arg52_1: None}, '_args': (arg52_1, -1), '_kwargs': {}, 'users': {unsqueeze_141: None}, 'type': None, '_prev': mul_52, '_next': unsqueeze_141, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___downsample': ("getattr(L['self'].layer4, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer4___0___downsample_1': ("getattr(getattr(L['self'].layer4, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___downsample_1', 'getattr_L__self___layer4___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_141', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_140: None}, '_args': (unsqueeze_140, -1), '_kwargs': {}, 'users': {mul_53: None}, 'type': None, '_prev': unsqueeze_140, '_next': mul_53, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___downsample': ("getattr(L['self'].layer4, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer4___0___downsample_1': ("getattr(getattr(L['self'].layer4, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___downsample_1', 'getattr_L__self___layer4___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_53', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {mul_52: None, unsqueeze_141: None}, '_args': (mul_52, unsqueeze_141), '_kwargs': {}, 'users': {add_41: None}, 'type': None, '_prev': unsqueeze_141, '_next': unsqueeze_142, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___downsample': ("getattr(L['self'].layer4, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer4___0___downsample_1': ("getattr(getattr(L['self'].layer4, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___downsample_1', 'getattr_L__self___layer4___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_142', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {arg53_1: None}, '_args': (arg53_1, -1), '_kwargs': {}, 'users': {unsqueeze_143: None}, 'type': None, '_prev': mul_53, '_next': unsqueeze_143, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___downsample': ("getattr(L['self'].layer4, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer4___0___downsample_1': ("getattr(getattr(L['self'].layer4, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___downsample_1', 'getattr_L__self___layer4___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_143', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_142: None}, '_args': (unsqueeze_142, -1), '_kwargs': {}, 'users': {add_41: None}, 'type': None, '_prev': unsqueeze_142, '_next': add_41, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___downsample': ("getattr(L['self'].layer4, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer4___0___downsample_1': ("getattr(getattr(L['self'].layer4, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___downsample_1', 'getattr_L__self___layer4___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_41', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {mul_53: None, unsqueeze_143: None}, '_args': (mul_53, unsqueeze_143), '_kwargs': {}, 'users': {add_42: None}, 'type': None, '_prev': unsqueeze_143, '_next': add_42, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 100, in forward\n    identity = self.downsample(x)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___downsample': ("getattr(L['self'].layer4, '0').downsample", <class 'torch.nn.modules.container.Sequential'>), 'getattr_L__self___layer4___0___downsample_1': ("getattr(getattr(L['self'].layer4, '0').downsample, '1')", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___0___downsample_1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___downsample_1', 'getattr_L__self___layer4___0___downsample_1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_42', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {add_39: None, add_41: None}, '_args': (add_39, add_41), '_kwargs': {}, 'users': {relu_14: None}, 'type': None, '_prev': add_41, '_next': relu_14, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 102, in forward\n    out += identity\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>)}, 'source_fn': ('iadd_6', <built-in function iadd>), 'original_aten': <OpOverload(op='aten.add', overload='Tensor')>, 'from_node': [('iadd_6', <built-in function iadd>)], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'relu_14', 'op': 'call_function', 'target': <OpOverload(op='aten.relu', overload='default')>, '_input_nodes': {add_42: None}, '_args': (add_42,), '_kwargs': {}, 'users': {convolution_18: None, add_47: None}, 'type': None, '_prev': add_42, '_next': convolution_18, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 103, in forward\n    out = self.relu(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_0': ("getattr(L['self'].layer4, '0')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___0___relu': ("getattr(L['self'].layer4, '0').relu", <class 'torch.nn.modules.activation.ReLU'>)}, 'source_fn': ('getattr_l__self___layer4___0___relu_1', <class 'torch.nn.modules.activation.ReLU'>), 'original_aten': <OpOverload(op='aten.relu', overload='default')>, 'from_node': [('getattr_l__self___layer4___0___relu_1', 'getattr_L__self___layer4___0___relu')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convolution_18', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {relu_14: None, arg54_1: None}, '_args': (relu_14, arg54_1, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {sub_18: None}, 'type': None, '_prev': relu_14, '_next': convert_element_type_36, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 92, in forward\n    out = self.conv1(x)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___conv1': ("getattr(L['self'].layer4, '1').conv1", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___conv1', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___conv1', 'getattr_L__self___layer4___1___conv1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convert_element_type_36', 'op': 'call_function', 'target': <OpOverload(op='prims.convert_element_type', overload='default')>, '_input_nodes': {arg116_1: None}, '_args': (arg116_1, torch.float32), '_kwargs': {}, 'users': {unsqueeze_144: None}, 'type': None, '_prev': convolution_18, '_next': convert_element_type_37, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___bn1': ("getattr(L['self'].layer4, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___bn1', 'getattr_L__self___layer4___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convert_element_type_37', 'op': 'call_function', 'target': <OpOverload(op='prims.convert_element_type', overload='default')>, '_input_nodes': {arg117_1: None}, '_args': (arg117_1, torch.float32), '_kwargs': {}, 'users': {add_43: None}, 'type': None, '_prev': convert_element_type_36, '_next': add_43, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___bn1': ("getattr(L['self'].layer4, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___bn1', 'getattr_L__self___layer4___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_43', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {convert_element_type_37: None}, '_args': (convert_element_type_37, 1e-05), '_kwargs': {}, 'users': {sqrt_18: None}, 'type': None, '_prev': convert_element_type_37, '_next': sqrt_18, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___bn1': ("getattr(L['self'].layer4, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___bn1', 'getattr_L__self___layer4___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'sqrt_18', 'op': 'call_function', 'target': <OpOverload(op='aten.sqrt', overload='default')>, '_input_nodes': {add_43: None}, '_args': (add_43,), '_kwargs': {}, 'users': {reciprocal_18: None}, 'type': None, '_prev': add_43, '_next': reciprocal_18, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___bn1': ("getattr(L['self'].layer4, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___bn1', 'getattr_L__self___layer4___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'reciprocal_18', 'op': 'call_function', 'target': <OpOverload(op='aten.reciprocal', overload='default')>, '_input_nodes': {sqrt_18: None}, '_args': (sqrt_18,), '_kwargs': {}, 'users': {mul_54: None}, 'type': None, '_prev': sqrt_18, '_next': mul_54, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___bn1': ("getattr(L['self'].layer4, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___bn1', 'getattr_L__self___layer4___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_54', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {reciprocal_18: None}, '_args': (reciprocal_18, 1), '_kwargs': {}, 'users': {unsqueeze_146: None}, 'type': None, '_prev': reciprocal_18, '_next': unsqueeze_144, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___bn1': ("getattr(L['self'].layer4, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___bn1', 'getattr_L__self___layer4___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_144', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {convert_element_type_36: None}, '_args': (convert_element_type_36, -1), '_kwargs': {}, 'users': {unsqueeze_145: None}, 'type': None, '_prev': mul_54, '_next': unsqueeze_145, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___bn1': ("getattr(L['self'].layer4, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___bn1', 'getattr_L__self___layer4___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_145', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_144: None}, '_args': (unsqueeze_144, -1), '_kwargs': {}, 'users': {sub_18: None}, 'type': None, '_prev': unsqueeze_144, '_next': unsqueeze_146, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___bn1': ("getattr(L['self'].layer4, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___bn1', 'getattr_L__self___layer4___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_146', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {mul_54: None}, '_args': (mul_54, -1), '_kwargs': {}, 'users': {unsqueeze_147: None}, 'type': None, '_prev': unsqueeze_145, '_next': unsqueeze_147, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___bn1': ("getattr(L['self'].layer4, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___bn1', 'getattr_L__self___layer4___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_147', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_146: None}, '_args': (unsqueeze_146, -1), '_kwargs': {}, 'users': {mul_55: None}, 'type': None, '_prev': unsqueeze_146, '_next': sub_18, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___bn1': ("getattr(L['self'].layer4, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___bn1', 'getattr_L__self___layer4___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'sub_18', 'op': 'call_function', 'target': <OpOverload(op='aten.sub', overload='Tensor')>, '_input_nodes': {convolution_18: None, unsqueeze_145: None}, '_args': (convolution_18, unsqueeze_145), '_kwargs': {}, 'users': {mul_55: None}, 'type': None, '_prev': unsqueeze_147, '_next': mul_55, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___bn1': ("getattr(L['self'].layer4, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___bn1', 'getattr_L__self___layer4___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_55', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {sub_18: None, unsqueeze_147: None}, '_args': (sub_18, unsqueeze_147), '_kwargs': {}, 'users': {mul_56: None}, 'type': None, '_prev': sub_18, '_next': unsqueeze_148, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___bn1': ("getattr(L['self'].layer4, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___bn1', 'getattr_L__self___layer4___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_148', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {arg55_1: None}, '_args': (arg55_1, -1), '_kwargs': {}, 'users': {unsqueeze_149: None}, 'type': None, '_prev': mul_55, '_next': unsqueeze_149, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___bn1': ("getattr(L['self'].layer4, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___bn1', 'getattr_L__self___layer4___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_149', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_148: None}, '_args': (unsqueeze_148, -1), '_kwargs': {}, 'users': {mul_56: None}, 'type': None, '_prev': unsqueeze_148, '_next': mul_56, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___bn1': ("getattr(L['self'].layer4, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___bn1', 'getattr_L__self___layer4___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_56', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {mul_55: None, unsqueeze_149: None}, '_args': (mul_55, unsqueeze_149), '_kwargs': {}, 'users': {add_44: None}, 'type': None, '_prev': unsqueeze_149, '_next': unsqueeze_150, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___bn1': ("getattr(L['self'].layer4, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___bn1', 'getattr_L__self___layer4___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_150', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {arg56_1: None}, '_args': (arg56_1, -1), '_kwargs': {}, 'users': {unsqueeze_151: None}, 'type': None, '_prev': mul_56, '_next': unsqueeze_151, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___bn1': ("getattr(L['self'].layer4, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___bn1', 'getattr_L__self___layer4___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_151', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_150: None}, '_args': (unsqueeze_150, -1), '_kwargs': {}, 'users': {add_44: None}, 'type': None, '_prev': unsqueeze_150, '_next': add_44, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___bn1': ("getattr(L['self'].layer4, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___bn1', 'getattr_L__self___layer4___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_44', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {mul_56: None, unsqueeze_151: None}, '_args': (mul_56, unsqueeze_151), '_kwargs': {}, 'users': {relu_15: None}, 'type': None, '_prev': unsqueeze_151, '_next': relu_15, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 93, in forward\n    out = self.bn1(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___bn1': ("getattr(L['self'].layer4, '1').bn1", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___bn1', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___bn1', 'getattr_L__self___layer4___1___bn1')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'relu_15', 'op': 'call_function', 'target': <OpOverload(op='aten.relu', overload='default')>, '_input_nodes': {add_44: None}, '_args': (add_44,), '_kwargs': {}, 'users': {convolution_19: None}, 'type': None, '_prev': add_44, '_next': convolution_19, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 94, in forward\n    out = self.relu(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___relu': ("getattr(L['self'].layer4, '1').relu", <class 'torch.nn.modules.activation.ReLU'>)}, 'source_fn': ('getattr_l__self___layer4___1___relu', <class 'torch.nn.modules.activation.ReLU'>), 'original_aten': <OpOverload(op='aten.relu', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___relu', 'getattr_L__self___layer4___1___relu')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convolution_19', 'op': 'call_function', 'target': <OpOverload(op='aten.convolution', overload='default')>, '_input_nodes': {relu_15: None, arg57_1: None}, '_args': (relu_15, arg57_1, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), '_kwargs': {}, 'users': {sub_19: None}, 'type': None, '_prev': relu_15, '_next': convert_element_type_38, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 96, in forward\n    out = self.conv2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___conv2': ("getattr(L['self'].layer4, '1').conv2", <class 'torch.nn.modules.conv.Conv2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___conv2', <class 'torch.nn.modules.conv.Conv2d'>), 'original_aten': <OpOverload(op='aten.convolution', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___conv2', 'getattr_L__self___layer4___1___conv2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convert_element_type_38', 'op': 'call_function', 'target': <OpOverload(op='prims.convert_element_type', overload='default')>, '_input_nodes': {arg119_1: None}, '_args': (arg119_1, torch.float32), '_kwargs': {}, 'users': {unsqueeze_152: None}, 'type': None, '_prev': convolution_19, '_next': convert_element_type_39, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___bn2': ("getattr(L['self'].layer4, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___bn2', 'getattr_L__self___layer4___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'convert_element_type_39', 'op': 'call_function', 'target': <OpOverload(op='prims.convert_element_type', overload='default')>, '_input_nodes': {arg120_1: None}, '_args': (arg120_1, torch.float32), '_kwargs': {}, 'users': {add_45: None}, 'type': None, '_prev': convert_element_type_38, '_next': add_45, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___bn2': ("getattr(L['self'].layer4, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___bn2', 'getattr_L__self___layer4___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_45', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {convert_element_type_39: None}, '_args': (convert_element_type_39, 1e-05), '_kwargs': {}, 'users': {sqrt_19: None}, 'type': None, '_prev': convert_element_type_39, '_next': sqrt_19, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___bn2': ("getattr(L['self'].layer4, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___bn2', 'getattr_L__self___layer4___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'sqrt_19', 'op': 'call_function', 'target': <OpOverload(op='aten.sqrt', overload='default')>, '_input_nodes': {add_45: None}, '_args': (add_45,), '_kwargs': {}, 'users': {reciprocal_19: None}, 'type': None, '_prev': add_45, '_next': reciprocal_19, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___bn2': ("getattr(L['self'].layer4, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___bn2', 'getattr_L__self___layer4___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'reciprocal_19', 'op': 'call_function', 'target': <OpOverload(op='aten.reciprocal', overload='default')>, '_input_nodes': {sqrt_19: None}, '_args': (sqrt_19,), '_kwargs': {}, 'users': {mul_57: None}, 'type': None, '_prev': sqrt_19, '_next': mul_57, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___bn2': ("getattr(L['self'].layer4, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___bn2', 'getattr_L__self___layer4___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_57', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {reciprocal_19: None}, '_args': (reciprocal_19, 1), '_kwargs': {}, 'users': {unsqueeze_154: None}, 'type': None, '_prev': reciprocal_19, '_next': unsqueeze_152, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___bn2': ("getattr(L['self'].layer4, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___bn2', 'getattr_L__self___layer4___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512,)), 'tensor_meta': TensorMetadata(shape=torch.Size([512]), dtype=torch.float32, requires_grad=False, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_152', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {convert_element_type_38: None}, '_args': (convert_element_type_38, -1), '_kwargs': {}, 'users': {unsqueeze_153: None}, 'type': None, '_prev': mul_57, '_next': unsqueeze_153, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___bn2': ("getattr(L['self'].layer4, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___bn2', 'getattr_L__self___layer4___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_153', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_152: None}, '_args': (unsqueeze_152, -1), '_kwargs': {}, 'users': {sub_19: None}, 'type': None, '_prev': unsqueeze_152, '_next': unsqueeze_154, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___bn2': ("getattr(L['self'].layer4, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___bn2', 'getattr_L__self___layer4___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_154', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {mul_57: None}, '_args': (mul_57, -1), '_kwargs': {}, 'users': {unsqueeze_155: None}, 'type': None, '_prev': unsqueeze_153, '_next': unsqueeze_155, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___bn2': ("getattr(L['self'].layer4, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___bn2', 'getattr_L__self___layer4___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_155', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_154: None}, '_args': (unsqueeze_154, -1), '_kwargs': {}, 'users': {mul_58: None}, 'type': None, '_prev': unsqueeze_154, '_next': sub_19, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___bn2': ("getattr(L['self'].layer4, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___bn2', 'getattr_L__self___layer4___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'sub_19', 'op': 'call_function', 'target': <OpOverload(op='aten.sub', overload='Tensor')>, '_input_nodes': {convolution_19: None, unsqueeze_153: None}, '_args': (convolution_19, unsqueeze_153), '_kwargs': {}, 'users': {mul_58: None}, 'type': None, '_prev': unsqueeze_155, '_next': mul_58, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___bn2': ("getattr(L['self'].layer4, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___bn2', 'getattr_L__self___layer4___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_58', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {sub_19: None, unsqueeze_155: None}, '_args': (sub_19, unsqueeze_155), '_kwargs': {}, 'users': {mul_59: None}, 'type': None, '_prev': sub_19, '_next': unsqueeze_156, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___bn2': ("getattr(L['self'].layer4, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___bn2', 'getattr_L__self___layer4___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_156', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {arg58_1: None}, '_args': (arg58_1, -1), '_kwargs': {}, 'users': {unsqueeze_157: None}, 'type': None, '_prev': mul_58, '_next': unsqueeze_157, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___bn2': ("getattr(L['self'].layer4, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___bn2', 'getattr_L__self___layer4___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_157', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_156: None}, '_args': (unsqueeze_156, -1), '_kwargs': {}, 'users': {mul_59: None}, 'type': None, '_prev': unsqueeze_156, '_next': mul_59, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___bn2': ("getattr(L['self'].layer4, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___bn2', 'getattr_L__self___layer4___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mul_59', 'op': 'call_function', 'target': <OpOverload(op='aten.mul', overload='Tensor')>, '_input_nodes': {mul_58: None, unsqueeze_157: None}, '_args': (mul_58, unsqueeze_157), '_kwargs': {}, 'users': {add_46: None}, 'type': None, '_prev': unsqueeze_157, '_next': unsqueeze_158, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___bn2': ("getattr(L['self'].layer4, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___bn2', 'getattr_L__self___layer4___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_158', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {arg59_1: None}, '_args': (arg59_1, -1), '_kwargs': {}, 'users': {unsqueeze_159: None}, 'type': None, '_prev': mul_59, '_next': unsqueeze_159, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___bn2': ("getattr(L['self'].layer4, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___bn2', 'getattr_L__self___layer4___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'unsqueeze_159', 'op': 'call_function', 'target': <OpOverload(op='aten.unsqueeze', overload='default')>, '_input_nodes': {unsqueeze_158: None}, '_args': (unsqueeze_158, -1), '_kwargs': {}, 'users': {add_46: None}, 'type': None, '_prev': unsqueeze_158, '_next': add_46, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___bn2': ("getattr(L['self'].layer4, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___bn2', 'getattr_L__self___layer4___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(1, 1, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_46', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {mul_59: None, unsqueeze_159: None}, '_args': (mul_59, unsqueeze_159), '_kwargs': {}, 'users': {add_47: None}, 'type': None, '_prev': unsqueeze_159, '_next': add_47, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 97, in forward\n    out = self.bn2(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___bn2': ("getattr(L['self'].layer4, '1').bn2", <class 'torch.nn.modules.batchnorm.BatchNorm2d'>)}, 'source_fn': ('getattr_l__self___layer4___1___bn2', <class 'torch.nn.modules.batchnorm.BatchNorm2d'>), 'original_aten': <OpOverload(op='aten._native_batch_norm_legit_no_training', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___bn2', 'getattr_L__self___layer4___1___bn2')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'add_47', 'op': 'call_function', 'target': <OpOverload(op='aten.add', overload='Tensor')>, '_input_nodes': {add_46: None, relu_14: None}, '_args': (add_46, relu_14), '_kwargs': {}, 'users': {relu_16: None}, 'type': None, '_prev': add_46, '_next': relu_16, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 102, in forward\n    out += identity\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>)}, 'source_fn': ('iadd_7', <built-in function iadd>), 'original_aten': <OpOverload(op='aten.add', overload='Tensor')>, 'from_node': [('iadd_7', <built-in function iadd>)], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'relu_16', 'op': 'call_function', 'target': <OpOverload(op='aten.relu', overload='default')>, '_input_nodes': {add_47: None}, '_args': (add_47,), '_kwargs': {}, 'users': {mean: None}, 'type': None, '_prev': add_47, '_next': mean, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 276, in _forward_impl\n    x = self.layer4(x)\n  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 103, in forward\n    out = self.relu(out)\n', 'nn_module_stack': {'L__self___layer4': ("L['self'].layer4", <class 'torch.nn.modules.container.Sequential'>), 'L__self___layer4_1': ("getattr(L['self'].layer4, '1')", <class 'torchvision.models.resnet.BasicBlock'>), 'getattr_L__self___layer4___1___relu': ("getattr(L['self'].layer4, '1').relu", <class 'torch.nn.modules.activation.ReLU'>)}, 'source_fn': ('getattr_l__self___layer4___1___relu_1', <class 'torch.nn.modules.activation.ReLU'>), 'original_aten': <OpOverload(op='aten.relu', overload='default')>, 'from_node': [('getattr_l__self___layer4___1___relu_1', 'getattr_L__self___layer4___1___relu')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 7, 7)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 7, 7]), dtype=torch.float32, requires_grad=False, stride=(25088, 49, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'mean', 'op': 'call_function', 'target': <OpOverload(op='aten.mean', overload='dim')>, '_input_nodes': {relu_16: None}, '_args': (relu_16, [-1, -2], True), '_kwargs': {}, 'users': {view: None}, 'type': None, '_prev': relu_16, '_next': view, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 278, in _forward_impl\n    x = self.avgpool(x)\n', 'nn_module_stack': {'L__self___avgpool': ("L['self'].avgpool", <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>)}, 'source_fn': ('l__self___avgpool', <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>), 'original_aten': <OpOverload(op='aten.mean', overload='dim')>, 'from_node': [('l__self___avgpool', 'L__self___avgpool')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512, 1, 1)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512, 1, 1]), dtype=torch.float32, requires_grad=False, stride=(512, 1, 1, 1), memory_format=torch.channels_last, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'view', 'op': 'call_function', 'target': <OpOverload(op='aten.view', overload='default')>, '_input_nodes': {mean: None}, '_args': (mean, [1, 512]), '_kwargs': {}, 'users': {addmm: None}, 'type': None, '_prev': mean, '_next': permute, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 279, in _forward_impl\n    x = torch.flatten(x, 1)\n', 'source_fn': ('flatten', <built-in method flatten of type object at 0x7f4558e6ca40>), 'original_aten': <OpOverload(op='aten.view', overload='default')>, 'from_node': [('flatten', <built-in method flatten of type object at 0x7f4558e6ca40>)], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 512)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 512]), dtype=torch.float32, requires_grad=False, stride=(512, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'permute', 'op': 'call_function', 'target': <OpOverload(op='aten.permute', overload='default')>, '_input_nodes': {arg60_1: None}, '_args': (arg60_1, [1, 0]), '_kwargs': {}, 'users': {addmm: None}, 'type': None, '_prev': view, '_next': addmm, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 280, in _forward_impl\n    x = self.fc(x)\n', 'nn_module_stack': {'L__self___fc': ("L['self'].fc", <class 'torch.nn.modules.linear.Linear'>)}, 'source_fn': ('l__self___fc', <class 'torch.nn.modules.linear.Linear'>), 'original_aten': <OpOverload(op='aten.t', overload='default')>, 'from_node': [('l__self___fc', 'L__self___fc')], 'seq_nr': 123, 'val': FakeTensor(..., size=(512, 1000)), 'tensor_meta': TensorMetadata(shape=torch.Size([512, 1000]), dtype=torch.float32, requires_grad=False, stride=(1, 512), memory_format=None, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'addmm', 'op': 'call_function', 'target': <OpOverload(op='aten.addmm', overload='default')>, '_input_nodes': {arg61_1: None, view: None, permute: None}, '_args': (arg61_1, view, permute), '_kwargs': {}, 'users': {output: None}, 'type': None, '_prev': permute, '_next': output, '_erased': False, '_repr_fn': None, 'meta': {'stack_trace': '  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 285, in forward\n    return self._forward_impl(x)\n  File "/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py", line 280, in _forward_impl\n    x = self.fc(x)\n', 'nn_module_stack': {'L__self___fc': ("L['self'].fc", <class 'torch.nn.modules.linear.Linear'>)}, 'source_fn': ('l__self___fc', <class 'torch.nn.modules.linear.Linear'>), 'original_aten': <OpOverload(op='aten.addmm', overload='default')>, 'from_node': [('l__self___fc', 'L__self___fc')], 'seq_nr': 123, 'val': FakeTensor(..., size=(1, 1000)), 'tensor_meta': TensorMetadata(shape=torch.Size([1, 1000]), dtype=torch.float32, requires_grad=False, stride=(1000, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})}}
{'graph': <torch.fx.graph.Graph object at 0x7f4427259180>, 'name': 'output', 'op': 'output', 'target': 'output', '_input_nodes': {addmm: None}, '_args': ((addmm,),), '_kwargs': {}, 'users': {}, 'type': None, '_prev': addmm, '_next': , '_erased': False, '_repr_fn': None, 'meta': {}}
